Wed 01 May 2024 07:02:55 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'ISIC2019']
IMG_SIZE: [384, 384]
CLASSIFIER: DenseNet121
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 4 dbs
Combining 2th db out of 4 dbs
Combining 3th db out of 4 dbs
Combining 4th db out of 4 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
densenet121 (Functional)     (None, 1024)              7037504   
_________________________________________________________________
dense (Dense)                (None, 512)               524800    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 7,697,218
Trainable params: 658,178
Non-trainable params: 7,039,040
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+ISIC2019_aug_DenseNet121_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+ISIC2019_aug_DenseNet121_384h_384w_None
Epoch: 1 loss: 0.8394 accuracy: 0.7964 val_loss: 0.7602 val_accuracy: 0.8118
Epoch: 2 loss: 0.6597 accuracy: 0.8513 val_loss: 0.7159 val_accuracy: 0.8250
Epoch: 3 loss: 0.6017 accuracy: 0.8666 val_loss: 0.6415 val_accuracy: 0.8540
Epoch: 4 loss: 0.5570 accuracy: 0.8778 val_loss: 0.6392 val_accuracy: 0.8288
Epoch: 5 loss: 0.5228 accuracy: 0.8883 val_loss: 0.6061 val_accuracy: 0.8451
Epoch: 6 loss: 0.4879 accuracy: 0.8971 val_loss: 0.5922 val_accuracy: 0.8463
Epoch: 7 loss: 0.4610 accuracy: 0.9031 val_loss: 0.5505 val_accuracy: 0.8615
Epoch: 8 loss: 0.4369 accuracy: 0.9096 val_loss: 0.5220 val_accuracy: 0.8737
Epoch: 9 loss: 0.4135 accuracy: 0.9149 val_loss: 0.5370 val_accuracy: 0.8576
Epoch: 10 loss: 0.3951 accuracy: 0.9182 val_loss: 0.5215 val_accuracy: 0.8537
Epoch: 11 loss: 0.3815 accuracy: 0.9210 val_loss: 0.4906 val_accuracy: 0.8732
Epoch: 12 loss: 0.3619 accuracy: 0.9278 val_loss: 0.4814 val_accuracy: 0.8769
Epoch: 13 loss: 0.3469 accuracy: 0.9308 val_loss: 0.4874 val_accuracy: 0.8694
Epoch: 14 loss: 0.3354 accuracy: 0.9334 val_loss: 0.4442 val_accuracy: 0.8873
Epoch: 15 loss: 0.3200 accuracy: 0.9363 val_loss: 0.4538 val_accuracy: 0.8857
Epoch: 16 loss: 0.3057 accuracy: 0.9419 val_loss: 0.4341 val_accuracy: 0.8891
Epoch: 17 loss: 0.2973 accuracy: 0.9439 val_loss: 0.4264 val_accuracy: 0.8927
Epoch: 18 loss: 0.2917 accuracy: 0.9425 val_loss: 0.4151 val_accuracy: 0.8959
Epoch: 19 loss: 0.2794 accuracy: 0.9475 val_loss: 0.4131 val_accuracy: 0.8950
Epoch: 20 loss: 0.2684 accuracy: 0.9491 val_loss: 0.4169 val_accuracy: 0.8957
Epoch: 21 loss: 0.2607 accuracy: 0.9513 val_loss: 0.4030 val_accuracy: 0.8964
Epoch: 22 loss: 0.2530 accuracy: 0.9528 val_loss: 0.3864 val_accuracy: 0.9050
Epoch: 23 loss: 0.2532 accuracy: 0.9518 val_loss: 0.3977 val_accuracy: 0.8984
Epoch: 24 loss: 0.2397 accuracy: 0.9556 val_loss: 0.3972 val_accuracy: 0.8916
Epoch: 25 loss: 0.2330 accuracy: 0.9565 val_loss: 0.4265 val_accuracy: 0.8912
Epoch: 26 loss: 0.2298 accuracy: 0.9574 val_loss: 0.3810 val_accuracy: 0.9052
Epoch: 27 loss: 0.2255 accuracy: 0.9582 val_loss: 0.3942 val_accuracy: 0.8945
Epoch: 28 loss: 0.2230 accuracy: 0.9581 val_loss: 0.3765 val_accuracy: 0.9018
Epoch: 29 loss: 0.2167 accuracy: 0.9591 val_loss: 0.3614 val_accuracy: 0.9091
Epoch: 30 loss: 0.2114 accuracy: 0.9598 val_loss: 0.3768 val_accuracy: 0.9082
Epoch: 31 loss: 0.2072 accuracy: 0.9623 val_loss: 0.3626 val_accuracy: 0.9072
Epoch: 32 loss: 0.2017 accuracy: 0.9627 val_loss: 0.3681 val_accuracy: 0.9089
Epoch: 33 loss: 0.2015 accuracy: 0.9623 val_loss: 0.3732 val_accuracy: 0.9029
Epoch: 34 loss: 0.1990 accuracy: 0.9624 val_loss: 0.3489 val_accuracy: 0.9166
Epoch: 35 loss: 0.1942 accuracy: 0.9651 val_loss: 0.3503 val_accuracy: 0.9163
Epoch: 36 loss: 0.1893 accuracy: 0.9650 val_loss: 0.3489 val_accuracy: 0.9156
Epoch: 37 loss: 0.1869 accuracy: 0.9661 val_loss: 0.3588 val_accuracy: 0.9082
Epoch: 38 loss: 0.1813 accuracy: 0.9682 val_loss: 0.3412 val_accuracy: 0.9138
Epoch: 39 loss: 0.1817 accuracy: 0.9673 val_loss: 0.3402 val_accuracy: 0.9145
Epoch: 40 loss: 0.1787 accuracy: 0.9664 val_loss: 0.3492 val_accuracy: 0.9122
Epoch: 41 loss: 0.1793 accuracy: 0.9673 val_loss: 0.3478 val_accuracy: 0.9154
Epoch: 42 loss: 0.1753 accuracy: 0.9669 val_loss: 0.3449 val_accuracy: 0.9191
Epoch: 43 loss: 0.1721 accuracy: 0.9690 val_loss: 0.3454 val_accuracy: 0.9131
Epoch: 44 loss: 0.1681 accuracy: 0.9705 val_loss: 0.3357 val_accuracy: 0.9132
Epoch: 45 loss: 0.1649 accuracy: 0.9713 val_loss: 0.3413 val_accuracy: 0.9213
Epoch: 46 loss: 0.1658 accuracy: 0.9695 val_loss: 0.3613 val_accuracy: 0.9068
Epoch: 47 loss: 0.1667 accuracy: 0.9694 val_loss: 0.3412 val_accuracy: 0.9170
Epoch: 48 loss: 0.1628 accuracy: 0.9710 val_loss: 0.3330 val_accuracy: 0.9181
Epoch: 49 loss: 0.1614 accuracy: 0.9706 val_loss: 0.3881 val_accuracy: 0.8939
Epoch: 50 loss: 0.1600 accuracy: 0.9707 val_loss: 0.3545 val_accuracy: 0.9122
Epoch: 51 loss: 0.1563 accuracy: 0.9720 val_loss: 0.3373 val_accuracy: 0.9172
Epoch: 52 loss: 0.1530 accuracy: 0.9732 val_loss: 0.3647 val_accuracy: 0.9136
Epoch: 53 loss: 0.1572 accuracy: 0.9715 val_loss: 0.3530 val_accuracy: 0.9197

Epoch 00053: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 54 loss: 0.1385 accuracy: 0.9785 val_loss: 0.3325 val_accuracy: 0.9240
Epoch: 55 loss: 0.1382 accuracy: 0.9779 val_loss: 0.3159 val_accuracy: 0.9258
Epoch: 56 loss: 0.1313 accuracy: 0.9804 val_loss: 0.3156 val_accuracy: 0.9268
Epoch: 57 loss: 0.1352 accuracy: 0.9782 val_loss: 0.3146 val_accuracy: 0.9281
Epoch: 58 loss: 0.1380 accuracy: 0.9773 val_loss: 0.3318 val_accuracy: 0.9227
Epoch: 59 loss: 0.1314 accuracy: 0.9788 val_loss: 0.3254 val_accuracy: 0.9231
Epoch: 60 loss: 0.1312 accuracy: 0.9789 val_loss: 0.3289 val_accuracy: 0.9240
Epoch: 61 loss: 0.1261 accuracy: 0.9808 val_loss: 0.3193 val_accuracy: 0.9304
Epoch: 62 loss: 0.1293 accuracy: 0.9794 val_loss: 0.3305 val_accuracy: 0.9265

Epoch 00062: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 63 loss: 0.1187 accuracy: 0.9829 val_loss: 0.3176 val_accuracy: 0.9299
Epoch: 64 loss: 0.1172 accuracy: 0.9840 val_loss: 0.3137 val_accuracy: 0.9261
Epoch: 65 loss: 0.1153 accuracy: 0.9841 val_loss: 0.3142 val_accuracy: 0.9304
Epoch: 66 loss: 0.1120 accuracy: 0.9859 val_loss: 0.3228 val_accuracy: 0.9270
Epoch: 67 loss: 0.1119 accuracy: 0.9851 val_loss: 0.3453 val_accuracy: 0.9211
Epoch: 68 loss: 0.1103 accuracy: 0.9858 val_loss: 0.3290 val_accuracy: 0.9275
Epoch: 69 loss: 0.1129 accuracy: 0.9843 val_loss: 0.3108 val_accuracy: 0.9306
Epoch: 70 loss: 0.1114 accuracy: 0.9843 val_loss: 0.3163 val_accuracy: 0.9306
Epoch: 71 loss: 0.1098 accuracy: 0.9857 val_loss: 0.3207 val_accuracy: 0.9295
Epoch: 72 loss: 0.1100 accuracy: 0.9850 val_loss: 0.3186 val_accuracy: 0.9336
Epoch: 73 loss: 0.1047 accuracy: 0.9868 val_loss: 0.3199 val_accuracy: 0.9340
Epoch: 74 loss: 0.1052 accuracy: 0.9866 val_loss: 0.3344 val_accuracy: 0.9299

Epoch 00074: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 75 loss: 0.1004 accuracy: 0.9885 val_loss: 0.3291 val_accuracy: 0.9331
Epoch: 76 loss: 0.0975 accuracy: 0.9891 val_loss: 0.3370 val_accuracy: 0.9304
Epoch: 77 loss: 0.0981 accuracy: 0.9882 val_loss: 0.3146 val_accuracy: 0.9360
Epoch: 78 loss: 0.0979 accuracy: 0.9886 val_loss: 0.3288 val_accuracy: 0.9345
Epoch: 79 loss: 0.0974 accuracy: 0.9882 val_loss: 0.3298 val_accuracy: 0.9315

Epoch 00079: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
End of augmented training
Finish
Job ended!
