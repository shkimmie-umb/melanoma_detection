Fri 03 May 2024 12:50:09 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'ISIC2019', 'ISIC2020', 'PH2', '_7_point_criteria', 'PAD_UFES_20']
IMG_SIZE: [384, 384]
CLASSIFIER: EfficientNetB1
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 8 dbs
Combining 2th db out of 8 dbs
Combining 3th db out of 8 dbs
Combining 4th db out of 8 dbs
Combining 5th db out of 8 dbs
Combining 6th db out of 8 dbs
Combining 7th db out of 8 dbs
Combining 8th db out of 8 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb1 (Functional)  (None, 1280)              6575239   
_________________________________________________________________
dense (Dense)                (None, 512)               655872    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 7,366,025
Trainable params: 789,250
Non-trainable params: 6,576,775
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020+PH2+_7_point_criteria+PAD_UFES_20_aug_EfficientNetB1_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020+PH2+_7_point_criteria+PAD_UFES_20_aug_EfficientNetB1_384h_384w_None
Epoch: 1 loss: 1.0639 accuracy: 0.6725 val_loss: 0.7430 val_accuracy: 0.9082
Epoch: 2 loss: 0.9028 accuracy: 0.7244 val_loss: 0.6545 val_accuracy: 0.9082
Epoch: 3 loss: 0.8100 accuracy: 0.7277 val_loss: 0.6440 val_accuracy: 0.9082
Epoch: 4 loss: 0.7383 accuracy: 0.7246 val_loss: 0.5352 val_accuracy: 0.9082
Epoch: 5 loss: 0.6851 accuracy: 0.7252 val_loss: 0.5396 val_accuracy: 0.9082
Epoch: 6 loss: 0.6535 accuracy: 0.7242 val_loss: 0.4566 val_accuracy: 0.9082
Epoch: 7 loss: 0.6323 accuracy: 0.7268 val_loss: 0.4092 val_accuracy: 0.9082
Epoch: 8 loss: 0.6219 accuracy: 0.7261 val_loss: 0.4245 val_accuracy: 0.9082
Epoch: 9 loss: 0.6161 accuracy: 0.7242 val_loss: 0.4291 val_accuracy: 0.9082
Epoch: 10 loss: 0.6110 accuracy: 0.7245 val_loss: 0.4305 val_accuracy: 0.9082
Epoch: 11 loss: 0.6075 accuracy: 0.7248 val_loss: 0.3354 val_accuracy: 0.9082
Epoch: 12 loss: 0.6023 accuracy: 0.7272 val_loss: 0.4038 val_accuracy: 0.9082
Epoch: 13 loss: 0.6040 accuracy: 0.7227 val_loss: 0.4001 val_accuracy: 0.9082
Epoch: 14 loss: 0.6027 accuracy: 0.7226 val_loss: 0.4298 val_accuracy: 0.9082
Epoch: 15 loss: 0.5990 accuracy: 0.7248 val_loss: 0.4188 val_accuracy: 0.9082
Epoch: 16 loss: 0.5971 accuracy: 0.7253 val_loss: 0.4059 val_accuracy: 0.9082

Epoch 00016: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 17 loss: 0.5924 accuracy: 0.7287 val_loss: 0.4363 val_accuracy: 0.9082
Epoch: 18 loss: 0.5945 accuracy: 0.7258 val_loss: 0.4005 val_accuracy: 0.9082
Epoch: 19 loss: 0.5954 accuracy: 0.7244 val_loss: 0.4098 val_accuracy: 0.9082
Epoch: 20 loss: 0.5916 accuracy: 0.7279 val_loss: 0.4152 val_accuracy: 0.9082
Epoch: 21 loss: 0.5936 accuracy: 0.7256 val_loss: 0.4075 val_accuracy: 0.9082

Epoch 00021: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
End of augmented training
Finish
Job ended!
