Thu 09 May 2024 02:47:23 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'MEDNODE', 'KaggleMB']
IMG_SIZE: [384, 384]
CLASSIFIER: VGG16
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 5 dbs
Combining 2th db out of 5 dbs
Combining 3th db out of 5 dbs
Combining 4th db out of 5 dbs
Combining 5th db out of 5 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
vgg16 (Functional)           (None, 512)               14714688  
_________________________________________________________________
dense (Dense)                (None, 512)               262656    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 15,112,258
Trainable params: 396,034
Non-trainable params: 14,716,224
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+MEDNODE+KaggleMB_aug_VGG16_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+MEDNODE+KaggleMB_aug_VGG16_384h_384w_None
Epoch: 1 loss: 0.9454 accuracy: 0.7124 val_loss: 0.7931 val_accuracy: 0.7355
Epoch: 2 loss: 0.7334 accuracy: 0.7730 val_loss: 0.7447 val_accuracy: 0.7419
Epoch: 3 loss: 0.6753 accuracy: 0.7814 val_loss: 0.6950 val_accuracy: 0.7705
Epoch: 4 loss: 0.6294 accuracy: 0.7907 val_loss: 0.6764 val_accuracy: 0.7760
Epoch: 5 loss: 0.6117 accuracy: 0.7958 val_loss: 0.6303 val_accuracy: 0.7982
Epoch: 6 loss: 0.5882 accuracy: 0.8053 val_loss: 0.6164 val_accuracy: 0.7751
Epoch: 7 loss: 0.5739 accuracy: 0.8110 val_loss: 0.6525 val_accuracy: 0.7465
Epoch: 8 loss: 0.5616 accuracy: 0.8099 val_loss: 0.6018 val_accuracy: 0.7862
Epoch: 9 loss: 0.5462 accuracy: 0.8150 val_loss: 0.6091 val_accuracy: 0.7917
Epoch: 10 loss: 0.5323 accuracy: 0.8254 val_loss: 0.5942 val_accuracy: 0.7751
Epoch: 11 loss: 0.5290 accuracy: 0.8212 val_loss: 0.5812 val_accuracy: 0.7889
Epoch: 12 loss: 0.5158 accuracy: 0.8236 val_loss: 0.5559 val_accuracy: 0.8046
Epoch: 13 loss: 0.5112 accuracy: 0.8248 val_loss: 0.5557 val_accuracy: 0.7972
Epoch: 14 loss: 0.4902 accuracy: 0.8342 val_loss: 0.5838 val_accuracy: 0.7991
Epoch: 15 loss: 0.4849 accuracy: 0.8334 val_loss: 0.5361 val_accuracy: 0.7991
Epoch: 16 loss: 0.4858 accuracy: 0.8323 val_loss: 0.5839 val_accuracy: 0.7834
Epoch: 17 loss: 0.4767 accuracy: 0.8353 val_loss: 0.6288 val_accuracy: 0.7456
Epoch: 18 loss: 0.4697 accuracy: 0.8375 val_loss: 0.5152 val_accuracy: 0.8129
Epoch: 19 loss: 0.4639 accuracy: 0.8394 val_loss: 0.5713 val_accuracy: 0.7834
Epoch: 20 loss: 0.4515 accuracy: 0.8471 val_loss: 0.5208 val_accuracy: 0.7945
Epoch: 21 loss: 0.4555 accuracy: 0.8357 val_loss: 0.5345 val_accuracy: 0.7972
Epoch: 22 loss: 0.4488 accuracy: 0.8409 val_loss: 0.5213 val_accuracy: 0.8009
Epoch: 23 loss: 0.4423 accuracy: 0.8444 val_loss: 0.5128 val_accuracy: 0.7991
Epoch: 24 loss: 0.4392 accuracy: 0.8419 val_loss: 0.5218 val_accuracy: 0.8046
Epoch: 25 loss: 0.4274 accuracy: 0.8478 val_loss: 0.4990 val_accuracy: 0.8120
Epoch: 26 loss: 0.4225 accuracy: 0.8499 val_loss: 0.5027 val_accuracy: 0.8028
Epoch: 27 loss: 0.4171 accuracy: 0.8494 val_loss: 0.4940 val_accuracy: 0.8046
Epoch: 28 loss: 0.4165 accuracy: 0.8487 val_loss: 0.4931 val_accuracy: 0.8046
Epoch: 29 loss: 0.4093 accuracy: 0.8489 val_loss: 0.4944 val_accuracy: 0.8184
Epoch: 30 loss: 0.4116 accuracy: 0.8493 val_loss: 0.4777 val_accuracy: 0.8166
Epoch: 31 loss: 0.3962 accuracy: 0.8573 val_loss: 0.4702 val_accuracy: 0.8175
Epoch: 32 loss: 0.3998 accuracy: 0.8531 val_loss: 0.4761 val_accuracy: 0.8129
Epoch: 33 loss: 0.3901 accuracy: 0.8561 val_loss: 0.5067 val_accuracy: 0.7972
Epoch: 34 loss: 0.3879 accuracy: 0.8566 val_loss: 0.4784 val_accuracy: 0.8101
Epoch: 35 loss: 0.3906 accuracy: 0.8554 val_loss: 0.4785 val_accuracy: 0.8092
Epoch: 36 loss: 0.3804 accuracy: 0.8613 val_loss: 0.5188 val_accuracy: 0.7797

Epoch 00036: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 37 loss: 0.3676 accuracy: 0.8639 val_loss: 0.4838 val_accuracy: 0.8083
Epoch: 38 loss: 0.3671 accuracy: 0.8649 val_loss: 0.4610 val_accuracy: 0.8249
Epoch: 39 loss: 0.3568 accuracy: 0.8700 val_loss: 0.4666 val_accuracy: 0.8111
Epoch: 40 loss: 0.3648 accuracy: 0.8660 val_loss: 0.5090 val_accuracy: 0.8000
Epoch: 41 loss: 0.3605 accuracy: 0.8674 val_loss: 0.4693 val_accuracy: 0.8055
Epoch: 42 loss: 0.3498 accuracy: 0.8720 val_loss: 0.4591 val_accuracy: 0.8184
Epoch: 43 loss: 0.3505 accuracy: 0.8737 val_loss: 0.4584 val_accuracy: 0.8313
Epoch: 44 loss: 0.3508 accuracy: 0.8687 val_loss: 0.4646 val_accuracy: 0.8249
Epoch: 45 loss: 0.3526 accuracy: 0.8694 val_loss: 0.4737 val_accuracy: 0.8194
Epoch: 46 loss: 0.3471 accuracy: 0.8709 val_loss: 0.4555 val_accuracy: 0.8203
Epoch: 47 loss: 0.3466 accuracy: 0.8707 val_loss: 0.4571 val_accuracy: 0.8166
Epoch: 48 loss: 0.3412 accuracy: 0.8720 val_loss: 0.4728 val_accuracy: 0.8129
Epoch: 49 loss: 0.3453 accuracy: 0.8701 val_loss: 0.4983 val_accuracy: 0.8037
Epoch: 50 loss: 0.3422 accuracy: 0.8711 val_loss: 0.4545 val_accuracy: 0.8276
Epoch: 51 loss: 0.3335 accuracy: 0.8761 val_loss: 0.4467 val_accuracy: 0.8267
Epoch: 52 loss: 0.3285 accuracy: 0.8762 val_loss: 0.4561 val_accuracy: 0.8138
Epoch: 53 loss: 0.3311 accuracy: 0.8761 val_loss: 0.4323 val_accuracy: 0.8295
Epoch: 54 loss: 0.3266 accuracy: 0.8793 val_loss: 0.4485 val_accuracy: 0.8212
Epoch: 55 loss: 0.3258 accuracy: 0.8785 val_loss: 0.4595 val_accuracy: 0.8074
Epoch: 56 loss: 0.3196 accuracy: 0.8815 val_loss: 0.4510 val_accuracy: 0.8304
Epoch: 57 loss: 0.3234 accuracy: 0.8807 val_loss: 0.4665 val_accuracy: 0.8184
Epoch: 58 loss: 0.3172 accuracy: 0.8845 val_loss: 0.4737 val_accuracy: 0.8276

Epoch 00058: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 59 loss: 0.3252 accuracy: 0.8772 val_loss: 0.4499 val_accuracy: 0.8138
Epoch: 60 loss: 0.3058 accuracy: 0.8872 val_loss: 0.4422 val_accuracy: 0.8230
Epoch: 61 loss: 0.3087 accuracy: 0.8867 val_loss: 0.4534 val_accuracy: 0.8249
Epoch: 62 loss: 0.3119 accuracy: 0.8844 val_loss: 0.4469 val_accuracy: 0.8175
Epoch: 63 loss: 0.2995 accuracy: 0.8891 val_loss: 0.4487 val_accuracy: 0.8295

Epoch 00063: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
End of augmented training
Finish
Job ended!
