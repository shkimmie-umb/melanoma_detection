Thu 09 May 2024 10:21:07 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2018', 'ISIC2019']
IMG_SIZE: [384, 384]
CLASSIFIER: Xception
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 3 dbs
Combining 2th db out of 3 dbs
Combining 3th db out of 3 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
xception (Functional)        (None, 2048)              20861480  
_________________________________________________________________
dense (Dense)                (None, 512)               1049088   
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 22,045,482
Trainable params: 1,182,466
Non-trainable params: 20,863,016
_________________________________________________________________
Fitting ISIC2016+ISIC2018+ISIC2019_aug_Xception_384h_384w_None model...
model_name: ISIC2016+ISIC2018+ISIC2019_aug_Xception_384h_384w_None
Epoch: 1 loss: 0.9949 accuracy: 0.8017 val_loss: 0.9444 val_accuracy: 0.8169
Epoch: 2 loss: 0.8416 accuracy: 0.8525 val_loss: 0.8907 val_accuracy: 0.8219
Epoch: 3 loss: 0.7635 accuracy: 0.8719 val_loss: 0.8367 val_accuracy: 0.8294
Epoch: 4 loss: 0.7007 accuracy: 0.8854 val_loss: 0.8147 val_accuracy: 0.8272
Epoch: 5 loss: 0.6432 accuracy: 0.8981 val_loss: 0.7732 val_accuracy: 0.8338
Epoch: 6 loss: 0.5984 accuracy: 0.9066 val_loss: 0.7050 val_accuracy: 0.8610
Epoch: 7 loss: 0.5539 accuracy: 0.9155 val_loss: 0.6913 val_accuracy: 0.8555
Epoch: 8 loss: 0.5250 accuracy: 0.9188 val_loss: 0.6619 val_accuracy: 0.8665
Epoch: 9 loss: 0.4933 accuracy: 0.9244 val_loss: 0.6336 val_accuracy: 0.8603
Epoch: 10 loss: 0.4641 accuracy: 0.9297 val_loss: 0.6708 val_accuracy: 0.8406
Epoch: 11 loss: 0.4431 accuracy: 0.9315 val_loss: 0.5900 val_accuracy: 0.8739
Epoch: 12 loss: 0.4188 accuracy: 0.9362 val_loss: 0.6089 val_accuracy: 0.8669
Epoch: 13 loss: 0.3982 accuracy: 0.9397 val_loss: 0.5840 val_accuracy: 0.8653
Epoch: 14 loss: 0.3788 accuracy: 0.9418 val_loss: 0.5708 val_accuracy: 0.8754
Epoch: 15 loss: 0.3625 accuracy: 0.9445 val_loss: 0.5708 val_accuracy: 0.8693
Epoch: 16 loss: 0.3517 accuracy: 0.9441 val_loss: 0.5492 val_accuracy: 0.8756
Epoch: 17 loss: 0.3357 accuracy: 0.9471 val_loss: 0.5315 val_accuracy: 0.8853
Epoch: 18 loss: 0.3201 accuracy: 0.9501 val_loss: 0.5045 val_accuracy: 0.8926
Epoch: 19 loss: 0.3118 accuracy: 0.9510 val_loss: 0.5173 val_accuracy: 0.8836
Epoch: 20 loss: 0.2942 accuracy: 0.9548 val_loss: 0.5062 val_accuracy: 0.8910
Epoch: 21 loss: 0.2804 accuracy: 0.9579 val_loss: 0.5030 val_accuracy: 0.8928
Epoch: 22 loss: 0.2715 accuracy: 0.9589 val_loss: 0.5096 val_accuracy: 0.8893
Epoch: 23 loss: 0.2650 accuracy: 0.9582 val_loss: 0.4785 val_accuracy: 0.8980
Epoch: 24 loss: 0.2594 accuracy: 0.9592 val_loss: 0.4756 val_accuracy: 0.8963
Epoch: 25 loss: 0.2486 accuracy: 0.9621 val_loss: 0.5120 val_accuracy: 0.8869
Epoch: 26 loss: 0.2528 accuracy: 0.9588 val_loss: 0.4943 val_accuracy: 0.8844
Epoch: 27 loss: 0.2365 accuracy: 0.9634 val_loss: 0.4818 val_accuracy: 0.8917
Epoch: 28 loss: 0.2348 accuracy: 0.9625 val_loss: 0.4816 val_accuracy: 0.8934
Epoch: 29 loss: 0.2296 accuracy: 0.9637 val_loss: 0.4783 val_accuracy: 0.8914

Epoch 00029: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 30 loss: 0.2101 accuracy: 0.9691 val_loss: 0.4596 val_accuracy: 0.9004
Epoch: 31 loss: 0.1998 accuracy: 0.9727 val_loss: 0.5077 val_accuracy: 0.8914
Epoch: 32 loss: 0.1939 accuracy: 0.9737 val_loss: 0.4890 val_accuracy: 0.8996
Epoch: 33 loss: 0.1906 accuracy: 0.9733 val_loss: 0.4636 val_accuracy: 0.9011
Epoch: 34 loss: 0.1836 accuracy: 0.9754 val_loss: 0.4656 val_accuracy: 0.9007
Epoch: 35 loss: 0.1845 accuracy: 0.9741 val_loss: 0.4656 val_accuracy: 0.9039

Epoch 00035: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 36 loss: 0.1668 accuracy: 0.9800 val_loss: 0.4521 val_accuracy: 0.9167
Epoch: 37 loss: 0.1630 accuracy: 0.9807 val_loss: 0.4725 val_accuracy: 0.8961
Epoch: 38 loss: 0.1602 accuracy: 0.9805 val_loss: 0.4642 val_accuracy: 0.9119
Epoch: 39 loss: 0.1587 accuracy: 0.9807 val_loss: 0.4709 val_accuracy: 0.9057
Epoch: 40 loss: 0.1578 accuracy: 0.9805 val_loss: 0.5046 val_accuracy: 0.8904
Epoch: 41 loss: 0.1551 accuracy: 0.9804 val_loss: 0.4666 val_accuracy: 0.9042

Epoch 00041: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 42 loss: 0.1425 accuracy: 0.9850 val_loss: 0.4682 val_accuracy: 0.9083
Epoch: 43 loss: 0.1394 accuracy: 0.9856 val_loss: 0.4939 val_accuracy: 0.9031
Epoch: 44 loss: 0.1363 accuracy: 0.9857 val_loss: 0.5124 val_accuracy: 0.8928
Epoch: 45 loss: 0.1342 accuracy: 0.9863 val_loss: 0.4837 val_accuracy: 0.9053
Epoch: 46 loss: 0.1309 accuracy: 0.9871 val_loss: 0.4756 val_accuracy: 0.9059

Epoch 00046: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
End of augmented training
Finish
Job ended!
