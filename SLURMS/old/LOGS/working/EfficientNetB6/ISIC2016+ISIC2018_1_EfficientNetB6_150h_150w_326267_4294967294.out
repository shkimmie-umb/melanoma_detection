Fri 01 Mar 2024 12:28:56 PM EST
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2018']
IMG_SIZE: [150, 150]
CLASSIFIER: EfficientNetB6
SELF_AUG: 1
JOB_INDEX: None
Combining...
Combining 1 db out of 2 dbs
Combining 2 db out of 2 dbs
Stacking training images
Stacking training labels
Stacking validation images
Stacking validation labels
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb6 (Functional)  (None, 2304)              40960143  
_________________________________________________________________
dense (Dense)                (None, 512)               1180160   
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 42,275,217
Trainable params: 1,313,538
Non-trainable params: 40,961,679
_________________________________________________________________
Fitting ISIC2016+ISIC2018_aug_EfficientNetB6_150h_150w_None model...
model_name: ISIC2016+ISIC2018_aug_EfficientNetB6_150h_150w_None
Epoch: 1 loss: 0.6092 accuracy: 0.7288 val_loss: 0.3624 val_accuracy: 0.8418
Epoch: 2 loss: 0.4837 accuracy: 0.7881 val_loss: 0.3604 val_accuracy: 0.8525
Epoch: 3 loss: 0.4392 accuracy: 0.8085 val_loss: 0.3587 val_accuracy: 0.8579
Epoch: 4 loss: 0.4225 accuracy: 0.8144 val_loss: 0.3425 val_accuracy: 0.8552
Epoch: 5 loss: 0.4101 accuracy: 0.8170 val_loss: 0.3256 val_accuracy: 0.8579
Epoch: 6 loss: 0.4029 accuracy: 0.8218 val_loss: 0.3492 val_accuracy: 0.8525
Epoch: 7 loss: 0.3933 accuracy: 0.8218 val_loss: 0.3420 val_accuracy: 0.8633
Epoch: 8 loss: 0.3801 accuracy: 0.8292 val_loss: 0.3442 val_accuracy: 0.8633
Epoch: 9 loss: 0.3651 accuracy: 0.8394 val_loss: 0.3483 val_accuracy: 0.8499
Epoch: 10 loss: 0.3653 accuracy: 0.8369 val_loss: 0.3488 val_accuracy: 0.8445
Epoch: 11 loss: 0.3615 accuracy: 0.8424 val_loss: 0.3493 val_accuracy: 0.8418
Epoch: 12 loss: 0.3520 accuracy: 0.8429 val_loss: 0.3558 val_accuracy: 0.8472
Epoch: 13 loss: 0.3465 accuracy: 0.8472 val_loss: 0.3433 val_accuracy: 0.8552
Epoch: 14 loss: 0.3412 accuracy: 0.8500 val_loss: 0.3487 val_accuracy: 0.8525
Epoch: 15 loss: 0.3432 accuracy: 0.8480 val_loss: 0.3459 val_accuracy: 0.8472
Epoch: 16 loss: 0.3388 accuracy: 0.8514 val_loss: 0.3467 val_accuracy: 0.8472
Epoch: 17 loss: 0.3322 accuracy: 0.8547 val_loss: 0.3368 val_accuracy: 0.8525
Epoch: 18 loss: 0.3278 accuracy: 0.8571 val_loss: 0.3541 val_accuracy: 0.8418
Epoch: 19 loss: 0.3257 accuracy: 0.8597 val_loss: 0.3561 val_accuracy: 0.8445
Epoch: 20 loss: 0.3258 accuracy: 0.8582 val_loss: 0.3729 val_accuracy: 0.8525
Job ended!
