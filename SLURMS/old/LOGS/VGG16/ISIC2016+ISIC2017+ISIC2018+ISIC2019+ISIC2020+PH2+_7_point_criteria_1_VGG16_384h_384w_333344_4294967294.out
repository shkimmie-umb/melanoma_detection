Wed 08 May 2024 11:15:18 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'ISIC2019', 'ISIC2020', 'PH2', '_7_point_criteria']
IMG_SIZE: [384, 384]
CLASSIFIER: VGG16
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 7 dbs
Combining 2th db out of 7 dbs
Combining 3th db out of 7 dbs
Combining 4th db out of 7 dbs
Combining 5th db out of 7 dbs
Combining 6th db out of 7 dbs
Combining 7th db out of 7 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
vgg16 (Functional)           (None, 512)               14714688  
_________________________________________________________________
dense (Dense)                (None, 512)               262656    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 15,112,258
Trainable params: 396,034
Non-trainable params: 14,716,224
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020+PH2+_7_point_criteria_aug_VGG16_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020+PH2+_7_point_criteria_aug_VGG16_384h_384w_None
Epoch: 1 loss: 0.7373 accuracy: 0.7749 val_loss: 0.4641 val_accuracy: 0.8939
Epoch: 2 loss: 0.5622 accuracy: 0.8247 val_loss: 0.4319 val_accuracy: 0.8932
Epoch: 3 loss: 0.5140 accuracy: 0.8371 val_loss: 0.4563 val_accuracy: 0.8603
Epoch: 4 loss: 0.4807 accuracy: 0.8434 val_loss: 0.3961 val_accuracy: 0.8841
Epoch: 5 loss: 0.4503 accuracy: 0.8494 val_loss: 0.4151 val_accuracy: 0.8606
Epoch: 6 loss: 0.4331 accuracy: 0.8516 val_loss: 0.3883 val_accuracy: 0.8720
Epoch: 7 loss: 0.4133 accuracy: 0.8544 val_loss: 0.4420 val_accuracy: 0.8351
Epoch: 8 loss: 0.3938 accuracy: 0.8588 val_loss: 0.3306 val_accuracy: 0.8987
Epoch: 9 loss: 0.3886 accuracy: 0.8581 val_loss: 0.3417 val_accuracy: 0.8832
Epoch: 10 loss: 0.3725 accuracy: 0.8612 val_loss: 0.3504 val_accuracy: 0.8749
Epoch: 11 loss: 0.3597 accuracy: 0.8662 val_loss: 0.3716 val_accuracy: 0.8630
Epoch: 12 loss: 0.3567 accuracy: 0.8650 val_loss: 0.3479 val_accuracy: 0.8754
Epoch: 13 loss: 0.3495 accuracy: 0.8670 val_loss: 0.3314 val_accuracy: 0.8762

Epoch 00013: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 14 loss: 0.3425 accuracy: 0.8698 val_loss: 0.3387 val_accuracy: 0.8729
Epoch: 15 loss: 0.3347 accuracy: 0.8722 val_loss: 0.3439 val_accuracy: 0.8659
Epoch: 16 loss: 0.3284 accuracy: 0.8738 val_loss: 0.3049 val_accuracy: 0.8915
Epoch: 17 loss: 0.3218 accuracy: 0.8761 val_loss: 0.3012 val_accuracy: 0.8932
Epoch: 18 loss: 0.3196 accuracy: 0.8783 val_loss: 0.3428 val_accuracy: 0.8673
Epoch: 19 loss: 0.3177 accuracy: 0.8782 val_loss: 0.3079 val_accuracy: 0.8886
Epoch: 20 loss: 0.3132 accuracy: 0.8803 val_loss: 0.3113 val_accuracy: 0.8826
Epoch: 21 loss: 0.3124 accuracy: 0.8794 val_loss: 0.3269 val_accuracy: 0.8726
Epoch: 22 loss: 0.3095 accuracy: 0.8806 val_loss: 0.3655 val_accuracy: 0.8527

Epoch 00022: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 23 loss: 0.2989 accuracy: 0.8856 val_loss: 0.2964 val_accuracy: 0.8961
Epoch: 24 loss: 0.3003 accuracy: 0.8855 val_loss: 0.3048 val_accuracy: 0.8885
Epoch: 25 loss: 0.2957 accuracy: 0.8869 val_loss: 0.2914 val_accuracy: 0.8955
Epoch: 26 loss: 0.2934 accuracy: 0.8880 val_loss: 0.3063 val_accuracy: 0.8849
Epoch: 27 loss: 0.2924 accuracy: 0.8896 val_loss: 0.3189 val_accuracy: 0.8788
Epoch: 28 loss: 0.2873 accuracy: 0.8909 val_loss: 0.3154 val_accuracy: 0.8799
Epoch: 29 loss: 0.2922 accuracy: 0.8877 val_loss: 0.3226 val_accuracy: 0.8767
Epoch: 30 loss: 0.2877 accuracy: 0.8898 val_loss: 0.2854 val_accuracy: 0.8964
Epoch: 31 loss: 0.2849 accuracy: 0.8911 val_loss: 0.2821 val_accuracy: 0.8967
Epoch: 32 loss: 0.2841 accuracy: 0.8908 val_loss: 0.3051 val_accuracy: 0.8847
Epoch: 33 loss: 0.2825 accuracy: 0.8911 val_loss: 0.2760 val_accuracy: 0.9009
Epoch: 34 loss: 0.2757 accuracy: 0.8950 val_loss: 0.3277 val_accuracy: 0.8730
Epoch: 35 loss: 0.2776 accuracy: 0.8951 val_loss: 0.3193 val_accuracy: 0.8750
Epoch: 36 loss: 0.2760 accuracy: 0.8953 val_loss: 0.2826 val_accuracy: 0.8971
Epoch: 37 loss: 0.2753 accuracy: 0.8955 val_loss: 0.2655 val_accuracy: 0.9084
Epoch: 38 loss: 0.2744 accuracy: 0.8950 val_loss: 0.2816 val_accuracy: 0.8970
Epoch: 39 loss: 0.2739 accuracy: 0.8958 val_loss: 0.2902 val_accuracy: 0.8936
Epoch: 40 loss: 0.2676 accuracy: 0.8988 val_loss: 0.3204 val_accuracy: 0.8754
Epoch: 41 loss: 0.2714 accuracy: 0.8978 val_loss: 0.3008 val_accuracy: 0.8861
Epoch: 42 loss: 0.2666 accuracy: 0.8988 val_loss: 0.2833 val_accuracy: 0.8947

Epoch 00042: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 43 loss: 0.2615 accuracy: 0.9015 val_loss: 0.2921 val_accuracy: 0.8912
Epoch: 44 loss: 0.2600 accuracy: 0.9022 val_loss: 0.2773 val_accuracy: 0.8995
Epoch: 45 loss: 0.2585 accuracy: 0.9037 val_loss: 0.2791 val_accuracy: 0.8974
Epoch: 46 loss: 0.2620 accuracy: 0.9008 val_loss: 0.2779 val_accuracy: 0.8985
Epoch: 47 loss: 0.2544 accuracy: 0.9047 val_loss: 0.2894 val_accuracy: 0.8912

Epoch 00047: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
End of augmented training
Finish
Job ended!
