Tue 27 Feb 2024 11:45:08 AM EST
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2018']
IMG_SIZE: [150, 150]
CLASSIFIER: EfficientNetB4
SELF_AUG: 1
JOB_INDEX: None
Combining...
Combining 1 db out of 2 dbs
Combining 2 db out of 2 dbs
Stacking training images
Stacking training labels
Stacking validation images
Stacking validation labels
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb4 (Functional)  (None, 1792)              17673823  
_________________________________________________________________
dense (Dense)                (None, 512)               918016    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 18,726,753
Trainable params: 1,051,394
Non-trainable params: 17,675,359
_________________________________________________________________
Fitting ISIC2016+ISIC2018_aug_EfficientNetB4_150h_150w_None model...
model_name: ISIC2016+ISIC2018_aug_EfficientNetB4_150h_150w_None
Epoch: 1 loss: 0.6246 accuracy: 0.6847 val_loss: 0.4955 val_accuracy: 0.8472
Epoch: 2 loss: 0.5911 accuracy: 0.7186 val_loss: 0.4794 val_accuracy: 0.8472
Epoch: 3 loss: 0.5832 accuracy: 0.7190 val_loss: 0.4296 val_accuracy: 0.8472
Epoch: 4 loss: 0.5807 accuracy: 0.7187 val_loss: 0.4553 val_accuracy: 0.8472
Epoch: 5 loss: 0.5794 accuracy: 0.7198 val_loss: 0.4321 val_accuracy: 0.8472
Epoch: 6 loss: 0.5770 accuracy: 0.7206 val_loss: 0.5202 val_accuracy: 0.8499
Epoch: 7 loss: 0.5756 accuracy: 0.7232 val_loss: 0.4651 val_accuracy: 0.8472
Epoch: 8 loss: 0.5735 accuracy: 0.7240 val_loss: 0.4471 val_accuracy: 0.8472
Epoch: 9 loss: 0.5719 accuracy: 0.7247 val_loss: 0.4452 val_accuracy: 0.8472
Epoch: 10 loss: 0.5706 accuracy: 0.7251 val_loss: 0.5078 val_accuracy: 0.8391
Epoch: 11 loss: 0.5683 accuracy: 0.7289 val_loss: 0.4370 val_accuracy: 0.8472
Epoch: 12 loss: 0.5694 accuracy: 0.7275 val_loss: 0.4157 val_accuracy: 0.8472
Epoch: 13 loss: 0.5670 accuracy: 0.7286 val_loss: 0.4578 val_accuracy: 0.8499
Epoch: 14 loss: 0.5659 accuracy: 0.7305 val_loss: 0.4710 val_accuracy: 0.8472
Epoch: 15 loss: 0.5695 accuracy: 0.7297 val_loss: 0.4223 val_accuracy: 0.8472
Epoch: 16 loss: 0.5670 accuracy: 0.7312 val_loss: 0.4954 val_accuracy: 0.8445
Epoch: 17 loss: 0.5681 accuracy: 0.7309 val_loss: 0.4970 val_accuracy: 0.8445
Epoch: 18 loss: 0.5685 accuracy: 0.7318 val_loss: 0.5531 val_accuracy: 0.7775
Epoch: 19 loss: 0.5686 accuracy: 0.7309 val_loss: 0.4502 val_accuracy: 0.8445
Epoch: 20 loss: 0.5662 accuracy: 0.7331 val_loss: 0.4680 val_accuracy: 0.8418
Job ended!
