Thu 02 May 2024 05:29:47 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2018', 'ISIC2019']
IMG_SIZE: [384, 384]
CLASSIFIER: DenseNet121
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 3 dbs
Combining 2th db out of 3 dbs
Combining 3th db out of 3 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
densenet121 (Functional)     (None, 1024)              7037504   
_________________________________________________________________
dense (Dense)                (None, 512)               524800    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 7,697,218
Trainable params: 658,178
Non-trainable params: 7,039,040
_________________________________________________________________
Fitting ISIC2016+ISIC2018+ISIC2019_aug_DenseNet121_384h_384w_None model...
model_name: ISIC2016+ISIC2018+ISIC2019_aug_DenseNet121_384h_384w_None
Epoch: 1 loss: 0.8438 accuracy: 0.7987 val_loss: 0.7324 val_accuracy: 0.8316
Epoch: 2 loss: 0.6576 accuracy: 0.8530 val_loss: 0.6816 val_accuracy: 0.8432
Epoch: 3 loss: 0.6064 accuracy: 0.8659 val_loss: 0.6596 val_accuracy: 0.8349
Epoch: 4 loss: 0.5642 accuracy: 0.8772 val_loss: 0.6103 val_accuracy: 0.8548
Epoch: 5 loss: 0.5254 accuracy: 0.8878 val_loss: 0.6034 val_accuracy: 0.8487
Epoch: 6 loss: 0.4971 accuracy: 0.8955 val_loss: 0.5757 val_accuracy: 0.8564
Epoch: 7 loss: 0.4666 accuracy: 0.9038 val_loss: 0.5651 val_accuracy: 0.8564
Epoch: 8 loss: 0.4456 accuracy: 0.9076 val_loss: 0.5337 val_accuracy: 0.8693
Epoch: 9 loss: 0.4258 accuracy: 0.9120 val_loss: 0.5273 val_accuracy: 0.8702
Epoch: 10 loss: 0.4039 accuracy: 0.9179 val_loss: 0.5206 val_accuracy: 0.8645
Epoch: 11 loss: 0.3863 accuracy: 0.9221 val_loss: 0.5136 val_accuracy: 0.8691
Epoch: 12 loss: 0.3716 accuracy: 0.9241 val_loss: 0.5133 val_accuracy: 0.8640
Epoch: 13 loss: 0.3532 accuracy: 0.9295 val_loss: 0.4739 val_accuracy: 0.8765
Epoch: 14 loss: 0.3453 accuracy: 0.9308 val_loss: 0.4556 val_accuracy: 0.8846
Epoch: 15 loss: 0.3276 accuracy: 0.9346 val_loss: 0.4815 val_accuracy: 0.8699
Epoch: 16 loss: 0.3157 accuracy: 0.9381 val_loss: 0.4499 val_accuracy: 0.8869
Epoch: 17 loss: 0.3060 accuracy: 0.9389 val_loss: 0.4520 val_accuracy: 0.8816
Epoch: 18 loss: 0.2962 accuracy: 0.9424 val_loss: 0.4381 val_accuracy: 0.8862
Epoch: 19 loss: 0.2865 accuracy: 0.9440 val_loss: 0.4238 val_accuracy: 0.8914
Epoch: 20 loss: 0.2758 accuracy: 0.9458 val_loss: 0.4249 val_accuracy: 0.8899
Epoch: 21 loss: 0.2625 accuracy: 0.9515 val_loss: 0.4147 val_accuracy: 0.8928
Epoch: 22 loss: 0.2597 accuracy: 0.9508 val_loss: 0.4235 val_accuracy: 0.8846
Epoch: 23 loss: 0.2496 accuracy: 0.9527 val_loss: 0.4298 val_accuracy: 0.8862
Epoch: 24 loss: 0.2441 accuracy: 0.9545 val_loss: 0.4104 val_accuracy: 0.8939
Epoch: 25 loss: 0.2407 accuracy: 0.9536 val_loss: 0.4272 val_accuracy: 0.8910
Epoch: 26 loss: 0.2308 accuracy: 0.9580 val_loss: 0.3901 val_accuracy: 0.8993
Epoch: 27 loss: 0.2266 accuracy: 0.9584 val_loss: 0.4045 val_accuracy: 0.8945
Epoch: 28 loss: 0.2229 accuracy: 0.9592 val_loss: 0.3803 val_accuracy: 0.9062
Epoch: 29 loss: 0.2194 accuracy: 0.9594 val_loss: 0.3991 val_accuracy: 0.8983
Epoch: 30 loss: 0.2185 accuracy: 0.9588 val_loss: 0.4012 val_accuracy: 0.8939
Epoch: 31 loss: 0.2098 accuracy: 0.9613 val_loss: 0.4352 val_accuracy: 0.8798
Epoch: 32 loss: 0.2122 accuracy: 0.9598 val_loss: 0.3872 val_accuracy: 0.9031
Epoch: 33 loss: 0.1991 accuracy: 0.9652 val_loss: 0.3981 val_accuracy: 0.8978

Epoch 00033: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 34 loss: 0.1858 accuracy: 0.9702 val_loss: 0.3854 val_accuracy: 0.9057
Epoch: 35 loss: 0.1836 accuracy: 0.9694 val_loss: 0.3827 val_accuracy: 0.9131
Epoch: 36 loss: 0.1776 accuracy: 0.9709 val_loss: 0.3978 val_accuracy: 0.9000
Epoch: 37 loss: 0.1716 accuracy: 0.9732 val_loss: 0.3847 val_accuracy: 0.9077
Epoch: 38 loss: 0.1705 accuracy: 0.9734 val_loss: 0.3764 val_accuracy: 0.9075
Epoch: 39 loss: 0.1699 accuracy: 0.9725 val_loss: 0.4103 val_accuracy: 0.8982
Epoch: 40 loss: 0.1679 accuracy: 0.9739 val_loss: 0.4109 val_accuracy: 0.8978
Epoch: 41 loss: 0.1646 accuracy: 0.9737 val_loss: 0.3669 val_accuracy: 0.9145
Epoch: 42 loss: 0.1640 accuracy: 0.9733 val_loss: 0.3797 val_accuracy: 0.9081
Epoch: 43 loss: 0.1569 accuracy: 0.9757 val_loss: 0.3764 val_accuracy: 0.9127
Epoch: 44 loss: 0.1553 accuracy: 0.9760 val_loss: 0.3752 val_accuracy: 0.9149
Epoch: 45 loss: 0.1578 accuracy: 0.9750 val_loss: 0.4015 val_accuracy: 0.9051
Epoch: 46 loss: 0.1570 accuracy: 0.9756 val_loss: 0.3982 val_accuracy: 0.9040

Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 47 loss: 0.1473 accuracy: 0.9783 val_loss: 0.3890 val_accuracy: 0.9083
Epoch: 48 loss: 0.1412 accuracy: 0.9808 val_loss: 0.3631 val_accuracy: 0.9189
Epoch: 49 loss: 0.1387 accuracy: 0.9815 val_loss: 0.3650 val_accuracy: 0.9123
Epoch: 50 loss: 0.1351 accuracy: 0.9818 val_loss: 0.3715 val_accuracy: 0.9129
Epoch: 51 loss: 0.1380 accuracy: 0.9817 val_loss: 0.3667 val_accuracy: 0.9191
Epoch: 52 loss: 0.1359 accuracy: 0.9814 val_loss: 0.3602 val_accuracy: 0.9169
Epoch: 53 loss: 0.1339 accuracy: 0.9819 val_loss: 0.3785 val_accuracy: 0.9085
Epoch: 54 loss: 0.1344 accuracy: 0.9810 val_loss: 0.3891 val_accuracy: 0.9081
Epoch: 55 loss: 0.1313 accuracy: 0.9823 val_loss: 0.3657 val_accuracy: 0.9132
Epoch: 56 loss: 0.1305 accuracy: 0.9819 val_loss: 0.3825 val_accuracy: 0.9165
Epoch: 57 loss: 0.1253 accuracy: 0.9838 val_loss: 0.3707 val_accuracy: 0.9173

Epoch 00057: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 58 loss: 0.1187 accuracy: 0.9864 val_loss: 0.3645 val_accuracy: 0.9187
Epoch: 59 loss: 0.1200 accuracy: 0.9859 val_loss: 0.3550 val_accuracy: 0.9195
Epoch: 60 loss: 0.1163 accuracy: 0.9868 val_loss: 0.3575 val_accuracy: 0.9206
Epoch: 61 loss: 0.1168 accuracy: 0.9863 val_loss: 0.3776 val_accuracy: 0.9208
Epoch: 62 loss: 0.1151 accuracy: 0.9865 val_loss: 0.3810 val_accuracy: 0.9184
Epoch: 63 loss: 0.1134 accuracy: 0.9872 val_loss: 0.3688 val_accuracy: 0.9241
Epoch: 64 loss: 0.1118 accuracy: 0.9882 val_loss: 0.3629 val_accuracy: 0.9195

Epoch 00064: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
Epoch: 65 loss: 0.1075 accuracy: 0.9891 val_loss: 0.3581 val_accuracy: 0.9226
Epoch: 66 loss: 0.1040 accuracy: 0.9907 val_loss: 0.3602 val_accuracy: 0.9221
Epoch: 67 loss: 0.1033 accuracy: 0.9904 val_loss: 0.3629 val_accuracy: 0.9254
Epoch: 68 loss: 0.1042 accuracy: 0.9899 val_loss: 0.3634 val_accuracy: 0.9237
Epoch: 69 loss: 0.1045 accuracy: 0.9890 val_loss: 0.3597 val_accuracy: 0.9226

Epoch 00069: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.
End of augmented training
Finish
Job ended!
