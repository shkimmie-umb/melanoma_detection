Tue 27 Feb 2024 08:22:28 AM EST
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'KaggleMB']
IMG_SIZE: [150, 150]
CLASSIFIER: EfficientNetB2
SELF_AUG: 1
JOB_INDEX: None
Combining...
Combining 1 db out of 2 dbs
Combining 2 db out of 2 dbs
Stacking training images
Stacking training labels
Stacking validation images
Stacking validation labels
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb2 (Functional)  (None, 1408)              7768569   
_________________________________________________________________
dense (Dense)                (None, 512)               721408    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 8,624,891
Trainable params: 854,786
Non-trainable params: 7,770,105
_________________________________________________________________
Fitting ISIC2016+KaggleMB_aug_EfficientNetB2_150h_150w_None model...
model_name: ISIC2016+KaggleMB_aug_EfficientNetB2_150h_150w_None
Epoch: 1 loss: 0.6956 accuracy: 0.5183 val_loss: 0.7132 val_accuracy: 0.3743
Epoch: 2 loss: 0.6906 accuracy: 0.5335 val_loss: 0.7231 val_accuracy: 0.3743
Epoch: 3 loss: 0.6886 accuracy: 0.5437 val_loss: 0.7291 val_accuracy: 0.3743
Epoch: 4 loss: 0.6889 accuracy: 0.5482 val_loss: 0.7447 val_accuracy: 0.3743
Epoch: 5 loss: 0.6876 accuracy: 0.5474 val_loss: 0.7181 val_accuracy: 0.3743
Epoch: 6 loss: 0.6873 accuracy: 0.5557 val_loss: 0.7480 val_accuracy: 0.3743
Epoch: 7 loss: 0.6873 accuracy: 0.5531 val_loss: 0.7597 val_accuracy: 0.3743
Epoch: 8 loss: 0.6853 accuracy: 0.5561 val_loss: 0.7511 val_accuracy: 0.3743
Epoch: 9 loss: 0.6844 accuracy: 0.5555 val_loss: 0.7209 val_accuracy: 0.3743
Epoch: 10 loss: 0.6864 accuracy: 0.5548 val_loss: 0.7379 val_accuracy: 0.3743
Epoch: 11 loss: 0.6851 accuracy: 0.5559 val_loss: 0.7046 val_accuracy: 0.3743
Epoch: 12 loss: 0.6853 accuracy: 0.5565 val_loss: 0.7477 val_accuracy: 0.3743
Epoch: 13 loss: 0.6840 accuracy: 0.5574 val_loss: 0.7177 val_accuracy: 0.3743
Epoch: 14 loss: 0.6850 accuracy: 0.5561 val_loss: 0.7201 val_accuracy: 0.3743
Epoch: 15 loss: 0.6824 accuracy: 0.5606 val_loss: 0.7199 val_accuracy: 0.3743
Epoch: 16 loss: 0.6818 accuracy: 0.5674 val_loss: 0.7111 val_accuracy: 0.3743
Epoch: 17 loss: 0.6799 accuracy: 0.5691 val_loss: 0.7205 val_accuracy: 0.3743
Epoch: 18 loss: 0.6802 accuracy: 0.5804 val_loss: 0.7392 val_accuracy: 0.3743
Epoch: 19 loss: 0.6790 accuracy: 0.5712 val_loss: 0.6970 val_accuracy: 0.4068
Epoch: 20 loss: 0.6785 accuracy: 0.5789 val_loss: 0.7386 val_accuracy: 0.3743
Job ended!
