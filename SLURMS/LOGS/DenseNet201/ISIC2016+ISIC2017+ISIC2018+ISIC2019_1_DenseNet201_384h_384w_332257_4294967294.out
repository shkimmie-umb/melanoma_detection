Fri 03 May 2024 10:26:12 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'ISIC2019']
IMG_SIZE: [384, 384]
CLASSIFIER: DenseNet201
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 4 dbs
Combining 2th db out of 4 dbs
Combining 3th db out of 4 dbs
Combining 4th db out of 4 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
densenet201 (Functional)     (None, 1920)              18321984  
_________________________________________________________________
dense (Dense)                (None, 512)               983552    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 19,440,450
Trainable params: 1,116,930
Non-trainable params: 18,323,520
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+ISIC2019_aug_DenseNet201_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+ISIC2019_aug_DenseNet201_384h_384w_None
Epoch: 1 loss: 0.8246 accuracy: 0.8041 val_loss: 0.7372 val_accuracy: 0.8181
Epoch: 2 loss: 0.6358 accuracy: 0.8573 val_loss: 0.6398 val_accuracy: 0.8560
Epoch: 3 loss: 0.5746 accuracy: 0.8775 val_loss: 0.6286 val_accuracy: 0.8533
Epoch: 4 loss: 0.5316 accuracy: 0.8893 val_loss: 0.6063 val_accuracy: 0.8515
Epoch: 5 loss: 0.4926 accuracy: 0.8988 val_loss: 0.5588 val_accuracy: 0.8685
Epoch: 6 loss: 0.4578 accuracy: 0.9073 val_loss: 0.5720 val_accuracy: 0.8530
Epoch: 7 loss: 0.4315 accuracy: 0.9132 val_loss: 0.5272 val_accuracy: 0.8676
Epoch: 8 loss: 0.4050 accuracy: 0.9208 val_loss: 0.5004 val_accuracy: 0.8800
Epoch: 9 loss: 0.3797 accuracy: 0.9273 val_loss: 0.5014 val_accuracy: 0.8760
Epoch: 10 loss: 0.3610 accuracy: 0.9312 val_loss: 0.5099 val_accuracy: 0.8685
Epoch: 11 loss: 0.3404 accuracy: 0.9361 val_loss: 0.4984 val_accuracy: 0.8692
Epoch: 12 loss: 0.3286 accuracy: 0.9372 val_loss: 0.4475 val_accuracy: 0.8891
Epoch: 13 loss: 0.3175 accuracy: 0.9395 val_loss: 0.4499 val_accuracy: 0.8887
Epoch: 14 loss: 0.2996 accuracy: 0.9445 val_loss: 0.4220 val_accuracy: 0.8961
Epoch: 15 loss: 0.2889 accuracy: 0.9448 val_loss: 0.4371 val_accuracy: 0.8898
Epoch: 16 loss: 0.2769 accuracy: 0.9488 val_loss: 0.4349 val_accuracy: 0.8907
Epoch: 17 loss: 0.2660 accuracy: 0.9515 val_loss: 0.4580 val_accuracy: 0.8816
Epoch: 18 loss: 0.2546 accuracy: 0.9543 val_loss: 0.3904 val_accuracy: 0.9052
Epoch: 19 loss: 0.2522 accuracy: 0.9524 val_loss: 0.4310 val_accuracy: 0.8905
Epoch: 20 loss: 0.2374 accuracy: 0.9578 val_loss: 0.3740 val_accuracy: 0.9134
Epoch: 21 loss: 0.2354 accuracy: 0.9570 val_loss: 0.3777 val_accuracy: 0.9120
Epoch: 22 loss: 0.2284 accuracy: 0.9582 val_loss: 0.4056 val_accuracy: 0.8991
Epoch: 23 loss: 0.2214 accuracy: 0.9602 val_loss: 0.3876 val_accuracy: 0.9104
Epoch: 24 loss: 0.2173 accuracy: 0.9605 val_loss: 0.3719 val_accuracy: 0.9109
Epoch: 25 loss: 0.2092 accuracy: 0.9629 val_loss: 0.4036 val_accuracy: 0.9045
Epoch: 26 loss: 0.2002 accuracy: 0.9645 val_loss: 0.3646 val_accuracy: 0.9107
Epoch: 27 loss: 0.1939 accuracy: 0.9668 val_loss: 0.3725 val_accuracy: 0.9125
Epoch: 28 loss: 0.1934 accuracy: 0.9657 val_loss: 0.3933 val_accuracy: 0.8991
Epoch: 29 loss: 0.1878 accuracy: 0.9666 val_loss: 0.3628 val_accuracy: 0.9150
Epoch: 30 loss: 0.1851 accuracy: 0.9676 val_loss: 0.4112 val_accuracy: 0.8993
Epoch: 31 loss: 0.1851 accuracy: 0.9663 val_loss: 0.3916 val_accuracy: 0.9047
Epoch: 32 loss: 0.1800 accuracy: 0.9674 val_loss: 0.3795 val_accuracy: 0.9118
Epoch: 33 loss: 0.1758 accuracy: 0.9696 val_loss: 0.3550 val_accuracy: 0.9195
Epoch: 34 loss: 0.1756 accuracy: 0.9673 val_loss: 0.4020 val_accuracy: 0.8948
Epoch: 35 loss: 0.1677 accuracy: 0.9709 val_loss: 0.3791 val_accuracy: 0.9077
Epoch: 36 loss: 0.1660 accuracy: 0.9710 val_loss: 0.3648 val_accuracy: 0.9106
Epoch: 37 loss: 0.1668 accuracy: 0.9704 val_loss: 0.3436 val_accuracy: 0.9229
Epoch: 38 loss: 0.1620 accuracy: 0.9715 val_loss: 0.3663 val_accuracy: 0.9202
Epoch: 39 loss: 0.1567 accuracy: 0.9727 val_loss: 0.3543 val_accuracy: 0.9190
Epoch: 40 loss: 0.1542 accuracy: 0.9736 val_loss: 0.3727 val_accuracy: 0.9114
Epoch: 41 loss: 0.1598 accuracy: 0.9707 val_loss: 0.3841 val_accuracy: 0.9157
Epoch: 42 loss: 0.1505 accuracy: 0.9741 val_loss: 0.3459 val_accuracy: 0.9177

Epoch 00042: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 43 loss: 0.1389 accuracy: 0.9788 val_loss: 0.3475 val_accuracy: 0.9166
Epoch: 44 loss: 0.1412 accuracy: 0.9782 val_loss: 0.3341 val_accuracy: 0.9293
Epoch: 45 loss: 0.1346 accuracy: 0.9788 val_loss: 0.3322 val_accuracy: 0.9224
Epoch: 46 loss: 0.1348 accuracy: 0.9784 val_loss: 0.3422 val_accuracy: 0.9199
Epoch: 47 loss: 0.1318 accuracy: 0.9796 val_loss: 0.3315 val_accuracy: 0.9295
Epoch: 48 loss: 0.1278 accuracy: 0.9805 val_loss: 0.3631 val_accuracy: 0.9165
Epoch: 49 loss: 0.1249 accuracy: 0.9817 val_loss: 0.3457 val_accuracy: 0.9249
Epoch: 50 loss: 0.1247 accuracy: 0.9815 val_loss: 0.3350 val_accuracy: 0.9249
Epoch: 51 loss: 0.1263 accuracy: 0.9804 val_loss: 0.3440 val_accuracy: 0.9242
Epoch: 52 loss: 0.1190 accuracy: 0.9821 val_loss: 0.3561 val_accuracy: 0.9231

Epoch 00052: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 53 loss: 0.1154 accuracy: 0.9839 val_loss: 0.3453 val_accuracy: 0.9277
Epoch: 54 loss: 0.1103 accuracy: 0.9856 val_loss: 0.3212 val_accuracy: 0.9335
Epoch: 55 loss: 0.1082 accuracy: 0.9856 val_loss: 0.3201 val_accuracy: 0.9340
Epoch: 56 loss: 0.1029 accuracy: 0.9871 val_loss: 0.3412 val_accuracy: 0.9327
Epoch: 57 loss: 0.1094 accuracy: 0.9849 val_loss: 0.3412 val_accuracy: 0.9349
Epoch: 58 loss: 0.1032 accuracy: 0.9870 val_loss: 0.3376 val_accuracy: 0.9311
Epoch: 59 loss: 0.1042 accuracy: 0.9866 val_loss: 0.3599 val_accuracy: 0.9309
Epoch: 60 loss: 0.1010 accuracy: 0.9874 val_loss: 0.3480 val_accuracy: 0.9299

Epoch 00060: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 61 loss: 0.0993 accuracy: 0.9877 val_loss: 0.3141 val_accuracy: 0.9394
Epoch: 62 loss: 0.0954 accuracy: 0.9893 val_loss: 0.3399 val_accuracy: 0.9297
Epoch: 63 loss: 0.0933 accuracy: 0.9899 val_loss: 0.3492 val_accuracy: 0.9318
Epoch: 64 loss: 0.0949 accuracy: 0.9885 val_loss: 0.3286 val_accuracy: 0.9372
Epoch: 65 loss: 0.0918 accuracy: 0.9900 val_loss: 0.3167 val_accuracy: 0.9385
Epoch: 66 loss: 0.0919 accuracy: 0.9890 val_loss: 0.3525 val_accuracy: 0.9349

Epoch 00066: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
Epoch: 67 loss: 0.0871 accuracy: 0.9910 val_loss: 0.3454 val_accuracy: 0.9326
Epoch: 68 loss: 0.0839 accuracy: 0.9917 val_loss: 0.3303 val_accuracy: 0.9386
Epoch: 69 loss: 0.0844 accuracy: 0.9911 val_loss: 0.3313 val_accuracy: 0.9394
Epoch: 70 loss: 0.0827 accuracy: 0.9923 val_loss: 0.3508 val_accuracy: 0.9347
Epoch: 71 loss: 0.0825 accuracy: 0.9920 val_loss: 0.3325 val_accuracy: 0.9377

Epoch 00071: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.
End of augmented training
Finish
Job ended!
