Thu 09 May 2024 01:44:40 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2018']
IMG_SIZE: [384, 384]
CLASSIFIER: VGG19
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 1 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
vgg19 (Functional)           (None, 512)               20024384  
_________________________________________________________________
dense (Dense)                (None, 512)               262656    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 20,421,954
Trainable params: 396,034
Non-trainable params: 20,025,920
_________________________________________________________________
Fitting ISIC2018_aug_VGG19_384h_384w_None model...
model_name: ISIC2018_aug_VGG19_384h_384w_None
Epoch: 1 loss: 1.0009 accuracy: 0.7115 val_loss: 0.6970 val_accuracy: 0.8705
Epoch: 2 loss: 0.7546 accuracy: 0.7856 val_loss: 0.5361 val_accuracy: 0.8653
Epoch: 3 loss: 0.6624 accuracy: 0.8038 val_loss: 0.6486 val_accuracy: 0.8394
Epoch: 4 loss: 0.6221 accuracy: 0.8108 val_loss: 0.4986 val_accuracy: 0.8860
Epoch: 5 loss: 0.5886 accuracy: 0.8177 val_loss: 0.5091 val_accuracy: 0.8756
Epoch: 6 loss: 0.5771 accuracy: 0.8191 val_loss: 0.4494 val_accuracy: 0.8705
Epoch: 7 loss: 0.5524 accuracy: 0.8229 val_loss: 0.5414 val_accuracy: 0.8497
Epoch: 8 loss: 0.5283 accuracy: 0.8302 val_loss: 0.4732 val_accuracy: 0.8964
Epoch: 9 loss: 0.5220 accuracy: 0.8302 val_loss: 0.4408 val_accuracy: 0.8860
Epoch: 10 loss: 0.5239 accuracy: 0.8298 val_loss: 0.4318 val_accuracy: 0.8964
Epoch: 11 loss: 0.5006 accuracy: 0.8390 val_loss: 0.4555 val_accuracy: 0.8756
Epoch: 12 loss: 0.5066 accuracy: 0.8287 val_loss: 0.3919 val_accuracy: 0.8912
Epoch: 13 loss: 0.5028 accuracy: 0.8355 val_loss: 0.4292 val_accuracy: 0.8756
Epoch: 14 loss: 0.4924 accuracy: 0.8348 val_loss: 0.4549 val_accuracy: 0.8601
Epoch: 15 loss: 0.4805 accuracy: 0.8397 val_loss: 0.3881 val_accuracy: 0.8912
Epoch: 16 loss: 0.4785 accuracy: 0.8403 val_loss: 0.3823 val_accuracy: 0.9016
Epoch: 17 loss: 0.4736 accuracy: 0.8413 val_loss: 0.4518 val_accuracy: 0.8601
Epoch: 18 loss: 0.4699 accuracy: 0.8413 val_loss: 0.3941 val_accuracy: 0.8860
Epoch: 19 loss: 0.4668 accuracy: 0.8414 val_loss: 0.4069 val_accuracy: 0.8705
Epoch: 20 loss: 0.4540 accuracy: 0.8459 val_loss: 0.4680 val_accuracy: 0.8497
Epoch: 21 loss: 0.4523 accuracy: 0.8459 val_loss: 0.4508 val_accuracy: 0.8446

Epoch 00021: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 22 loss: 0.4445 accuracy: 0.8468 val_loss: 0.4424 val_accuracy: 0.8497
Epoch: 23 loss: 0.4426 accuracy: 0.8479 val_loss: 0.4084 val_accuracy: 0.8808
Epoch: 24 loss: 0.4387 accuracy: 0.8452 val_loss: 0.4951 val_accuracy: 0.8290
Epoch: 25 loss: 0.4240 accuracy: 0.8536 val_loss: 0.4462 val_accuracy: 0.8446
Epoch: 26 loss: 0.4294 accuracy: 0.8520 val_loss: 0.3657 val_accuracy: 0.9016
Epoch: 27 loss: 0.4213 accuracy: 0.8527 val_loss: 0.3788 val_accuracy: 0.9016
Epoch: 28 loss: 0.4197 accuracy: 0.8513 val_loss: 0.4927 val_accuracy: 0.8135
Epoch: 29 loss: 0.4214 accuracy: 0.8508 val_loss: 0.3651 val_accuracy: 0.8808
Epoch: 30 loss: 0.4132 accuracy: 0.8517 val_loss: 0.3711 val_accuracy: 0.8756
Epoch: 31 loss: 0.4059 accuracy: 0.8564 val_loss: 0.3473 val_accuracy: 0.8860
Epoch: 32 loss: 0.4001 accuracy: 0.8566 val_loss: 0.4238 val_accuracy: 0.8601
Epoch: 33 loss: 0.3895 accuracy: 0.8601 val_loss: 0.4231 val_accuracy: 0.8601
Epoch: 34 loss: 0.4066 accuracy: 0.8544 val_loss: 0.5055 val_accuracy: 0.8031
Epoch: 35 loss: 0.3922 accuracy: 0.8601 val_loss: 0.3400 val_accuracy: 0.9223
Epoch: 36 loss: 0.3890 accuracy: 0.8613 val_loss: 0.4336 val_accuracy: 0.8497
Epoch: 37 loss: 0.3859 accuracy: 0.8560 val_loss: 0.4081 val_accuracy: 0.8446
Epoch: 38 loss: 0.3770 accuracy: 0.8642 val_loss: 0.3081 val_accuracy: 0.8964
Epoch: 39 loss: 0.3788 accuracy: 0.8617 val_loss: 0.3513 val_accuracy: 0.8653
Epoch: 40 loss: 0.3743 accuracy: 0.8652 val_loss: 0.4177 val_accuracy: 0.8497
Epoch: 41 loss: 0.3755 accuracy: 0.8631 val_loss: 0.3414 val_accuracy: 0.8912
Epoch: 42 loss: 0.3751 accuracy: 0.8577 val_loss: 0.4306 val_accuracy: 0.8446
Epoch: 43 loss: 0.3745 accuracy: 0.8590 val_loss: 0.3058 val_accuracy: 0.8808
Epoch: 44 loss: 0.3661 accuracy: 0.8640 val_loss: 0.3230 val_accuracy: 0.9016
Epoch: 45 loss: 0.3671 accuracy: 0.8614 val_loss: 0.3255 val_accuracy: 0.8912
Epoch: 46 loss: 0.3561 accuracy: 0.8669 val_loss: 0.4150 val_accuracy: 0.8238
Epoch: 47 loss: 0.3563 accuracy: 0.8651 val_loss: 0.3455 val_accuracy: 0.8860
Epoch: 48 loss: 0.3567 accuracy: 0.8661 val_loss: 0.3506 val_accuracy: 0.8705

Epoch 00048: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 49 loss: 0.3525 accuracy: 0.8682 val_loss: 0.3343 val_accuracy: 0.8860
Epoch: 50 loss: 0.3465 accuracy: 0.8695 val_loss: 0.4169 val_accuracy: 0.8446
Epoch: 51 loss: 0.3522 accuracy: 0.8665 val_loss: 0.3472 val_accuracy: 0.8756
Epoch: 52 loss: 0.3384 accuracy: 0.8721 val_loss: 0.3616 val_accuracy: 0.8756
Epoch: 53 loss: 0.3418 accuracy: 0.8717 val_loss: 0.3244 val_accuracy: 0.8912

Epoch 00053: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
End of augmented training
Finish
Job ended!
