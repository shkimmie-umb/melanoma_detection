Thu 09 May 2024 06:58:40 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'ISIC2019', 'ISIC2020']
IMG_SIZE: [384, 384]
CLASSIFIER: Xception
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 5 dbs
Combining 2th db out of 5 dbs
Combining 3th db out of 5 dbs
Combining 4th db out of 5 dbs
Combining 5th db out of 5 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
xception (Functional)        (None, 2048)              20861480  
_________________________________________________________________
dense (Dense)                (None, 512)               1049088   
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 22,045,482
Trainable params: 1,182,466
Non-trainable params: 20,863,016
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020_aug_Xception_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020_aug_Xception_384h_384w_None
Epoch: 1 loss: 0.9262 accuracy: 0.8321 val_loss: 0.8218 val_accuracy: 0.8689
Epoch: 2 loss: 0.7411 accuracy: 0.8813 val_loss: 0.7148 val_accuracy: 0.8796
Epoch: 3 loss: 0.6472 accuracy: 0.8943 val_loss: 0.6761 val_accuracy: 0.8688
Epoch: 4 loss: 0.5712 accuracy: 0.9062 val_loss: 0.5782 val_accuracy: 0.8969
Epoch: 5 loss: 0.5150 accuracy: 0.9116 val_loss: 0.5277 val_accuracy: 0.9047
Epoch: 6 loss: 0.4671 accuracy: 0.9177 val_loss: 0.5260 val_accuracy: 0.8897
Epoch: 7 loss: 0.4282 accuracy: 0.9232 val_loss: 0.4601 val_accuracy: 0.9103
Epoch: 8 loss: 0.3949 accuracy: 0.9270 val_loss: 0.4504 val_accuracy: 0.9068
Epoch: 9 loss: 0.3698 accuracy: 0.9305 val_loss: 0.4416 val_accuracy: 0.8973
Epoch: 10 loss: 0.3437 accuracy: 0.9341 val_loss: 0.4092 val_accuracy: 0.9118
Epoch: 11 loss: 0.3233 accuracy: 0.9376 val_loss: 0.4010 val_accuracy: 0.9077
Epoch: 12 loss: 0.3082 accuracy: 0.9391 val_loss: 0.4191 val_accuracy: 0.9008
Epoch: 13 loss: 0.2913 accuracy: 0.9420 val_loss: 0.3581 val_accuracy: 0.9185
Epoch: 14 loss: 0.2792 accuracy: 0.9430 val_loss: 0.3536 val_accuracy: 0.9168
Epoch: 15 loss: 0.2648 accuracy: 0.9463 val_loss: 0.3499 val_accuracy: 0.9182
Epoch: 16 loss: 0.2507 accuracy: 0.9490 val_loss: 0.4375 val_accuracy: 0.8870
Epoch: 17 loss: 0.2432 accuracy: 0.9505 val_loss: 0.3350 val_accuracy: 0.9232
Epoch: 18 loss: 0.2360 accuracy: 0.9502 val_loss: 0.3431 val_accuracy: 0.9140
Epoch: 19 loss: 0.2254 accuracy: 0.9529 val_loss: 0.3201 val_accuracy: 0.9279
Epoch: 20 loss: 0.2197 accuracy: 0.9546 val_loss: 0.3645 val_accuracy: 0.9021
Epoch: 21 loss: 0.2109 accuracy: 0.9561 val_loss: 0.3524 val_accuracy: 0.9124
Epoch: 22 loss: 0.2068 accuracy: 0.9570 val_loss: 0.3467 val_accuracy: 0.9098
Epoch: 23 loss: 0.2021 accuracy: 0.9573 val_loss: 0.3033 val_accuracy: 0.9257
Epoch: 24 loss: 0.1961 accuracy: 0.9580 val_loss: 0.3117 val_accuracy: 0.9260
Epoch: 25 loss: 0.1939 accuracy: 0.9583 val_loss: 0.3044 val_accuracy: 0.9262
Epoch: 26 loss: 0.1853 accuracy: 0.9612 val_loss: 0.3063 val_accuracy: 0.9258
Epoch: 27 loss: 0.1875 accuracy: 0.9596 val_loss: 0.3155 val_accuracy: 0.9203
Epoch: 28 loss: 0.1791 accuracy: 0.9624 val_loss: 0.3007 val_accuracy: 0.9283
Epoch: 29 loss: 0.1751 accuracy: 0.9636 val_loss: 0.2993 val_accuracy: 0.9303
Epoch: 30 loss: 0.1723 accuracy: 0.9641 val_loss: 0.2962 val_accuracy: 0.9294
Epoch: 31 loss: 0.1696 accuracy: 0.9634 val_loss: 0.3227 val_accuracy: 0.9203
Epoch: 32 loss: 0.1664 accuracy: 0.9656 val_loss: 0.3011 val_accuracy: 0.9261
Epoch: 33 loss: 0.1655 accuracy: 0.9652 val_loss: 0.2888 val_accuracy: 0.9317
Epoch: 34 loss: 0.1634 accuracy: 0.9654 val_loss: 0.2775 val_accuracy: 0.9410
Epoch: 35 loss: 0.1609 accuracy: 0.9655 val_loss: 0.2987 val_accuracy: 0.9251
Epoch: 36 loss: 0.1572 accuracy: 0.9666 val_loss: 0.3054 val_accuracy: 0.9219
Epoch: 37 loss: 0.1545 accuracy: 0.9675 val_loss: 0.3025 val_accuracy: 0.9263
Epoch: 38 loss: 0.1546 accuracy: 0.9675 val_loss: 0.3009 val_accuracy: 0.9247
Epoch: 39 loss: 0.1503 accuracy: 0.9691 val_loss: 0.3418 val_accuracy: 0.9122

Epoch 00039: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 40 loss: 0.1382 accuracy: 0.9735 val_loss: 0.2814 val_accuracy: 0.9358
Epoch: 41 loss: 0.1327 accuracy: 0.9750 val_loss: 0.2778 val_accuracy: 0.9357
Epoch: 42 loss: 0.1308 accuracy: 0.9747 val_loss: 0.2707 val_accuracy: 0.9336
Epoch: 43 loss: 0.1290 accuracy: 0.9758 val_loss: 0.2804 val_accuracy: 0.9370
Epoch: 44 loss: 0.1262 accuracy: 0.9763 val_loss: 0.2832 val_accuracy: 0.9387
Epoch: 45 loss: 0.1263 accuracy: 0.9757 val_loss: 0.2752 val_accuracy: 0.9427
Epoch: 46 loss: 0.1257 accuracy: 0.9760 val_loss: 0.3019 val_accuracy: 0.9253
Epoch: 47 loss: 0.1219 accuracy: 0.9764 val_loss: 0.2809 val_accuracy: 0.9401

Epoch 00047: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 48 loss: 0.1133 accuracy: 0.9803 val_loss: 0.2807 val_accuracy: 0.9367
Epoch: 49 loss: 0.1119 accuracy: 0.9805 val_loss: 0.2872 val_accuracy: 0.9385
Epoch: 50 loss: 0.1080 accuracy: 0.9819 val_loss: 0.2914 val_accuracy: 0.9379
Epoch: 51 loss: 0.1038 accuracy: 0.9835 val_loss: 0.3072 val_accuracy: 0.9321
Epoch: 52 loss: 0.1071 accuracy: 0.9814 val_loss: 0.2777 val_accuracy: 0.9404

Epoch 00052: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
End of augmented training
Finish
Job ended!
