Thu 02 May 2024 03:42:56 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'ISIC2020', 'PH2']
IMG_SIZE: [384, 384]
CLASSIFIER: DenseNet121
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 5 dbs
Combining 2th db out of 5 dbs
Combining 3th db out of 5 dbs
Combining 4th db out of 5 dbs
Combining 5th db out of 5 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
densenet121 (Functional)     (None, 1024)              7037504   
_________________________________________________________________
dense (Dense)                (None, 512)               524800    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 7,697,218
Trainable params: 658,178
Non-trainable params: 7,039,040
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+ISIC2020+PH2_aug_DenseNet121_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+ISIC2020+PH2_aug_DenseNet121_384h_384w_None
Epoch: 1 loss: 0.7796 accuracy: 0.8342 val_loss: 0.5732 val_accuracy: 0.9168
Epoch: 2 loss: 0.5580 accuracy: 0.9008 val_loss: 0.4719 val_accuracy: 0.9385
Epoch: 3 loss: 0.5022 accuracy: 0.9112 val_loss: 0.4213 val_accuracy: 0.9508
Epoch: 4 loss: 0.4595 accuracy: 0.9201 val_loss: 0.3945 val_accuracy: 0.9499
Epoch: 5 loss: 0.4230 accuracy: 0.9275 val_loss: 0.3709 val_accuracy: 0.9524
Epoch: 6 loss: 0.3945 accuracy: 0.9323 val_loss: 0.3695 val_accuracy: 0.9475
Epoch: 7 loss: 0.3715 accuracy: 0.9366 val_loss: 0.3542 val_accuracy: 0.9466
Epoch: 8 loss: 0.3490 accuracy: 0.9393 val_loss: 0.3319 val_accuracy: 0.9495
Epoch: 9 loss: 0.3340 accuracy: 0.9411 val_loss: 0.3063 val_accuracy: 0.9558
Epoch: 10 loss: 0.3149 accuracy: 0.9446 val_loss: 0.3243 val_accuracy: 0.9449
Epoch: 11 loss: 0.3021 accuracy: 0.9475 val_loss: 0.2883 val_accuracy: 0.9548
Epoch: 12 loss: 0.2831 accuracy: 0.9501 val_loss: 0.2927 val_accuracy: 0.9534
Epoch: 13 loss: 0.2719 accuracy: 0.9522 val_loss: 0.2765 val_accuracy: 0.9540
Epoch: 14 loss: 0.2598 accuracy: 0.9538 val_loss: 0.2809 val_accuracy: 0.9480
Epoch: 15 loss: 0.2537 accuracy: 0.9545 val_loss: 0.2789 val_accuracy: 0.9442
Epoch: 16 loss: 0.2418 accuracy: 0.9562 val_loss: 0.2562 val_accuracy: 0.9545
Epoch: 17 loss: 0.2352 accuracy: 0.9588 val_loss: 0.2675 val_accuracy: 0.9501
Epoch: 18 loss: 0.2259 accuracy: 0.9592 val_loss: 0.2462 val_accuracy: 0.9526
Epoch: 19 loss: 0.2154 accuracy: 0.9606 val_loss: 0.2658 val_accuracy: 0.9449
Epoch: 20 loss: 0.2087 accuracy: 0.9624 val_loss: 0.2348 val_accuracy: 0.9608
Epoch: 21 loss: 0.2035 accuracy: 0.9622 val_loss: 0.2236 val_accuracy: 0.9593
Epoch: 22 loss: 0.1990 accuracy: 0.9646 val_loss: 0.2249 val_accuracy: 0.9578
Epoch: 23 loss: 0.1893 accuracy: 0.9657 val_loss: 0.2292 val_accuracy: 0.9538
Epoch: 24 loss: 0.1878 accuracy: 0.9647 val_loss: 0.2150 val_accuracy: 0.9620
Epoch: 25 loss: 0.1844 accuracy: 0.9652 val_loss: 0.2186 val_accuracy: 0.9620
Epoch: 26 loss: 0.1814 accuracy: 0.9647 val_loss: 0.2249 val_accuracy: 0.9551
Epoch: 27 loss: 0.1712 accuracy: 0.9691 val_loss: 0.2091 val_accuracy: 0.9607
Epoch: 28 loss: 0.1731 accuracy: 0.9673 val_loss: 0.2033 val_accuracy: 0.9645
Epoch: 29 loss: 0.1661 accuracy: 0.9682 val_loss: 0.2371 val_accuracy: 0.9533
Epoch: 30 loss: 0.1644 accuracy: 0.9695 val_loss: 0.2106 val_accuracy: 0.9607
Epoch: 31 loss: 0.1575 accuracy: 0.9706 val_loss: 0.1956 val_accuracy: 0.9663
Epoch: 32 loss: 0.1587 accuracy: 0.9690 val_loss: 0.2071 val_accuracy: 0.9586
Epoch: 33 loss: 0.1522 accuracy: 0.9715 val_loss: 0.1951 val_accuracy: 0.9629
Epoch: 34 loss: 0.1519 accuracy: 0.9704 val_loss: 0.2082 val_accuracy: 0.9541
Epoch: 35 loss: 0.1490 accuracy: 0.9713 val_loss: 0.2151 val_accuracy: 0.9576
Epoch: 36 loss: 0.1433 accuracy: 0.9727 val_loss: 0.1958 val_accuracy: 0.9606
Epoch: 37 loss: 0.1458 accuracy: 0.9714 val_loss: 0.1922 val_accuracy: 0.9694
Epoch: 38 loss: 0.1436 accuracy: 0.9725 val_loss: 0.1909 val_accuracy: 0.9681
Epoch: 39 loss: 0.1370 accuracy: 0.9750 val_loss: 0.2019 val_accuracy: 0.9638
Epoch: 40 loss: 0.1332 accuracy: 0.9759 val_loss: 0.2092 val_accuracy: 0.9538
Epoch: 41 loss: 0.1349 accuracy: 0.9743 val_loss: 0.1911 val_accuracy: 0.9624
Epoch: 42 loss: 0.1369 accuracy: 0.9732 val_loss: 0.2131 val_accuracy: 0.9580
Epoch: 43 loss: 0.1313 accuracy: 0.9748 val_loss: 0.2175 val_accuracy: 0.9523

Epoch 00043: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 44 loss: 0.1258 accuracy: 0.9760 val_loss: 0.1869 val_accuracy: 0.9620
Epoch: 45 loss: 0.1169 accuracy: 0.9793 val_loss: 0.1940 val_accuracy: 0.9594
Epoch: 46 loss: 0.1215 accuracy: 0.9781 val_loss: 0.2002 val_accuracy: 0.9601
Epoch: 47 loss: 0.1154 accuracy: 0.9802 val_loss: 0.2009 val_accuracy: 0.9611
Epoch: 48 loss: 0.1155 accuracy: 0.9795 val_loss: 0.2007 val_accuracy: 0.9614
Epoch: 49 loss: 0.1124 accuracy: 0.9799 val_loss: 0.1922 val_accuracy: 0.9636

Epoch 00049: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 50 loss: 0.1032 accuracy: 0.9838 val_loss: 0.1989 val_accuracy: 0.9583
Epoch: 51 loss: 0.1025 accuracy: 0.9833 val_loss: 0.1929 val_accuracy: 0.9606
Epoch: 52 loss: 0.0998 accuracy: 0.9839 val_loss: 0.1801 val_accuracy: 0.9660
Epoch: 53 loss: 0.0959 accuracy: 0.9852 val_loss: 0.1876 val_accuracy: 0.9653
Epoch: 54 loss: 0.0954 accuracy: 0.9852 val_loss: 0.1923 val_accuracy: 0.9649
Epoch: 55 loss: 0.0961 accuracy: 0.9853 val_loss: 0.1987 val_accuracy: 0.9666
Epoch: 56 loss: 0.0932 accuracy: 0.9856 val_loss: 0.1888 val_accuracy: 0.9643
Epoch: 57 loss: 0.0936 accuracy: 0.9854 val_loss: 0.1935 val_accuracy: 0.9607

Epoch 00057: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 58 loss: 0.0889 accuracy: 0.9870 val_loss: 0.1788 val_accuracy: 0.9648
Epoch: 59 loss: 0.0852 accuracy: 0.9888 val_loss: 0.1881 val_accuracy: 0.9634
Epoch: 60 loss: 0.0850 accuracy: 0.9883 val_loss: 0.1921 val_accuracy: 0.9624
Epoch: 61 loss: 0.0857 accuracy: 0.9879 val_loss: 0.1944 val_accuracy: 0.9615
Epoch: 62 loss: 0.0836 accuracy: 0.9884 val_loss: 0.1824 val_accuracy: 0.9668
Epoch: 63 loss: 0.0811 accuracy: 0.9896 val_loss: 0.1852 val_accuracy: 0.9668

Epoch 00063: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
Epoch: 64 loss: 0.0776 accuracy: 0.9903 val_loss: 0.1865 val_accuracy: 0.9689
Epoch: 65 loss: 0.0782 accuracy: 0.9899 val_loss: 0.1842 val_accuracy: 0.9678
Epoch: 66 loss: 0.0758 accuracy: 0.9910 val_loss: 0.1953 val_accuracy: 0.9649
Epoch: 67 loss: 0.0752 accuracy: 0.9912 val_loss: 0.1942 val_accuracy: 0.9652
Epoch: 68 loss: 0.0731 accuracy: 0.9918 val_loss: 0.1969 val_accuracy: 0.9638

Epoch 00068: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.
End of augmented training
Finish
Job ended!
