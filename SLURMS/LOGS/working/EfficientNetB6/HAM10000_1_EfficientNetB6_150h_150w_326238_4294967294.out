Fri 01 Mar 2024 10:46:49 AM EST
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['HAM10000']
IMG_SIZE: [150, 150]
CLASSIFIER: EfficientNetB6
SELF_AUG: 1
JOB_INDEX: None
Combining...
Combining 1 db out of 1 dbs
Stacking training images
Stacking training labels
Stacking validation images
Stacking validation labels
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb6 (Functional)  (None, 2304)              40960143  
_________________________________________________________________
dense (Dense)                (None, 512)               1180160   
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 42,275,217
Trainable params: 1,313,538
Non-trainable params: 40,961,679
_________________________________________________________________
Fitting HAM10000_aug_EfficientNetB6_150h_150w_None model...
model_name: HAM10000_aug_EfficientNetB6_150h_150w_None
Epoch: 1 loss: 0.6404 accuracy: 0.7181 val_loss: 0.2105 val_accuracy: 0.9558
Epoch: 2 loss: 0.5106 accuracy: 0.7752 val_loss: 0.1497 val_accuracy: 0.9581
Epoch: 3 loss: 0.4604 accuracy: 0.7994 val_loss: 0.1323 val_accuracy: 0.9558
Epoch: 4 loss: 0.4491 accuracy: 0.8044 val_loss: 0.1209 val_accuracy: 0.9626
Epoch: 5 loss: 0.4298 accuracy: 0.8128 val_loss: 0.1198 val_accuracy: 0.9638
Epoch: 6 loss: 0.4136 accuracy: 0.8179 val_loss: 0.1222 val_accuracy: 0.9581
Epoch: 7 loss: 0.4007 accuracy: 0.8232 val_loss: 0.1217 val_accuracy: 0.9570
Epoch: 8 loss: 0.3970 accuracy: 0.8270 val_loss: 0.1412 val_accuracy: 0.9536
Epoch: 9 loss: 0.3891 accuracy: 0.8311 val_loss: 0.1174 val_accuracy: 0.9638
Epoch: 10 loss: 0.3814 accuracy: 0.8327 val_loss: 0.1351 val_accuracy: 0.9513
Epoch: 11 loss: 0.3728 accuracy: 0.8335 val_loss: 0.1246 val_accuracy: 0.9592
Epoch: 12 loss: 0.3685 accuracy: 0.8413 val_loss: 0.1231 val_accuracy: 0.9558
Epoch: 13 loss: 0.3567 accuracy: 0.8434 val_loss: 0.1177 val_accuracy: 0.9570
Epoch: 14 loss: 0.3511 accuracy: 0.8463 val_loss: 0.1268 val_accuracy: 0.9536
Epoch: 15 loss: 0.3560 accuracy: 0.8450 val_loss: 0.1128 val_accuracy: 0.9649
Epoch: 16 loss: 0.3491 accuracy: 0.8458 val_loss: 0.1140 val_accuracy: 0.9558
Epoch: 17 loss: 0.3463 accuracy: 0.8471 val_loss: 0.1406 val_accuracy: 0.9468
Epoch: 18 loss: 0.3378 accuracy: 0.8508 val_loss: 0.1224 val_accuracy: 0.9547
Epoch: 19 loss: 0.3351 accuracy: 0.8553 val_loss: 0.1292 val_accuracy: 0.9570
Epoch: 20 loss: 0.3338 accuracy: 0.8526 val_loss: 0.1311 val_accuracy: 0.9490
Job ended!
