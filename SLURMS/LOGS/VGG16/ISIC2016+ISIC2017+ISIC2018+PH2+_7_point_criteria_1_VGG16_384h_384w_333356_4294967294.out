Thu 09 May 2024 03:10:44 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'PH2', '_7_point_criteria']
IMG_SIZE: [384, 384]
CLASSIFIER: VGG16
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 5 dbs
Combining 2th db out of 5 dbs
Combining 3th db out of 5 dbs
Combining 4th db out of 5 dbs
Combining 5th db out of 5 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
vgg16 (Functional)           (None, 512)               14714688  
_________________________________________________________________
dense (Dense)                (None, 512)               262656    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 15,112,258
Trainable params: 396,034
Non-trainable params: 14,716,224
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+PH2+_7_point_criteria_aug_VGG16_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+PH2+_7_point_criteria_aug_VGG16_384h_384w_None
Epoch: 1 loss: 1.0106 accuracy: 0.6942 val_loss: 0.7631 val_accuracy: 0.8030
Epoch: 2 loss: 0.7672 accuracy: 0.7696 val_loss: 0.7016 val_accuracy: 0.8113
Epoch: 3 loss: 0.6902 accuracy: 0.7881 val_loss: 0.6882 val_accuracy: 0.8072
Epoch: 4 loss: 0.6542 accuracy: 0.7953 val_loss: 0.6693 val_accuracy: 0.8072
Epoch: 5 loss: 0.6293 accuracy: 0.8003 val_loss: 0.6373 val_accuracy: 0.8127
Epoch: 6 loss: 0.6051 accuracy: 0.8065 val_loss: 0.6608 val_accuracy: 0.7824
Epoch: 7 loss: 0.5895 accuracy: 0.8086 val_loss: 0.6181 val_accuracy: 0.8072
Epoch: 8 loss: 0.5741 accuracy: 0.8146 val_loss: 0.6328 val_accuracy: 0.8085
Epoch: 9 loss: 0.5660 accuracy: 0.8147 val_loss: 0.6248 val_accuracy: 0.7906
Epoch: 10 loss: 0.5529 accuracy: 0.8184 val_loss: 0.6251 val_accuracy: 0.8017
Epoch: 11 loss: 0.5400 accuracy: 0.8238 val_loss: 0.6214 val_accuracy: 0.8085
Epoch: 12 loss: 0.5329 accuracy: 0.8228 val_loss: 0.5876 val_accuracy: 0.8085
Epoch: 13 loss: 0.5227 accuracy: 0.8230 val_loss: 0.5761 val_accuracy: 0.8085
Epoch: 14 loss: 0.5129 accuracy: 0.8292 val_loss: 0.6024 val_accuracy: 0.8058
Epoch: 15 loss: 0.5084 accuracy: 0.8296 val_loss: 0.5756 val_accuracy: 0.8099
Epoch: 16 loss: 0.5063 accuracy: 0.8302 val_loss: 0.5750 val_accuracy: 0.8113
Epoch: 17 loss: 0.4948 accuracy: 0.8328 val_loss: 0.5700 val_accuracy: 0.8085
Epoch: 18 loss: 0.4847 accuracy: 0.8372 val_loss: 0.5659 val_accuracy: 0.8168
Epoch: 19 loss: 0.4854 accuracy: 0.8324 val_loss: 0.5561 val_accuracy: 0.8072
Epoch: 20 loss: 0.4702 accuracy: 0.8392 val_loss: 0.5628 val_accuracy: 0.8085
Epoch: 21 loss: 0.4651 accuracy: 0.8381 val_loss: 0.5661 val_accuracy: 0.8099
Epoch: 22 loss: 0.4619 accuracy: 0.8417 val_loss: 0.5557 val_accuracy: 0.8085
Epoch: 23 loss: 0.4538 accuracy: 0.8435 val_loss: 0.5970 val_accuracy: 0.7741
Epoch: 24 loss: 0.4546 accuracy: 0.8411 val_loss: 0.5535 val_accuracy: 0.8058
Epoch: 25 loss: 0.4449 accuracy: 0.8452 val_loss: 0.5521 val_accuracy: 0.8058
Epoch: 26 loss: 0.4359 accuracy: 0.8466 val_loss: 0.5664 val_accuracy: 0.8003
Epoch: 27 loss: 0.4325 accuracy: 0.8504 val_loss: 0.5449 val_accuracy: 0.8072
Epoch: 28 loss: 0.4316 accuracy: 0.8450 val_loss: 0.5357 val_accuracy: 0.8182
Epoch: 29 loss: 0.4282 accuracy: 0.8495 val_loss: 0.5299 val_accuracy: 0.8072
Epoch: 30 loss: 0.4116 accuracy: 0.8567 val_loss: 0.5768 val_accuracy: 0.7824
Epoch: 31 loss: 0.4136 accuracy: 0.8556 val_loss: 0.5362 val_accuracy: 0.8168
Epoch: 32 loss: 0.4133 accuracy: 0.8536 val_loss: 0.5534 val_accuracy: 0.8140
Epoch: 33 loss: 0.4046 accuracy: 0.8562 val_loss: 0.5389 val_accuracy: 0.8182
Epoch: 34 loss: 0.4029 accuracy: 0.8562 val_loss: 0.5797 val_accuracy: 0.7824

Epoch 00034: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 35 loss: 0.3955 accuracy: 0.8604 val_loss: 0.5417 val_accuracy: 0.8044
Epoch: 36 loss: 0.3971 accuracy: 0.8562 val_loss: 0.5367 val_accuracy: 0.8209
Epoch: 37 loss: 0.3936 accuracy: 0.8552 val_loss: 0.5285 val_accuracy: 0.8044
Epoch: 38 loss: 0.3827 accuracy: 0.8623 val_loss: 0.5407 val_accuracy: 0.8113
Epoch: 39 loss: 0.3823 accuracy: 0.8639 val_loss: 0.5092 val_accuracy: 0.8099
Epoch: 40 loss: 0.3774 accuracy: 0.8655 val_loss: 0.5553 val_accuracy: 0.7879
Epoch: 41 loss: 0.3746 accuracy: 0.8670 val_loss: 0.5257 val_accuracy: 0.8099
Epoch: 42 loss: 0.3752 accuracy: 0.8633 val_loss: 0.5212 val_accuracy: 0.8140
Epoch: 43 loss: 0.3739 accuracy: 0.8670 val_loss: 0.5422 val_accuracy: 0.8030
Epoch: 44 loss: 0.3625 accuracy: 0.8718 val_loss: 0.5404 val_accuracy: 0.8085

Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 45 loss: 0.3543 accuracy: 0.8737 val_loss: 0.5243 val_accuracy: 0.8058
Epoch: 46 loss: 0.3592 accuracy: 0.8717 val_loss: 0.5436 val_accuracy: 0.8044
Epoch: 47 loss: 0.3463 accuracy: 0.8758 val_loss: 0.5412 val_accuracy: 0.8099
Epoch: 48 loss: 0.3445 accuracy: 0.8763 val_loss: 0.5283 val_accuracy: 0.8017
Epoch: 49 loss: 0.3497 accuracy: 0.8725 val_loss: 0.5245 val_accuracy: 0.8196

Epoch 00049: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
End of augmented training
Finish
Job ended!
