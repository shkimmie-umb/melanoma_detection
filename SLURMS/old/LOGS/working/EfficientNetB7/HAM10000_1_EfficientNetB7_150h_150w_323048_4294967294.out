Tue 27 Feb 2024 05:17:28 PM EST
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['HAM10000']
IMG_SIZE: [150, 150]
CLASSIFIER: EfficientNetB7
SELF_AUG: 1
JOB_INDEX: None
Combining...
Combining 1 db out of 1 dbs
Stacking training images
Stacking training labels
Stacking validation images
Stacking validation labels
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb7 (Functional)  (None, 2560)              64097687  
_________________________________________________________________
dense (Dense)                (None, 512)               1311232   
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 65,543,833
Trainable params: 1,444,610
Non-trainable params: 64,099,223
_________________________________________________________________
Fitting HAM10000_aug_EfficientNetB7_150h_150w_None model...
model_name: HAM10000_aug_EfficientNetB7_150h_150w_None
Epoch: 1 loss: 0.6383 accuracy: 0.6597 val_loss: 0.4385 val_accuracy: 0.9694
Epoch: 2 loss: 0.6026 accuracy: 0.7078 val_loss: 0.4222 val_accuracy: 0.9694
Epoch: 3 loss: 0.5972 accuracy: 0.7075 val_loss: 0.3347 val_accuracy: 0.9694
Epoch: 4 loss: 0.5926 accuracy: 0.7074 val_loss: 0.3458 val_accuracy: 0.9694
Epoch: 5 loss: 0.5876 accuracy: 0.7079 val_loss: 0.3806 val_accuracy: 0.9694
Epoch: 6 loss: 0.5862 accuracy: 0.7084 val_loss: 0.3511 val_accuracy: 0.9694
Epoch: 7 loss: 0.5838 accuracy: 0.7107 val_loss: 0.3080 val_accuracy: 0.9694
Epoch: 8 loss: 0.5797 accuracy: 0.7097 val_loss: 0.2238 val_accuracy: 0.9694
Epoch: 9 loss: 0.5783 accuracy: 0.7112 val_loss: 0.4576 val_accuracy: 0.9672
Epoch: 10 loss: 0.5714 accuracy: 0.7151 val_loss: 0.3284 val_accuracy: 0.9694
Epoch: 11 loss: 0.5745 accuracy: 0.7127 val_loss: 0.2428 val_accuracy: 0.9694
Epoch: 12 loss: 0.5736 accuracy: 0.7152 val_loss: 0.2871 val_accuracy: 0.9694
Epoch: 13 loss: 0.5679 accuracy: 0.7159 val_loss: 0.3836 val_accuracy: 0.9660
Epoch: 14 loss: 0.5672 accuracy: 0.7197 val_loss: 0.2322 val_accuracy: 0.9694
Epoch: 15 loss: 0.5678 accuracy: 0.7205 val_loss: 0.1807 val_accuracy: 0.9694
Epoch: 16 loss: 0.5670 accuracy: 0.7196 val_loss: 0.2060 val_accuracy: 0.9694
Epoch: 17 loss: 0.5654 accuracy: 0.7163 val_loss: 0.3403 val_accuracy: 0.9694
Epoch: 18 loss: 0.5637 accuracy: 0.7185 val_loss: 0.3134 val_accuracy: 0.9660
Epoch: 19 loss: 0.5631 accuracy: 0.7221 val_loss: 0.2958 val_accuracy: 0.9694
Epoch: 20 loss: 0.5607 accuracy: 0.7217 val_loss: 0.2370 val_accuracy: 0.9694
Job ended!
