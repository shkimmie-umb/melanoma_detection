Fri 03 May 2024 10:15:15 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', '_7_point_criteria', 'PAD_UFES_20']
IMG_SIZE: [384, 384]
CLASSIFIER: DenseNet201
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 3 dbs
Combining 2th db out of 3 dbs
Combining 3th db out of 3 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
densenet201 (Functional)     (None, 1920)              18321984  
_________________________________________________________________
dense (Dense)                (None, 512)               983552    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 19,440,450
Trainable params: 1,116,930
Non-trainable params: 18,323,520
_________________________________________________________________
Fitting ISIC2016+_7_point_criteria+PAD_UFES_20_aug_DenseNet201_384h_384w_None model...
model_name: ISIC2016+_7_point_criteria+PAD_UFES_20_aug_DenseNet201_384h_384w_None
Epoch: 1 loss: 1.1701 accuracy: 0.6975 val_loss: 1.0039 val_accuracy: 0.8351
Epoch: 2 loss: 0.9382 accuracy: 0.7869 val_loss: 0.9653 val_accuracy: 0.7877
Epoch: 3 loss: 0.7857 accuracy: 0.8533 val_loss: 0.8621 val_accuracy: 0.8031
Epoch: 4 loss: 0.6994 accuracy: 0.8854 val_loss: 0.7748 val_accuracy: 0.8505
Epoch: 5 loss: 0.6455 accuracy: 0.8990 val_loss: 0.7363 val_accuracy: 0.8493
Epoch: 6 loss: 0.5906 accuracy: 0.9255 val_loss: 0.6999 val_accuracy: 0.8731
Epoch: 7 loss: 0.5489 accuracy: 0.9305 val_loss: 0.7081 val_accuracy: 0.8553
Epoch: 8 loss: 0.5132 accuracy: 0.9475 val_loss: 0.6920 val_accuracy: 0.8660
Epoch: 9 loss: 0.4915 accuracy: 0.9565 val_loss: 0.6503 val_accuracy: 0.8636
Epoch: 10 loss: 0.4687 accuracy: 0.9611 val_loss: 0.6352 val_accuracy: 0.8814
Epoch: 11 loss: 0.4569 accuracy: 0.9611 val_loss: 0.6623 val_accuracy: 0.8624
Epoch: 12 loss: 0.4220 accuracy: 0.9724 val_loss: 0.6231 val_accuracy: 0.8743
Epoch: 13 loss: 0.4193 accuracy: 0.9726 val_loss: 0.6316 val_accuracy: 0.8814
Epoch: 14 loss: 0.4009 accuracy: 0.9751 val_loss: 0.6459 val_accuracy: 0.8754
Epoch: 15 loss: 0.3884 accuracy: 0.9778 val_loss: 0.6064 val_accuracy: 0.8873
Epoch: 16 loss: 0.3857 accuracy: 0.9792 val_loss: 0.6154 val_accuracy: 0.8885
Epoch: 17 loss: 0.3706 accuracy: 0.9832 val_loss: 0.6214 val_accuracy: 0.8814
Epoch: 18 loss: 0.3669 accuracy: 0.9812 val_loss: 0.6243 val_accuracy: 0.8885
Epoch: 19 loss: 0.3584 accuracy: 0.9839 val_loss: 0.6130 val_accuracy: 0.8873
Epoch: 20 loss: 0.3535 accuracy: 0.9857 val_loss: 0.6163 val_accuracy: 0.8814

Epoch 00020: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 21 loss: 0.3449 accuracy: 0.9857 val_loss: 0.6163 val_accuracy: 0.8885
Epoch: 22 loss: 0.3378 accuracy: 0.9878 val_loss: 0.6234 val_accuracy: 0.8861
Epoch: 23 loss: 0.3282 accuracy: 0.9914 val_loss: 0.6184 val_accuracy: 0.8873
Epoch: 24 loss: 0.3268 accuracy: 0.9898 val_loss: 0.6113 val_accuracy: 0.8837
Epoch: 25 loss: 0.3213 accuracy: 0.9925 val_loss: 0.6098 val_accuracy: 0.8897

Epoch 00025: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
End of augmented training
Finish
Job ended!
