Fri 01 Mar 2024 04:09:48 AM EST
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['HAM10000']
IMG_SIZE: [150, 150]
CLASSIFIER: EfficientNetB2
SELF_AUG: 1
JOB_INDEX: None
Combining...
Combining 1 db out of 1 dbs
Stacking training images
Stacking training labels
Stacking validation images
Stacking validation labels
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb2 (Functional)  (None, 1408)              7768569   
_________________________________________________________________
dense (Dense)                (None, 512)               721408    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 8,624,891
Trainable params: 854,786
Non-trainable params: 7,770,105
_________________________________________________________________
Fitting HAM10000_aug_EfficientNetB2_150h_150w_None model...
model_name: HAM10000_aug_EfficientNetB2_150h_150w_None
Epoch: 1 loss: 0.6430 accuracy: 0.7096 val_loss: 0.1835 val_accuracy: 0.9524
Epoch: 2 loss: 0.5127 accuracy: 0.7713 val_loss: 0.1545 val_accuracy: 0.9513
Epoch: 3 loss: 0.4536 accuracy: 0.7978 val_loss: 0.1482 val_accuracy: 0.9536
Epoch: 4 loss: 0.4228 accuracy: 0.8171 val_loss: 0.1476 val_accuracy: 0.9456
Epoch: 5 loss: 0.4024 accuracy: 0.8222 val_loss: 0.1354 val_accuracy: 0.9502
Epoch: 6 loss: 0.3811 accuracy: 0.8324 val_loss: 0.1537 val_accuracy: 0.9445
Epoch: 7 loss: 0.3704 accuracy: 0.8402 val_loss: 0.1419 val_accuracy: 0.9502
Epoch: 8 loss: 0.3588 accuracy: 0.8461 val_loss: 0.1340 val_accuracy: 0.9581
Epoch: 9 loss: 0.3463 accuracy: 0.8485 val_loss: 0.1300 val_accuracy: 0.9581
Epoch: 10 loss: 0.3364 accuracy: 0.8533 val_loss: 0.1235 val_accuracy: 0.9558
Epoch: 11 loss: 0.3382 accuracy: 0.8544 val_loss: 0.1380 val_accuracy: 0.9524
Epoch: 12 loss: 0.3220 accuracy: 0.8589 val_loss: 0.1338 val_accuracy: 0.9524
Epoch: 13 loss: 0.3072 accuracy: 0.8675 val_loss: 0.1318 val_accuracy: 0.9547
Epoch: 14 loss: 0.3052 accuracy: 0.8694 val_loss: 0.1296 val_accuracy: 0.9524
Epoch: 15 loss: 0.2989 accuracy: 0.8713 val_loss: 0.1403 val_accuracy: 0.9479
Epoch: 16 loss: 0.2915 accuracy: 0.8757 val_loss: 0.1362 val_accuracy: 0.9513
Epoch: 17 loss: 0.2834 accuracy: 0.8796 val_loss: 0.1378 val_accuracy: 0.9581
Epoch: 18 loss: 0.2734 accuracy: 0.8817 val_loss: 0.1318 val_accuracy: 0.9570
Epoch: 19 loss: 0.2685 accuracy: 0.8855 val_loss: 0.1351 val_accuracy: 0.9547
Epoch: 20 loss: 0.2659 accuracy: 0.8884 val_loss: 0.1340 val_accuracy: 0.9547
Job ended!
