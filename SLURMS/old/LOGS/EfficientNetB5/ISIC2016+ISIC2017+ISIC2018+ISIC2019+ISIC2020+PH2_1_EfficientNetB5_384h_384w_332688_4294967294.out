Tue 07 May 2024 07:23:52 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'ISIC2019', 'ISIC2020', 'PH2']
IMG_SIZE: [384, 384]
CLASSIFIER: EfficientNetB5
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 6 dbs
Combining 2th db out of 6 dbs
Combining 3th db out of 6 dbs
Combining 4th db out of 6 dbs
Combining 5th db out of 6 dbs
Combining 6th db out of 6 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb5 (Functional)  (None, 2048)              28513527  
_________________________________________________________________
dense (Dense)                (None, 512)               1049088   
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 29,697,529
Trainable params: 1,182,466
Non-trainable params: 28,515,063
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020+PH2_aug_EfficientNetB5_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020+PH2_aug_EfficientNetB5_384h_384w_None
Epoch: 1 loss: 1.0962 accuracy: 0.6650 val_loss: 0.6967 val_accuracy: 0.9091
Epoch: 2 loss: 0.9373 accuracy: 0.7159 val_loss: 0.6259 val_accuracy: 0.9091
Epoch: 3 loss: 0.8429 accuracy: 0.7195 val_loss: 0.5705 val_accuracy: 0.9091
Epoch: 4 loss: 0.7677 accuracy: 0.7184 val_loss: 0.5998 val_accuracy: 0.9091
Epoch: 5 loss: 0.7062 accuracy: 0.7229 val_loss: 0.5051 val_accuracy: 0.9091
Epoch: 6 loss: 0.6681 accuracy: 0.7239 val_loss: 0.4513 val_accuracy: 0.9091
Epoch: 7 loss: 0.6439 accuracy: 0.7239 val_loss: 0.4830 val_accuracy: 0.9091
Epoch: 8 loss: 0.6317 accuracy: 0.7221 val_loss: 0.4687 val_accuracy: 0.9091
Epoch: 9 loss: 0.6222 accuracy: 0.7224 val_loss: 0.4304 val_accuracy: 0.9091
Epoch: 10 loss: 0.6125 accuracy: 0.7255 val_loss: 0.4493 val_accuracy: 0.9091
Epoch: 11 loss: 0.6103 accuracy: 0.7235 val_loss: 0.4174 val_accuracy: 0.9091
Epoch: 12 loss: 0.6076 accuracy: 0.7223 val_loss: 0.4180 val_accuracy: 0.9091
Epoch: 13 loss: 0.6049 accuracy: 0.7229 val_loss: 0.3987 val_accuracy: 0.9091
Epoch: 14 loss: 0.6013 accuracy: 0.7240 val_loss: 0.4863 val_accuracy: 0.9091
Epoch: 15 loss: 0.5982 accuracy: 0.7257 val_loss: 0.4180 val_accuracy: 0.9091
Epoch: 16 loss: 0.5971 accuracy: 0.7252 val_loss: 0.4560 val_accuracy: 0.9091
Epoch: 17 loss: 0.5990 accuracy: 0.7227 val_loss: 0.4273 val_accuracy: 0.9091
Epoch: 18 loss: 0.5973 accuracy: 0.7233 val_loss: 0.4133 val_accuracy: 0.9091

Epoch 00018: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 19 loss: 0.5963 accuracy: 0.7233 val_loss: 0.4139 val_accuracy: 0.9091
Epoch: 20 loss: 0.5953 accuracy: 0.7239 val_loss: 0.4196 val_accuracy: 0.9091
Epoch: 21 loss: 0.5961 accuracy: 0.7225 val_loss: 0.4155 val_accuracy: 0.9091
Epoch: 22 loss: 0.5979 accuracy: 0.7203 val_loss: 0.4642 val_accuracy: 0.9091
Epoch: 23 loss: 0.5925 accuracy: 0.7255 val_loss: 0.4265 val_accuracy: 0.9091

Epoch 00023: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
End of augmented training
Finish
Job ended!
