Tue 27 Feb 2024 12:21:52 PM EST
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['HAM10000']
IMG_SIZE: [150, 150]
CLASSIFIER: EfficientNetB5
SELF_AUG: 1
JOB_INDEX: None
Combining...
Combining 1 db out of 1 dbs
Stacking training images
Stacking training labels
Stacking validation images
Stacking validation labels
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb5 (Functional)  (None, 2048)              28513527  
_________________________________________________________________
dense (Dense)                (None, 512)               1049088   
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
dropout_1 (Dropout)          (None, 256)               0         
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 29,697,529
Trainable params: 1,182,466
Non-trainable params: 28,515,063
_________________________________________________________________
Fitting HAM10000_aug_EfficientNetB5_150h_150w_None model...
model_name: HAM10000_aug_EfficientNetB5_150h_150w_None
Epoch: 1 loss: 0.6335 accuracy: 0.6648 val_loss: 0.4178 val_accuracy: 0.9694
Epoch: 2 loss: 0.5937 accuracy: 0.7085 val_loss: 0.3383 val_accuracy: 0.9694
Epoch: 3 loss: 0.5883 accuracy: 0.7087 val_loss: 0.4614 val_accuracy: 0.9694
Epoch: 4 loss: 0.5901 accuracy: 0.7080 val_loss: 0.3032 val_accuracy: 0.9694
Epoch: 5 loss: 0.5859 accuracy: 0.7091 val_loss: 0.2676 val_accuracy: 0.9694
Epoch: 6 loss: 0.5860 accuracy: 0.7094 val_loss: 0.2545 val_accuracy: 0.9694
Epoch: 7 loss: 0.5821 accuracy: 0.7132 val_loss: 0.3725 val_accuracy: 0.9638
Epoch: 8 loss: 0.5818 accuracy: 0.7112 val_loss: 0.3206 val_accuracy: 0.9694
Epoch: 9 loss: 0.5794 accuracy: 0.7144 val_loss: 0.3325 val_accuracy: 0.9694
Epoch: 10 loss: 0.5739 accuracy: 0.7169 val_loss: 0.3107 val_accuracy: 0.9672
Epoch: 11 loss: 0.5756 accuracy: 0.7143 val_loss: 0.4282 val_accuracy: 0.9558
Epoch: 12 loss: 0.5730 accuracy: 0.7163 val_loss: 0.2857 val_accuracy: 0.9694
Epoch: 13 loss: 0.5728 accuracy: 0.7159 val_loss: 0.2953 val_accuracy: 0.9694
Epoch: 14 loss: 0.5728 accuracy: 0.7164 val_loss: 0.4076 val_accuracy: 0.9547
Epoch: 15 loss: 0.5667 accuracy: 0.7179 val_loss: 0.2816 val_accuracy: 0.9581
Epoch: 16 loss: 0.5676 accuracy: 0.7179 val_loss: 0.3629 val_accuracy: 0.9502
Epoch: 17 loss: 0.5622 accuracy: 0.7189 val_loss: 0.2888 val_accuracy: 0.9604
Epoch: 18 loss: 0.5660 accuracy: 0.7197 val_loss: 0.3222 val_accuracy: 0.9615
Epoch: 19 loss: 0.5644 accuracy: 0.7197 val_loss: 0.2820 val_accuracy: 0.9683
Epoch: 20 loss: 0.5607 accuracy: 0.7197 val_loss: 0.3065 val_accuracy: 0.9592
Job ended!
