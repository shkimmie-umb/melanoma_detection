Mon 06 May 2024 05:06:00 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2018', 'ISIC2019']
IMG_SIZE: [384, 384]
CLASSIFIER: ResNet101V2
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 3 dbs
Combining 2th db out of 3 dbs
Combining 3th db out of 3 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
resnet101v2 (Functional)     (None, 2048)              42626560  
_________________________________________________________________
dense (Dense)                (None, 512)               1049088   
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 43,810,562
Trainable params: 1,182,466
Non-trainable params: 42,628,096
_________________________________________________________________
Fitting ISIC2016+ISIC2018+ISIC2019_aug_ResNet101V2_384h_384w_None model...
model_name: ISIC2016+ISIC2018+ISIC2019_aug_ResNet101V2_384h_384w_None
Epoch: 1 loss: 0.9456 accuracy: 0.8030 val_loss: 0.8807 val_accuracy: 0.8180
Epoch: 2 loss: 0.7596 accuracy: 0.8616 val_loss: 0.7823 val_accuracy: 0.8426
Epoch: 3 loss: 0.6806 accuracy: 0.8786 val_loss: 0.7516 val_accuracy: 0.8399
Epoch: 4 loss: 0.6158 accuracy: 0.8945 val_loss: 0.6785 val_accuracy: 0.8634
Epoch: 5 loss: 0.5656 accuracy: 0.9057 val_loss: 0.6371 val_accuracy: 0.8741
Epoch: 6 loss: 0.5237 accuracy: 0.9137 val_loss: 0.6351 val_accuracy: 0.8647
Epoch: 7 loss: 0.4892 accuracy: 0.9186 val_loss: 0.6059 val_accuracy: 0.8706
Epoch: 8 loss: 0.4536 accuracy: 0.9282 val_loss: 0.5613 val_accuracy: 0.8881
Epoch: 9 loss: 0.4284 accuracy: 0.9306 val_loss: 0.5514 val_accuracy: 0.8803
Epoch: 10 loss: 0.4054 accuracy: 0.9363 val_loss: 0.5576 val_accuracy: 0.8752
Epoch: 11 loss: 0.3840 accuracy: 0.9392 val_loss: 0.5041 val_accuracy: 0.8958
Epoch: 12 loss: 0.3623 accuracy: 0.9448 val_loss: 0.5402 val_accuracy: 0.8761
Epoch: 13 loss: 0.3459 accuracy: 0.9469 val_loss: 0.4955 val_accuracy: 0.8930
Epoch: 14 loss: 0.3314 accuracy: 0.9498 val_loss: 0.4928 val_accuracy: 0.8919
Epoch: 15 loss: 0.3181 accuracy: 0.9510 val_loss: 0.4646 val_accuracy: 0.8952
Epoch: 16 loss: 0.3124 accuracy: 0.9506 val_loss: 0.4483 val_accuracy: 0.9053
Epoch: 17 loss: 0.2984 accuracy: 0.9536 val_loss: 0.4594 val_accuracy: 0.8998
Epoch: 18 loss: 0.2872 accuracy: 0.9557 val_loss: 0.4848 val_accuracy: 0.8908
Epoch: 19 loss: 0.2771 accuracy: 0.9575 val_loss: 0.4436 val_accuracy: 0.9048
Epoch: 20 loss: 0.2670 accuracy: 0.9590 val_loss: 0.4720 val_accuracy: 0.8893
Epoch: 21 loss: 0.2585 accuracy: 0.9597 val_loss: 0.4551 val_accuracy: 0.9042
Epoch: 22 loss: 0.2513 accuracy: 0.9614 val_loss: 0.4281 val_accuracy: 0.9070
Epoch: 23 loss: 0.2434 accuracy: 0.9627 val_loss: 0.4246 val_accuracy: 0.9062
Epoch: 24 loss: 0.2383 accuracy: 0.9617 val_loss: 0.4378 val_accuracy: 0.8996
Epoch: 25 loss: 0.2335 accuracy: 0.9628 val_loss: 0.4195 val_accuracy: 0.9033
Epoch: 26 loss: 0.2303 accuracy: 0.9632 val_loss: 0.4255 val_accuracy: 0.8949
Epoch: 27 loss: 0.2218 accuracy: 0.9645 val_loss: 0.4155 val_accuracy: 0.8987
Epoch: 28 loss: 0.2124 accuracy: 0.9670 val_loss: 0.4165 val_accuracy: 0.9037
Epoch: 29 loss: 0.2088 accuracy: 0.9667 val_loss: 0.4428 val_accuracy: 0.8978
Epoch: 30 loss: 0.2018 accuracy: 0.9698 val_loss: 0.4648 val_accuracy: 0.8858
Epoch: 31 loss: 0.1986 accuracy: 0.9681 val_loss: 0.3901 val_accuracy: 0.9160
Epoch: 32 loss: 0.1982 accuracy: 0.9685 val_loss: 0.4118 val_accuracy: 0.8991
Epoch: 33 loss: 0.1926 accuracy: 0.9700 val_loss: 0.3857 val_accuracy: 0.9101
Epoch: 34 loss: 0.1880 accuracy: 0.9701 val_loss: 0.4365 val_accuracy: 0.8906
Epoch: 35 loss: 0.1838 accuracy: 0.9716 val_loss: 0.3976 val_accuracy: 0.9176
Epoch: 36 loss: 0.1870 accuracy: 0.9692 val_loss: 0.4192 val_accuracy: 0.8950
Epoch: 37 loss: 0.1831 accuracy: 0.9705 val_loss: 0.4161 val_accuracy: 0.8949
Epoch: 38 loss: 0.1723 accuracy: 0.9735 val_loss: 0.4147 val_accuracy: 0.8965

Epoch 00038: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 39 loss: 0.1671 accuracy: 0.9754 val_loss: 0.3836 val_accuracy: 0.9110
Epoch: 40 loss: 0.1588 accuracy: 0.9782 val_loss: 0.3845 val_accuracy: 0.9099
Epoch: 41 loss: 0.1566 accuracy: 0.9782 val_loss: 0.3804 val_accuracy: 0.9116
Epoch: 42 loss: 0.1534 accuracy: 0.9786 val_loss: 0.3694 val_accuracy: 0.9132
Epoch: 43 loss: 0.1507 accuracy: 0.9785 val_loss: 0.3872 val_accuracy: 0.9119
Epoch: 44 loss: 0.1506 accuracy: 0.9781 val_loss: 0.3732 val_accuracy: 0.9187
Epoch: 45 loss: 0.1481 accuracy: 0.9796 val_loss: 0.3920 val_accuracy: 0.9114
Epoch: 46 loss: 0.1427 accuracy: 0.9810 val_loss: 0.4032 val_accuracy: 0.9110
Epoch: 47 loss: 0.1404 accuracy: 0.9808 val_loss: 0.4143 val_accuracy: 0.9088

Epoch 00047: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 48 loss: 0.1337 accuracy: 0.9830 val_loss: 0.3857 val_accuracy: 0.9171
Epoch: 49 loss: 0.1293 accuracy: 0.9843 val_loss: 0.3847 val_accuracy: 0.9197
Epoch: 50 loss: 0.1253 accuracy: 0.9852 val_loss: 0.3909 val_accuracy: 0.9189
Epoch: 51 loss: 0.1237 accuracy: 0.9856 val_loss: 0.3996 val_accuracy: 0.9160
Epoch: 52 loss: 0.1211 accuracy: 0.9858 val_loss: 0.3916 val_accuracy: 0.9182

Epoch 00052: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
End of augmented training
Finish
Job ended!
