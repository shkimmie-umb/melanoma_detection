Fri 03 May 2024 09:17:51 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'MEDNODE', 'KaggleMB']
IMG_SIZE: [384, 384]
CLASSIFIER: EfficientNetB2
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 5 dbs
Combining 2th db out of 5 dbs
Combining 3th db out of 5 dbs
Combining 4th db out of 5 dbs
Combining 5th db out of 5 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb2 (Functional)  (None, 1408)              7768569   
_________________________________________________________________
dense (Dense)                (None, 512)               721408    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 8,624,891
Trainable params: 854,786
Non-trainable params: 7,770,105
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+MEDNODE+KaggleMB_aug_EfficientNetB2_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+MEDNODE+KaggleMB_aug_EfficientNetB2_384h_384w_None
Epoch: 1 loss: 1.2928 accuracy: 0.5382 val_loss: 1.0558 val_accuracy: 0.6995
Epoch: 2 loss: 1.1529 accuracy: 0.5809 val_loss: 1.0128 val_accuracy: 0.6995
Epoch: 3 loss: 1.1031 accuracy: 0.5933 val_loss: 1.0113 val_accuracy: 0.6995
Epoch: 4 loss: 1.0699 accuracy: 0.6000 val_loss: 0.9972 val_accuracy: 0.6995
Epoch: 5 loss: 1.0413 accuracy: 0.6123 val_loss: 0.9555 val_accuracy: 0.6995
Epoch: 6 loss: 1.0067 accuracy: 0.6206 val_loss: 0.9274 val_accuracy: 0.6995
Epoch: 7 loss: 0.9829 accuracy: 0.6254 val_loss: 0.9111 val_accuracy: 0.6995
Epoch: 8 loss: 0.9577 accuracy: 0.6301 val_loss: 0.9077 val_accuracy: 0.6995
Epoch: 9 loss: 0.9360 accuracy: 0.6319 val_loss: 0.8767 val_accuracy: 0.6995
Epoch: 10 loss: 0.9105 accuracy: 0.6393 val_loss: 0.8561 val_accuracy: 0.6995
Epoch: 11 loss: 0.8896 accuracy: 0.6391 val_loss: 0.9717 val_accuracy: 0.3005
Epoch: 12 loss: 0.8671 accuracy: 0.6451 val_loss: 0.8104 val_accuracy: 0.6995
Epoch: 13 loss: 0.8458 accuracy: 0.6454 val_loss: 0.7949 val_accuracy: 0.6995
Epoch: 14 loss: 0.8295 accuracy: 0.6452 val_loss: 0.7808 val_accuracy: 0.6995
Epoch: 15 loss: 0.8115 accuracy: 0.6441 val_loss: 0.7716 val_accuracy: 0.6995
Epoch: 16 loss: 0.7884 accuracy: 0.6520 val_loss: 0.7468 val_accuracy: 0.6995
Epoch: 17 loss: 0.7751 accuracy: 0.6511 val_loss: 0.7292 val_accuracy: 0.6995
Epoch: 18 loss: 0.7588 accuracy: 0.6533 val_loss: 0.7430 val_accuracy: 0.6995
Epoch: 19 loss: 0.7498 accuracy: 0.6463 val_loss: 0.7122 val_accuracy: 0.6995
Epoch: 20 loss: 0.7375 accuracy: 0.6482 val_loss: 0.6907 val_accuracy: 0.6995
Epoch: 21 loss: 0.7209 accuracy: 0.6573 val_loss: 0.6808 val_accuracy: 0.6995
Epoch: 22 loss: 0.7127 accuracy: 0.6570 val_loss: 0.6699 val_accuracy: 0.6995
Epoch: 23 loss: 0.7056 accuracy: 0.6540 val_loss: 0.6635 val_accuracy: 0.6995
Epoch: 24 loss: 0.7006 accuracy: 0.6523 val_loss: 0.7118 val_accuracy: 0.6995
Epoch: 25 loss: 0.6943 accuracy: 0.6519 val_loss: 0.6558 val_accuracy: 0.6995
Epoch: 26 loss: 0.6870 accuracy: 0.6556 val_loss: 0.6672 val_accuracy: 0.6995
Epoch: 27 loss: 0.6825 accuracy: 0.6570 val_loss: 0.8016 val_accuracy: 0.3005
Epoch: 28 loss: 0.6872 accuracy: 0.6438 val_loss: 0.6414 val_accuracy: 0.6995
Epoch: 29 loss: 0.6783 accuracy: 0.6527 val_loss: 0.6485 val_accuracy: 0.6995
Epoch: 30 loss: 0.6751 accuracy: 0.6578 val_loss: 0.6498 val_accuracy: 0.6995
Epoch: 31 loss: 0.6761 accuracy: 0.6492 val_loss: 0.6363 val_accuracy: 0.6995
Epoch: 32 loss: 0.6724 accuracy: 0.6535 val_loss: 0.6336 val_accuracy: 0.6995
Epoch: 33 loss: 0.6669 accuracy: 0.6601 val_loss: 0.6384 val_accuracy: 0.6995
Epoch: 34 loss: 0.6684 accuracy: 0.6536 val_loss: 0.6312 val_accuracy: 0.6995
Epoch: 35 loss: 0.6670 accuracy: 0.6544 val_loss: 0.6397 val_accuracy: 0.6995
Epoch: 36 loss: 0.6653 accuracy: 0.6566 val_loss: 0.6419 val_accuracy: 0.6995
Epoch: 37 loss: 0.6616 accuracy: 0.6609 val_loss: 0.6309 val_accuracy: 0.6995
Epoch: 38 loss: 0.6625 accuracy: 0.6559 val_loss: 0.6362 val_accuracy: 0.6995
Epoch: 39 loss: 0.6624 accuracy: 0.6559 val_loss: 0.6344 val_accuracy: 0.6995
Epoch: 40 loss: 0.6603 accuracy: 0.6584 val_loss: 0.6278 val_accuracy: 0.6995
Epoch: 41 loss: 0.6621 accuracy: 0.6547 val_loss: 0.6258 val_accuracy: 0.6995
Epoch: 42 loss: 0.6612 accuracy: 0.6542 val_loss: 0.6233 val_accuracy: 0.6995
Epoch: 43 loss: 0.6621 accuracy: 0.6527 val_loss: 0.6327 val_accuracy: 0.6995
Epoch: 44 loss: 0.6634 accuracy: 0.6478 val_loss: 0.6383 val_accuracy: 0.6995
Epoch: 45 loss: 0.6608 accuracy: 0.6534 val_loss: 0.6228 val_accuracy: 0.6995
Epoch: 46 loss: 0.6586 accuracy: 0.6544 val_loss: 0.6343 val_accuracy: 0.6995
Epoch: 47 loss: 0.6582 accuracy: 0.6549 val_loss: 0.6276 val_accuracy: 0.6995
Epoch: 48 loss: 0.6606 accuracy: 0.6503 val_loss: 0.6232 val_accuracy: 0.6995
Epoch: 49 loss: 0.6575 accuracy: 0.6546 val_loss: 0.6240 val_accuracy: 0.6995
Epoch: 50 loss: 0.6557 accuracy: 0.6577 val_loss: 0.6201 val_accuracy: 0.6995
Epoch: 51 loss: 0.6552 accuracy: 0.6559 val_loss: 0.6397 val_accuracy: 0.6995
Epoch: 52 loss: 0.6550 accuracy: 0.6578 val_loss: 0.6386 val_accuracy: 0.6995
Epoch: 53 loss: 0.6600 accuracy: 0.6478 val_loss: 0.6317 val_accuracy: 0.6995
Epoch: 54 loss: 0.6586 accuracy: 0.6495 val_loss: 0.6273 val_accuracy: 0.6995
Epoch: 55 loss: 0.6524 accuracy: 0.6589 val_loss: 0.6243 val_accuracy: 0.6995

Epoch 00055: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 56 loss: 0.6553 accuracy: 0.6528 val_loss: 0.6194 val_accuracy: 0.6995
Epoch: 57 loss: 0.6583 accuracy: 0.6486 val_loss: 0.6189 val_accuracy: 0.6995
Epoch: 58 loss: 0.6545 accuracy: 0.6534 val_loss: 0.6196 val_accuracy: 0.6995
Epoch: 59 loss: 0.6514 accuracy: 0.6581 val_loss: 0.6194 val_accuracy: 0.6995
Epoch: 60 loss: 0.6523 accuracy: 0.6562 val_loss: 0.6194 val_accuracy: 0.6995
Epoch: 61 loss: 0.6484 accuracy: 0.6619 val_loss: 0.6224 val_accuracy: 0.6995
Epoch: 62 loss: 0.6529 accuracy: 0.6545 val_loss: 0.6203 val_accuracy: 0.6995

Epoch 00062: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 63 loss: 0.6513 accuracy: 0.6558 val_loss: 0.6257 val_accuracy: 0.6995
Epoch: 64 loss: 0.6496 accuracy: 0.6581 val_loss: 0.6218 val_accuracy: 0.6995
Epoch: 65 loss: 0.6477 accuracy: 0.6603 val_loss: 0.6176 val_accuracy: 0.6995
Epoch: 66 loss: 0.6522 accuracy: 0.6547 val_loss: 0.6255 val_accuracy: 0.6995
Epoch: 67 loss: 0.6562 accuracy: 0.6465 val_loss: 0.6205 val_accuracy: 0.6995
Epoch: 68 loss: 0.6518 accuracy: 0.6540 val_loss: 0.6161 val_accuracy: 0.6995
Epoch: 69 loss: 0.6553 accuracy: 0.6495 val_loss: 0.6216 val_accuracy: 0.6995
Epoch: 70 loss: 0.6500 accuracy: 0.6558 val_loss: 0.6235 val_accuracy: 0.6995
Epoch: 71 loss: 0.6519 accuracy: 0.6542 val_loss: 0.6197 val_accuracy: 0.6995
Epoch: 72 loss: 0.6497 accuracy: 0.6567 val_loss: 0.6219 val_accuracy: 0.6995
Epoch: 73 loss: 0.6527 accuracy: 0.6514 val_loss: 0.6181 val_accuracy: 0.6995

Epoch 00073: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 74 loss: 0.6494 accuracy: 0.6562 val_loss: 0.6227 val_accuracy: 0.6995
Epoch: 75 loss: 0.6465 accuracy: 0.6605 val_loss: 0.6183 val_accuracy: 0.6995
Epoch: 76 loss: 0.6521 accuracy: 0.6513 val_loss: 0.6190 val_accuracy: 0.6995
Epoch: 77 loss: 0.6459 accuracy: 0.6599 val_loss: 0.6290 val_accuracy: 0.6995
Epoch: 78 loss: 0.6485 accuracy: 0.6567 val_loss: 0.6151 val_accuracy: 0.6995
Epoch: 79 loss: 0.6513 accuracy: 0.6526 val_loss: 0.6186 val_accuracy: 0.6995
Epoch: 80 loss: 0.6508 accuracy: 0.6527 val_loss: 0.6198 val_accuracy: 0.6995
Epoch: 81 loss: 0.6488 accuracy: 0.6557 val_loss: 0.6159 val_accuracy: 0.6995
Epoch: 82 loss: 0.6512 accuracy: 0.6524 val_loss: 0.6207 val_accuracy: 0.6995
Epoch: 83 loss: 0.6488 accuracy: 0.6560 val_loss: 0.6209 val_accuracy: 0.6995

Epoch 00083: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
Epoch: 84 loss: 0.6487 accuracy: 0.6557 val_loss: 0.6183 val_accuracy: 0.6995
Epoch: 85 loss: 0.6521 accuracy: 0.6497 val_loss: 0.6239 val_accuracy: 0.6995
Epoch: 86 loss: 0.6480 accuracy: 0.6561 val_loss: 0.6280 val_accuracy: 0.6995
Epoch: 87 loss: 0.6490 accuracy: 0.6540 val_loss: 0.6184 val_accuracy: 0.6995
Epoch: 88 loss: 0.6505 accuracy: 0.6529 val_loss: 0.6179 val_accuracy: 0.6995

Epoch 00088: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.
End of augmented training
Finish
Job ended!
