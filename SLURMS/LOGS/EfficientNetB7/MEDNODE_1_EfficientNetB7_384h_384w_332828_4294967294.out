Wed 08 May 2024 07:50:52 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['MEDNODE']
IMG_SIZE: [384, 384]
CLASSIFIER: EfficientNetB7
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 1 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb7 (Functional)  (None, 2560)              64097687  
_________________________________________________________________
dense (Dense)                (None, 512)               1311232   
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 65,543,833
Trainable params: 1,444,610
Non-trainable params: 64,099,223
_________________________________________________________________
Fitting MEDNODE_aug_EfficientNetB7_384h_384w_None model...
model_name: MEDNODE_aug_EfficientNetB7_384h_384w_None
Epoch: 1 loss: 1.7079 accuracy: 0.4635 val_loss: 1.2852 val_accuracy: 0.5294
Epoch: 2 loss: 1.5950 accuracy: 0.4740 val_loss: 1.2828 val_accuracy: 0.5294
Epoch: 3 loss: 1.5501 accuracy: 0.5469 val_loss: 1.2805 val_accuracy: 0.5294
Epoch: 4 loss: 1.5310 accuracy: 0.5677 val_loss: 1.2778 val_accuracy: 0.5294
Epoch: 5 loss: 1.4942 accuracy: 0.5365 val_loss: 1.2755 val_accuracy: 0.5294
Epoch: 6 loss: 1.5421 accuracy: 0.4792 val_loss: 1.2734 val_accuracy: 0.5294
Epoch: 7 loss: 1.4387 accuracy: 0.5573 val_loss: 1.2713 val_accuracy: 0.5294
Epoch: 8 loss: 1.4293 accuracy: 0.5625 val_loss: 1.2694 val_accuracy: 0.5294
Epoch: 9 loss: 1.6046 accuracy: 0.4792 val_loss: 1.2674 val_accuracy: 0.5294
Epoch: 10 loss: 1.4918 accuracy: 0.5312 val_loss: 1.2647 val_accuracy: 0.5294
Epoch: 11 loss: 1.4783 accuracy: 0.5104 val_loss: 1.2623 val_accuracy: 0.5294
Epoch: 12 loss: 1.4396 accuracy: 0.5000 val_loss: 1.2602 val_accuracy: 0.5294
Epoch: 13 loss: 1.5265 accuracy: 0.4792 val_loss: 1.2583 val_accuracy: 0.5294
Epoch: 14 loss: 1.4673 accuracy: 0.5104 val_loss: 1.2563 val_accuracy: 0.5294
Epoch: 15 loss: 1.4392 accuracy: 0.5312 val_loss: 1.2543 val_accuracy: 0.5294
Epoch: 16 loss: 1.4667 accuracy: 0.4896 val_loss: 1.2524 val_accuracy: 0.5294
Epoch: 17 loss: 1.4021 accuracy: 0.5365 val_loss: 1.2504 val_accuracy: 0.5294
Epoch: 18 loss: 1.4004 accuracy: 0.5052 val_loss: 1.2486 val_accuracy: 0.5294
Epoch: 19 loss: 1.4209 accuracy: 0.5052 val_loss: 1.2469 val_accuracy: 0.5294
Epoch: 20 loss: 1.4723 accuracy: 0.5000 val_loss: 1.2451 val_accuracy: 0.5294
Epoch: 21 loss: 1.4771 accuracy: 0.4792 val_loss: 1.2434 val_accuracy: 0.5294
Epoch: 22 loss: 1.4350 accuracy: 0.4635 val_loss: 1.2418 val_accuracy: 0.5294
Epoch: 23 loss: 1.3656 accuracy: 0.5312 val_loss: 1.2403 val_accuracy: 0.5294
Epoch: 24 loss: 1.4161 accuracy: 0.4896 val_loss: 1.2385 val_accuracy: 0.5294
Epoch: 25 loss: 1.4146 accuracy: 0.4688 val_loss: 1.2368 val_accuracy: 0.5294
Epoch: 26 loss: 1.4023 accuracy: 0.4844 val_loss: 1.2352 val_accuracy: 0.5294
Epoch: 27 loss: 1.3606 accuracy: 0.4792 val_loss: 1.2338 val_accuracy: 0.5294
Epoch: 28 loss: 1.3721 accuracy: 0.4896 val_loss: 1.2321 val_accuracy: 0.5294
Epoch: 29 loss: 1.2919 accuracy: 0.5625 val_loss: 1.2305 val_accuracy: 0.5294
Epoch: 30 loss: 1.4167 accuracy: 0.4375 val_loss: 1.2290 val_accuracy: 0.5294
Epoch: 31 loss: 1.3763 accuracy: 0.4896 val_loss: 1.2276 val_accuracy: 0.5294
Epoch: 32 loss: 1.3898 accuracy: 0.5677 val_loss: 1.2263 val_accuracy: 0.5294
Epoch: 33 loss: 1.3575 accuracy: 0.5052 val_loss: 1.2251 val_accuracy: 0.5294
Epoch: 34 loss: 1.3736 accuracy: 0.5104 val_loss: 1.2242 val_accuracy: 0.5294
Epoch: 35 loss: 1.3418 accuracy: 0.5469 val_loss: 1.2241 val_accuracy: 0.4706
Epoch: 36 loss: 1.4019 accuracy: 0.4740 val_loss: 1.2248 val_accuracy: 0.4706
Epoch: 37 loss: 1.4007 accuracy: 0.4531 val_loss: 1.2248 val_accuracy: 0.4706
Epoch: 38 loss: 1.3644 accuracy: 0.5156 val_loss: 1.2244 val_accuracy: 0.4706
Epoch: 39 loss: 1.3054 accuracy: 0.5365 val_loss: 1.2242 val_accuracy: 0.4706
Epoch: 40 loss: 1.2804 accuracy: 0.5521 val_loss: 1.2223 val_accuracy: 0.4706
Epoch: 41 loss: 1.3866 accuracy: 0.4219 val_loss: 1.2203 val_accuracy: 0.4706
Epoch: 42 loss: 1.3093 accuracy: 0.5365 val_loss: 1.2182 val_accuracy: 0.4706
Epoch: 43 loss: 1.2803 accuracy: 0.5729 val_loss: 1.2158 val_accuracy: 0.4706
Epoch: 44 loss: 1.3353 accuracy: 0.4948 val_loss: 1.2148 val_accuracy: 0.4706
Epoch: 45 loss: 1.2748 accuracy: 0.5521 val_loss: 1.2159 val_accuracy: 0.4706
Epoch: 46 loss: 1.3501 accuracy: 0.5000 val_loss: 1.2169 val_accuracy: 0.4706
Epoch: 47 loss: 1.3295 accuracy: 0.5156 val_loss: 1.2179 val_accuracy: 0.4706
Epoch: 48 loss: 1.3547 accuracy: 0.4427 val_loss: 1.2168 val_accuracy: 0.4706
Epoch: 49 loss: 1.2760 accuracy: 0.5208 val_loss: 1.2146 val_accuracy: 0.4706
Epoch: 50 loss: 1.3562 accuracy: 0.5104 val_loss: 1.2123 val_accuracy: 0.4706
Epoch: 51 loss: 1.2817 accuracy: 0.4844 val_loss: 1.2103 val_accuracy: 0.4706
Epoch: 52 loss: 1.3091 accuracy: 0.4896 val_loss: 1.2087 val_accuracy: 0.4706
Epoch: 53 loss: 1.3790 accuracy: 0.4271 val_loss: 1.2068 val_accuracy: 0.4706
Epoch: 54 loss: 1.3282 accuracy: 0.4792 val_loss: 1.2053 val_accuracy: 0.4706
Epoch: 55 loss: 1.2942 accuracy: 0.5052 val_loss: 1.2046 val_accuracy: 0.4706
Epoch: 56 loss: 1.2710 accuracy: 0.4896 val_loss: 1.2040 val_accuracy: 0.4706
Epoch: 57 loss: 1.2779 accuracy: 0.5260 val_loss: 1.2042 val_accuracy: 0.4706
Epoch: 58 loss: 1.3059 accuracy: 0.4948 val_loss: 1.2063 val_accuracy: 0.4706
Epoch: 59 loss: 1.2438 accuracy: 0.5312 val_loss: 1.2096 val_accuracy: 0.4706
Epoch: 60 loss: 1.2886 accuracy: 0.5000 val_loss: 1.2117 val_accuracy: 0.4706
Epoch: 61 loss: 1.2664 accuracy: 0.5104 val_loss: 1.2105 val_accuracy: 0.4706

Epoch 00061: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 62 loss: 1.3662 accuracy: 0.4531 val_loss: 1.2070 val_accuracy: 0.4706
Epoch: 63 loss: 1.2921 accuracy: 0.5469 val_loss: 1.2023 val_accuracy: 0.4706
Epoch: 64 loss: 1.3181 accuracy: 0.4635 val_loss: 1.1995 val_accuracy: 0.4706
Epoch: 65 loss: 1.2539 accuracy: 0.4844 val_loss: 1.1992 val_accuracy: 0.4706
Epoch: 66 loss: 1.2349 accuracy: 0.5052 val_loss: 1.1982 val_accuracy: 0.4706
Epoch: 67 loss: 1.2916 accuracy: 0.4740 val_loss: 1.1959 val_accuracy: 0.4706
Epoch: 68 loss: 1.2465 accuracy: 0.5312 val_loss: 1.1940 val_accuracy: 0.4706
Epoch: 69 loss: 1.2937 accuracy: 0.4896 val_loss: 1.1931 val_accuracy: 0.4706
Epoch: 70 loss: 1.2598 accuracy: 0.5208 val_loss: 1.1924 val_accuracy: 0.4706
Epoch: 71 loss: 1.2816 accuracy: 0.4948 val_loss: 1.1914 val_accuracy: 0.4706
Epoch: 72 loss: 1.2458 accuracy: 0.5208 val_loss: 1.1912 val_accuracy: 0.4706
Epoch: 73 loss: 1.2490 accuracy: 0.4844 val_loss: 1.1909 val_accuracy: 0.4706
Epoch: 74 loss: 1.2675 accuracy: 0.4740 val_loss: 1.1901 val_accuracy: 0.4706
Epoch: 75 loss: 1.2532 accuracy: 0.4896 val_loss: 1.1888 val_accuracy: 0.4706
Epoch: 76 loss: 1.2527 accuracy: 0.5156 val_loss: 1.1870 val_accuracy: 0.4706
Epoch: 77 loss: 1.2368 accuracy: 0.4948 val_loss: 1.1854 val_accuracy: 0.4706
Epoch: 78 loss: 1.2640 accuracy: 0.5052 val_loss: 1.1851 val_accuracy: 0.4706
Epoch: 79 loss: 1.2045 accuracy: 0.5677 val_loss: 1.1851 val_accuracy: 0.4706
Epoch: 80 loss: 1.2412 accuracy: 0.5208 val_loss: 1.1862 val_accuracy: 0.4706
Epoch: 81 loss: 1.2770 accuracy: 0.4583 val_loss: 1.1873 val_accuracy: 0.4706
Epoch: 82 loss: 1.2333 accuracy: 0.5104 val_loss: 1.1870 val_accuracy: 0.4706
Epoch: 83 loss: 1.2622 accuracy: 0.5312 val_loss: 1.1856 val_accuracy: 0.4706

Epoch 00083: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 84 loss: 1.2321 accuracy: 0.5260 val_loss: 1.1851 val_accuracy: 0.4706
Epoch: 85 loss: 1.2911 accuracy: 0.4792 val_loss: 1.1853 val_accuracy: 0.4706
Epoch: 86 loss: 1.2221 accuracy: 0.5312 val_loss: 1.1858 val_accuracy: 0.4706
Epoch: 87 loss: 1.2639 accuracy: 0.5365 val_loss: 1.1858 val_accuracy: 0.4706
Epoch: 88 loss: 1.2641 accuracy: 0.5000 val_loss: 1.1843 val_accuracy: 0.4706
Epoch: 89 loss: 1.2326 accuracy: 0.5729 val_loss: 1.1824 val_accuracy: 0.4706
Epoch: 90 loss: 1.2637 accuracy: 0.5104 val_loss: 1.1796 val_accuracy: 0.4706
Epoch: 91 loss: 1.2327 accuracy: 0.5000 val_loss: 1.1782 val_accuracy: 0.4706
Epoch: 92 loss: 1.2971 accuracy: 0.4792 val_loss: 1.1766 val_accuracy: 0.4706
Epoch: 93 loss: 1.2098 accuracy: 0.5677 val_loss: 1.1751 val_accuracy: 0.5294
Epoch: 94 loss: 1.2243 accuracy: 0.5312 val_loss: 1.1742 val_accuracy: 0.5294
Epoch: 95 loss: 1.2408 accuracy: 0.5000 val_loss: 1.1736 val_accuracy: 0.5294
Epoch: 96 loss: 1.2855 accuracy: 0.4479 val_loss: 1.1739 val_accuracy: 0.4706
Epoch: 97 loss: 1.2207 accuracy: 0.5625 val_loss: 1.1749 val_accuracy: 0.4706
Epoch: 98 loss: 1.2377 accuracy: 0.5312 val_loss: 1.1742 val_accuracy: 0.4706
Epoch: 99 loss: 1.2140 accuracy: 0.5208 val_loss: 1.1732 val_accuracy: 0.4706
Epoch: 100 loss: 1.2167 accuracy: 0.4792 val_loss: 1.1723 val_accuracy: 0.4706
End of augmented training
Finish
Job ended!
