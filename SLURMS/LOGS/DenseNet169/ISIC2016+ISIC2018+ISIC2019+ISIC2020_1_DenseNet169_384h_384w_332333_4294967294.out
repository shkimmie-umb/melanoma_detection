Sat 04 May 2024 09:22:48 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2018', 'ISIC2019', 'ISIC2020']
IMG_SIZE: [384, 384]
CLASSIFIER: DenseNet169
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 4 dbs
Combining 2th db out of 4 dbs
Combining 3th db out of 4 dbs
Combining 4th db out of 4 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
densenet169 (Functional)     (None, 1664)              12642880  
_________________________________________________________________
dense (Dense)                (None, 512)               852480    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 13,630,274
Trainable params: 985,858
Non-trainable params: 12,644,416
_________________________________________________________________
Fitting ISIC2016+ISIC2018+ISIC2019+ISIC2020_aug_DenseNet169_384h_384w_None model...
model_name: ISIC2016+ISIC2018+ISIC2019+ISIC2020_aug_DenseNet169_384h_384w_None
Epoch: 1 loss: 0.7400 accuracy: 0.8392 val_loss: 0.6181 val_accuracy: 0.8797
Epoch: 2 loss: 0.5609 accuracy: 0.8887 val_loss: 0.5134 val_accuracy: 0.9078
Epoch: 3 loss: 0.4977 accuracy: 0.9029 val_loss: 0.4987 val_accuracy: 0.8993
Epoch: 4 loss: 0.4504 accuracy: 0.9117 val_loss: 0.4514 val_accuracy: 0.9097
Epoch: 5 loss: 0.4111 accuracy: 0.9184 val_loss: 0.4697 val_accuracy: 0.8875
Epoch: 6 loss: 0.3808 accuracy: 0.9237 val_loss: 0.4026 val_accuracy: 0.9125
Epoch: 7 loss: 0.3553 accuracy: 0.9282 val_loss: 0.4329 val_accuracy: 0.8904
Epoch: 8 loss: 0.3349 accuracy: 0.9298 val_loss: 0.3565 val_accuracy: 0.9296
Epoch: 9 loss: 0.3095 accuracy: 0.9366 val_loss: 0.3611 val_accuracy: 0.9133
Epoch: 10 loss: 0.2966 accuracy: 0.9374 val_loss: 0.3451 val_accuracy: 0.9213
Epoch: 11 loss: 0.2748 accuracy: 0.9435 val_loss: 0.3303 val_accuracy: 0.9233
Epoch: 12 loss: 0.2671 accuracy: 0.9433 val_loss: 0.3352 val_accuracy: 0.9145
Epoch: 13 loss: 0.2544 accuracy: 0.9445 val_loss: 0.3057 val_accuracy: 0.9297
Epoch: 14 loss: 0.2457 accuracy: 0.9463 val_loss: 0.2980 val_accuracy: 0.9324
Epoch: 15 loss: 0.2354 accuracy: 0.9482 val_loss: 0.3251 val_accuracy: 0.9130
Epoch: 16 loss: 0.2250 accuracy: 0.9514 val_loss: 0.3235 val_accuracy: 0.9146
Epoch: 17 loss: 0.2151 accuracy: 0.9523 val_loss: 0.3012 val_accuracy: 0.9270
Epoch: 18 loss: 0.2129 accuracy: 0.9525 val_loss: 0.2963 val_accuracy: 0.9243
Epoch: 19 loss: 0.2066 accuracy: 0.9538 val_loss: 0.2939 val_accuracy: 0.9223
Epoch: 20 loss: 0.1996 accuracy: 0.9552 val_loss: 0.2773 val_accuracy: 0.9296
Epoch: 21 loss: 0.1905 accuracy: 0.9573 val_loss: 0.3028 val_accuracy: 0.9170
Epoch: 22 loss: 0.1881 accuracy: 0.9572 val_loss: 0.2892 val_accuracy: 0.9202
Epoch: 23 loss: 0.1875 accuracy: 0.9572 val_loss: 0.2652 val_accuracy: 0.9319
Epoch: 24 loss: 0.1774 accuracy: 0.9606 val_loss: 0.2750 val_accuracy: 0.9304
Epoch: 25 loss: 0.1769 accuracy: 0.9594 val_loss: 0.2591 val_accuracy: 0.9355
Epoch: 26 loss: 0.1691 accuracy: 0.9620 val_loss: 0.2780 val_accuracy: 0.9260
Epoch: 27 loss: 0.1687 accuracy: 0.9608 val_loss: 0.2693 val_accuracy: 0.9320
Epoch: 28 loss: 0.1642 accuracy: 0.9619 val_loss: 0.2685 val_accuracy: 0.9300
Epoch: 29 loss: 0.1621 accuracy: 0.9629 val_loss: 0.2788 val_accuracy: 0.9233
Epoch: 30 loss: 0.1563 accuracy: 0.9652 val_loss: 0.2791 val_accuracy: 0.9296

Epoch 00030: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 31 loss: 0.1421 accuracy: 0.9696 val_loss: 0.2660 val_accuracy: 0.9347
Epoch: 32 loss: 0.1428 accuracy: 0.9696 val_loss: 0.2584 val_accuracy: 0.9364
Epoch: 33 loss: 0.1404 accuracy: 0.9704 val_loss: 0.2504 val_accuracy: 0.9373
Epoch: 34 loss: 0.1335 accuracy: 0.9721 val_loss: 0.2527 val_accuracy: 0.9359
Epoch: 35 loss: 0.1328 accuracy: 0.9724 val_loss: 0.2594 val_accuracy: 0.9341
Epoch: 36 loss: 0.1310 accuracy: 0.9729 val_loss: 0.2633 val_accuracy: 0.9370
Epoch: 37 loss: 0.1284 accuracy: 0.9733 val_loss: 0.2542 val_accuracy: 0.9376
Epoch: 38 loss: 0.1253 accuracy: 0.9742 val_loss: 0.2655 val_accuracy: 0.9357

Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 39 loss: 0.1175 accuracy: 0.9766 val_loss: 0.2506 val_accuracy: 0.9422
Epoch: 40 loss: 0.1140 accuracy: 0.9782 val_loss: 0.2481 val_accuracy: 0.9412
Epoch: 41 loss: 0.1084 accuracy: 0.9800 val_loss: 0.2554 val_accuracy: 0.9425
Epoch: 42 loss: 0.1107 accuracy: 0.9798 val_loss: 0.2597 val_accuracy: 0.9396
Epoch: 43 loss: 0.1078 accuracy: 0.9796 val_loss: 0.2657 val_accuracy: 0.9413
Epoch: 44 loss: 0.1070 accuracy: 0.9799 val_loss: 0.2590 val_accuracy: 0.9375
Epoch: 45 loss: 0.1052 accuracy: 0.9805 val_loss: 0.2607 val_accuracy: 0.9400

Epoch 00045: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 46 loss: 0.0989 accuracy: 0.9832 val_loss: 0.2493 val_accuracy: 0.9443
Epoch: 47 loss: 0.0977 accuracy: 0.9835 val_loss: 0.2506 val_accuracy: 0.9414
Epoch: 48 loss: 0.0951 accuracy: 0.9844 val_loss: 0.2492 val_accuracy: 0.9465
Epoch: 49 loss: 0.0935 accuracy: 0.9846 val_loss: 0.2595 val_accuracy: 0.9410
Epoch: 50 loss: 0.0914 accuracy: 0.9856 val_loss: 0.2556 val_accuracy: 0.9421

Epoch 00050: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
End of augmented training
Finish
Job ended!
