Fri 03 May 2024 03:33:24 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'PH2', '_7_point_criteria']
IMG_SIZE: [384, 384]
CLASSIFIER: EfficientNetB1
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 5 dbs
Combining 2th db out of 5 dbs
Combining 3th db out of 5 dbs
Combining 4th db out of 5 dbs
Combining 5th db out of 5 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb1 (Functional)  (None, 1280)              6575239   
_________________________________________________________________
dense (Dense)                (None, 512)               655872    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 7,366,025
Trainable params: 789,250
Non-trainable params: 6,576,775
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+PH2+_7_point_criteria_aug_EfficientNetB1_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+PH2+_7_point_criteria_aug_EfficientNetB1_384h_384w_None
Epoch: 1 loss: 1.2616 accuracy: 0.5632 val_loss: 0.9921 val_accuracy: 0.8017
Epoch: 2 loss: 1.0883 accuracy: 0.6520 val_loss: 0.9829 val_accuracy: 0.8017
Epoch: 3 loss: 1.0406 accuracy: 0.6788 val_loss: 0.8935 val_accuracy: 0.8017
Epoch: 4 loss: 1.0123 accuracy: 0.6909 val_loss: 0.9175 val_accuracy: 0.8017
Epoch: 5 loss: 0.9805 accuracy: 0.7010 val_loss: 0.8649 val_accuracy: 0.8017
Epoch: 6 loss: 0.9714 accuracy: 0.6919 val_loss: 0.8800 val_accuracy: 0.8017
Epoch: 7 loss: 0.9503 accuracy: 0.6938 val_loss: 0.8393 val_accuracy: 0.8017
Epoch: 8 loss: 0.9225 accuracy: 0.7038 val_loss: 0.8370 val_accuracy: 0.8017
Epoch: 9 loss: 0.9050 accuracy: 0.7018 val_loss: 0.8001 val_accuracy: 0.8017
Epoch: 10 loss: 0.8837 accuracy: 0.7043 val_loss: 0.7698 val_accuracy: 0.8017
Epoch: 11 loss: 0.8610 accuracy: 0.7084 val_loss: 0.7590 val_accuracy: 0.8017
Epoch: 12 loss: 0.8550 accuracy: 0.6967 val_loss: 0.7370 val_accuracy: 0.8017
Epoch: 13 loss: 0.8305 accuracy: 0.7056 val_loss: 0.7256 val_accuracy: 0.8017
Epoch: 14 loss: 0.8187 accuracy: 0.7016 val_loss: 0.7079 val_accuracy: 0.8017
Epoch: 15 loss: 0.7993 accuracy: 0.7048 val_loss: 0.6923 val_accuracy: 0.8017
Epoch: 16 loss: 0.7874 accuracy: 0.6996 val_loss: 0.6983 val_accuracy: 0.8017
Epoch: 17 loss: 0.7770 accuracy: 0.6969 val_loss: 0.6662 val_accuracy: 0.8017
Epoch: 18 loss: 0.7618 accuracy: 0.6959 val_loss: 0.6711 val_accuracy: 0.8017
Epoch: 19 loss: 0.7458 accuracy: 0.7017 val_loss: 0.6593 val_accuracy: 0.8017
Epoch: 20 loss: 0.7352 accuracy: 0.6999 val_loss: 0.6360 val_accuracy: 0.8017
Epoch: 21 loss: 0.7277 accuracy: 0.6958 val_loss: 0.6235 val_accuracy: 0.8017
Epoch: 22 loss: 0.7095 accuracy: 0.7053 val_loss: 0.6196 val_accuracy: 0.8017
Epoch: 23 loss: 0.7052 accuracy: 0.7003 val_loss: 0.6276 val_accuracy: 0.8017
Epoch: 24 loss: 0.6989 accuracy: 0.6981 val_loss: 0.5916 val_accuracy: 0.8017
Epoch: 25 loss: 0.6856 accuracy: 0.7050 val_loss: 0.5837 val_accuracy: 0.8017
Epoch: 26 loss: 0.6849 accuracy: 0.6974 val_loss: 0.5951 val_accuracy: 0.8017
Epoch: 27 loss: 0.6742 accuracy: 0.7047 val_loss: 0.5863 val_accuracy: 0.8017
Epoch: 28 loss: 0.6750 accuracy: 0.6983 val_loss: 0.5712 val_accuracy: 0.8017
Epoch: 29 loss: 0.6654 accuracy: 0.7027 val_loss: 0.5497 val_accuracy: 0.8017
Epoch: 30 loss: 0.6638 accuracy: 0.6997 val_loss: 0.5539 val_accuracy: 0.8017
Epoch: 31 loss: 0.6610 accuracy: 0.6992 val_loss: 0.5738 val_accuracy: 0.8017
Epoch: 32 loss: 0.6548 accuracy: 0.7026 val_loss: 0.5619 val_accuracy: 0.8017
Epoch: 33 loss: 0.6476 accuracy: 0.7078 val_loss: 0.5772 val_accuracy: 0.8017
Epoch: 34 loss: 0.6503 accuracy: 0.7016 val_loss: 0.5554 val_accuracy: 0.8017

Epoch 00034: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 35 loss: 0.6492 accuracy: 0.6992 val_loss: 0.5431 val_accuracy: 0.8017
Epoch: 36 loss: 0.6433 accuracy: 0.7043 val_loss: 0.5584 val_accuracy: 0.8017
Epoch: 37 loss: 0.6450 accuracy: 0.7000 val_loss: 0.5520 val_accuracy: 0.8017
Epoch: 38 loss: 0.6445 accuracy: 0.6989 val_loss: 0.5671 val_accuracy: 0.8017
Epoch: 39 loss: 0.6415 accuracy: 0.7005 val_loss: 0.5410 val_accuracy: 0.8017
Epoch: 40 loss: 0.6367 accuracy: 0.7046 val_loss: 0.5487 val_accuracy: 0.8017
Epoch: 41 loss: 0.6374 accuracy: 0.7018 val_loss: 0.5435 val_accuracy: 0.8017
Epoch: 42 loss: 0.6408 accuracy: 0.6971 val_loss: 0.5469 val_accuracy: 0.8017
Epoch: 43 loss: 0.6343 accuracy: 0.7025 val_loss: 0.5412 val_accuracy: 0.8017
Epoch: 44 loss: 0.6352 accuracy: 0.7004 val_loss: 0.5528 val_accuracy: 0.8017

Epoch 00044: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 45 loss: 0.6364 accuracy: 0.6970 val_loss: 0.5288 val_accuracy: 0.8017
Epoch: 46 loss: 0.6322 accuracy: 0.7016 val_loss: 0.5398 val_accuracy: 0.8017
Epoch: 47 loss: 0.6333 accuracy: 0.6995 val_loss: 0.5556 val_accuracy: 0.8017
Epoch: 48 loss: 0.6287 accuracy: 0.7043 val_loss: 0.5427 val_accuracy: 0.8017
Epoch: 49 loss: 0.6251 accuracy: 0.7077 val_loss: 0.5353 val_accuracy: 0.8017
Epoch: 50 loss: 0.6266 accuracy: 0.7045 val_loss: 0.5298 val_accuracy: 0.8017

Epoch 00050: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 51 loss: 0.6309 accuracy: 0.6995 val_loss: 0.5511 val_accuracy: 0.8017
Epoch: 52 loss: 0.6277 accuracy: 0.7020 val_loss: 0.5280 val_accuracy: 0.8017
Epoch: 53 loss: 0.6256 accuracy: 0.7045 val_loss: 0.5351 val_accuracy: 0.8017
Epoch: 54 loss: 0.6206 accuracy: 0.7089 val_loss: 0.5360 val_accuracy: 0.8017
Epoch: 55 loss: 0.6278 accuracy: 0.7010 val_loss: 0.5417 val_accuracy: 0.8017
Epoch: 56 loss: 0.6257 accuracy: 0.7026 val_loss: 0.5486 val_accuracy: 0.8017
Epoch: 57 loss: 0.6219 accuracy: 0.7069 val_loss: 0.5370 val_accuracy: 0.8017

Epoch 00057: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
Epoch: 58 loss: 0.6204 accuracy: 0.7076 val_loss: 0.5302 val_accuracy: 0.8017
Epoch: 59 loss: 0.6208 accuracy: 0.7065 val_loss: 0.5461 val_accuracy: 0.8017
Epoch: 60 loss: 0.6241 accuracy: 0.7030 val_loss: 0.5530 val_accuracy: 0.8017
Epoch: 61 loss: 0.6263 accuracy: 0.6992 val_loss: 0.5491 val_accuracy: 0.8017
Epoch: 62 loss: 0.6229 accuracy: 0.7034 val_loss: 0.5295 val_accuracy: 0.8017

Epoch 00062: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.
End of augmented training
Finish
Job ended!
