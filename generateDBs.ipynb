{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-23 00:22:04.501464: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "path:  /hpcstor6/scratch01/s/sanghyuk.kim001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Melanoma classification:Images available in ISIC2020 train dataset: 33126\n",
      "DEBUG:Melanoma classification:Images available in ISIC2020 test dataset: 10982\n",
      "DEBUG:Melanoma classification:Let's check ISIC2020 metadata briefly\n",
      "DEBUG:Melanoma classification:This is ISIC2020 training data samples\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>sex</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>anatom_site_general_challenge</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>benign_malignant</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>IP_7279968</td>\n",
       "      <td>male</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>IP_3075186</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>IP_2842074</td>\n",
       "      <td>female</td>\n",
       "      <td>50.0</td>\n",
       "      <td>lower extremity</td>\n",
       "      <td>nevus</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>IP_6890425</td>\n",
       "      <td>female</td>\n",
       "      <td>45.0</td>\n",
       "      <td>head/neck</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>IP_8723313</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>upper extremity</td>\n",
       "      <td>unknown</td>\n",
       "      <td>benign</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  patient_id     sex  age_approx anatom_site_general_challenge  \\\n",
       "0  ISIC_2637011  IP_7279968    male        45.0                     head/neck   \n",
       "1  ISIC_0015719  IP_3075186  female        45.0               upper extremity   \n",
       "2  ISIC_0052212  IP_2842074  female        50.0               lower extremity   \n",
       "3  ISIC_0068279  IP_6890425  female        45.0                     head/neck   \n",
       "4  ISIC_0074268  IP_8723313  female        55.0               upper extremity   \n",
       "\n",
       "  diagnosis benign_malignant  target  \n",
       "0   unknown           benign       0  \n",
       "1   unknown           benign       0  \n",
       "2     nevus           benign       0  \n",
       "3   unknown           benign       0  \n",
       "4   unknown           benign       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:Melanoma classification:Check null data in ISIC2020 training metadata\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "image_name                         0\n",
       "patient_id                         0\n",
       "sex                               65\n",
       "age_approx                        68\n",
       "anatom_site_general_challenge    527\n",
       "diagnosis                          0\n",
       "benign_malignant                   0\n",
       "target                             0\n",
       "path                               0\n",
       "cell_type_binary                   0\n",
       "cell_type_binary_idx               0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import melanoma as mel\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload -p 2\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.debug(\"test\")\n",
    "\n",
    "rootpath = '/hpcstor6/scratch01/s/sanghyuk.kim001'\n",
    "# img_size = (224, 224) # height, width\n",
    "img_size = (150, 150) # height, width\n",
    "utilInstance = mel.Util(rootpath, img_size)\n",
    "# dataType = mel.DatasetType.PAD_UFES_20\n",
    "\n",
    "\n",
    "\n",
    "CREATE_DB = 1\n",
    "# Save datasets as pickle files\n",
    "if (CREATE_DB == 1):\n",
    "    networkType = mel.NetworkType.ResNet50\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.HAM10000, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2016, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2017, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2018, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2019, networkType, 1.2)\n",
    "    utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2020, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PH2, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType._7_point_criteria, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PAD_UFES_20, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.MEDNODE, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.KaggleMB, networkType, 1.2)\n",
    "\n",
    "\n",
    "    # networkType = mel.NetworkType.Xception\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.HAM10000, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2016, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2017, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2018, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2019, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2020, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PH2, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType._7_point_criteria, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PAD_UFES_20, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.MEDNODE, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.KaggleMB, networkType, 1.2)\n",
    "\n",
    "    # networkType = mel.NetworkType.VGG16\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.HAM10000, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2016, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2017, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2018, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2019, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2020, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PH2, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType._7_point_criteria, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PAD_UFES_20, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.MEDNODE, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.KaggleMB, networkType, 1.2)\n",
    "\n",
    "    # networkType = mel.NetworkType.VGG19\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.HAM10000, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2016, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2017, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2018, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2019, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2020, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PH2, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType._7_point_criteria, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PAD_UFES_20, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.MEDNODE, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.KaggleMB, networkType, 1.2)\n",
    "\n",
    "    # networkType = mel.NetworkType.EfficientNetB0\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.HAM10000, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2016, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2017, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2018, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2019, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2020, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PH2, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType._7_point_criteria, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PAD_UFES_20, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.MEDNODE, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.KaggleMB, networkType, 1.2)\n",
    "\n",
    "    # networkType = mel.NetworkType.ResNet50V2\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.HAM10000, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2016, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2017, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2018, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2019, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2020, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PH2, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType._7_point_criteria, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PAD_UFES_20, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.MEDNODE, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.KaggleMB, networkType, 1.2)\n",
    "\n",
    "    # networkType = mel.NetworkType.MobileNet\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.HAM10000, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2016, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2017, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2018, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2019, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2020, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PH2, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType._7_point_criteria, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PAD_UFES_20, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.MEDNODE, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.KaggleMB, networkType, 1.2)\n",
    "\n",
    "    # networkType = mel.NetworkType.MobileNetV2\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.HAM10000, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2016, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2017, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2018, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2019, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2020, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PH2, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType._7_point_criteria, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PAD_UFES_20, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.MEDNODE, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.KaggleMB, networkType, 1.2)\n",
    "\n",
    "    # networkType = mel.NetworkType.DenseNet121\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.HAM10000, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2016, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2017, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2018, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2019, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2020, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PH2, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType._7_point_criteria, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PAD_UFES_20, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.MEDNODE, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.KaggleMB, networkType, 1.2)\n",
    "\n",
    "    # networkType = mel.NetworkType.NASNetMobile\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.HAM10000, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2016, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2017, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2018, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2019, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.ISIC2020, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PH2, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType._7_point_criteria, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.PAD_UFES_20, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.MEDNODE, networkType, 1.2)\n",
    "    # utilInstance.saveDatasetsToFile(mel.DatasetType.KaggleMB, networkType, 1.2)\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Combining...\n",
      "Combining 1 db out of 2 dbs\n",
      "Combining 2 db out of 2 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018_ISIC2016_150h_150w.pkl...\n",
      "ISIC2018_ISIC2016_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 3 dbs\n",
      "Combining 2 db out of 3 dbs\n",
      "Combining 3 db out of 3 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018_ISIC2016_ISIC2017_150h_150w.pkl...\n",
      "ISIC2018_ISIC2016_ISIC2017_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 4 dbs\n",
      "Combining 2 db out of 4 dbs\n",
      "Combining 3 db out of 4 dbs\n",
      "Combining 4 db out of 4 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018_ISIC2016_ISIC2017_ISIC2019_150h_150w.pkl...\n",
      "ISIC2018_ISIC2016_ISIC2017_ISIC2019_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 5 dbs\n",
      "Combining 2 db out of 5 dbs\n",
      "Combining 3 db out of 5 dbs\n",
      "Combining 4 db out of 5 dbs\n",
      "Combining 5 db out of 5 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_150h_150w.pkl...\n",
      "ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 6 dbs\n",
      "Combining 2 db out of 6 dbs\n",
      "Combining 3 db out of 6 dbs\n",
      "Combining 4 db out of 6 dbs\n",
      "Combining 5 db out of 6 dbs\n",
      "Combining 6 db out of 6 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_150h_150w.pkl...\n",
      "ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 7 dbs\n",
      "Combining 2 db out of 7 dbs\n",
      "Combining 3 db out of 7 dbs\n",
      "Combining 4 db out of 7 dbs\n",
      "Combining 5 db out of 7 dbs\n",
      "Combining 6 db out of 7 dbs\n",
      "Combining 7 db out of 7 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_150h_150w.pkl...\n",
      "ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 8 dbs\n",
      "Combining 2 db out of 8 dbs\n",
      "Combining 3 db out of 8 dbs\n",
      "Combining 4 db out of 8 dbs\n",
      "Combining 5 db out of 8 dbs\n",
      "Combining 6 db out of 8 dbs\n",
      "Combining 7 db out of 8 dbs\n",
      "Combining 8 db out of 8 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_PADUFES20_150h_150w.pkl...\n",
      "ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_PADUFES20_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 9 dbs\n",
      "Combining 2 db out of 9 dbs\n",
      "Combining 3 db out of 9 dbs\n",
      "Combining 4 db out of 9 dbs\n",
      "Combining 5 db out of 9 dbs\n",
      "Combining 6 db out of 9 dbs\n",
      "Combining 7 db out of 9 dbs\n",
      "Combining 8 db out of 9 dbs\n",
      "Combining 9 db out of 9 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_PADUFES20_PH2_150h_150w.pkl...\n",
      "ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_PADUFES20_PH2_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 10 dbs\n",
      "Combining 2 db out of 10 dbs\n",
      "Combining 3 db out of 10 dbs\n",
      "Combining 4 db out of 10 dbs\n",
      "Combining 5 db out of 10 dbs\n",
      "Combining 6 db out of 10 dbs\n",
      "Combining 7 db out of 10 dbs\n",
      "Combining 8 db out of 10 dbs\n",
      "Combining 9 db out of 10 dbs\n",
      "Combining 10 db out of 10 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_PADUFES20_PH2_7POINT_150h_150w.pkl...\n",
      "ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_PADUFES20_PH2_7POINT_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 2 dbs\n",
      "Combining 2 db out of 2 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018aug_ISIC2016aug_150h_150w.pkl...\n",
      "ISIC2018aug_ISIC2016aug_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 3 dbs\n",
      "Combining 2 db out of 3 dbs\n",
      "Combining 3 db out of 3 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018aug_ISIC2016aug_ISIC2017aug_150h_150w.pkl...\n",
      "ISIC2018aug_ISIC2016aug_ISIC2017aug_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 4 dbs\n",
      "Combining 2 db out of 4 dbs\n",
      "Combining 3 db out of 4 dbs\n",
      "Combining 4 db out of 4 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_150h_150w.pkl...\n",
      "ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 5 dbs\n",
      "Combining 2 db out of 5 dbs\n",
      "Combining 3 db out of 5 dbs\n",
      "Combining 4 db out of 5 dbs\n",
      "Combining 5 db out of 5 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_150h_150w.pkl...\n",
      "ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 6 dbs\n",
      "Combining 2 db out of 6 dbs\n",
      "Combining 3 db out of 6 dbs\n",
      "Combining 4 db out of 6 dbs\n",
      "Combining 5 db out of 6 dbs\n",
      "Combining 6 db out of 6 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_150h_150w.pkl...\n",
      "ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 7 dbs\n",
      "Combining 2 db out of 7 dbs\n",
      "Combining 3 db out of 7 dbs\n",
      "Combining 4 db out of 7 dbs\n",
      "Combining 5 db out of 7 dbs\n",
      "Combining 6 db out of 7 dbs\n",
      "Combining 7 db out of 7 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_150h_150w.pkl...\n",
      "ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 8 dbs\n",
      "Combining 2 db out of 8 dbs\n",
      "Combining 3 db out of 8 dbs\n",
      "Combining 4 db out of 8 dbs\n",
      "Combining 5 db out of 8 dbs\n",
      "Combining 6 db out of 8 dbs\n",
      "Combining 7 db out of 8 dbs\n",
      "Combining 8 db out of 8 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_PADUFES20aug_150h_150w.pkl...\n",
      "ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_PADUFES20aug_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 9 dbs\n",
      "Combining 2 db out of 9 dbs\n",
      "Combining 3 db out of 9 dbs\n",
      "Combining 4 db out of 9 dbs\n",
      "Combining 5 db out of 9 dbs\n",
      "Combining 6 db out of 9 dbs\n",
      "Combining 7 db out of 9 dbs\n",
      "Combining 8 db out of 9 dbs\n",
      "Combining 9 db out of 9 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_PADUFES20aug_PH2aug_150h_150w.pkl...\n",
      "ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_PADUFES20aug_PH2aug_150h_150w.pkl generated\n",
      "Combining...\n",
      "Combining 1 db out of 10 dbs\n",
      "Combining 2 db out of 10 dbs\n",
      "Combining 3 db out of 10 dbs\n",
      "Combining 4 db out of 10 dbs\n",
      "Combining 5 db out of 10 dbs\n",
      "Combining 6 db out of 10 dbs\n",
      "Combining 7 db out of 10 dbs\n",
      "Combining 8 db out of 10 dbs\n",
      "Combining 9 db out of 10 dbs\n",
      "Combining 10 db out of 10 dbs\n",
      "Stacking training images\n",
      "Stacking training labels\n",
      "Stacking validation images\n",
      "Stacking validation labels\n",
      "Pickling ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_PADUFES20aug_PH2aug_7POINTaug_150h_150w.pkl...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "[Errno 28] No space left on device",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb Cell 3\u001b[0m line \u001b[0;36m8\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=85'>86</a>\u001b[0m utilInstance\u001b[39m.\u001b[39mcombineSavedDatasets(combineddbpath, \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_PADUFES20aug_PH2aug_\u001b[39m\u001b[39m{\u001b[39;00mimg_size[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39mh_\u001b[39m\u001b[39m{\u001b[39;00mimg_size[\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39mw.pkl\u001b[39m\u001b[39m'\u001b[39m, ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug, KaggleDB_aug, MEDNODE_aug, PAD_UFES_20_aug, PH2_aug )\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=86'>87</a>\u001b[0m \u001b[39m# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020 + KaggleMB + MEDNODE + PAD_UFES_20 + PH2 + 7point\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=87'>88</a>\u001b[0m utilInstance\u001b[39m.\u001b[39;49mcombineSavedDatasets(combineddbpath, \u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_PADUFES20aug_PH2aug_7POINTaug_\u001b[39;49m\u001b[39m{\u001b[39;49;00mimg_size[\u001b[39m0\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39mh_\u001b[39;49m\u001b[39m{\u001b[39;49;00mimg_size[\u001b[39m1\u001b[39;49m]\u001b[39m}\u001b[39;49;00m\u001b[39mw.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m, ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug, KaggleDB_aug, MEDNODE_aug, PAD_UFES_20_aug, PH2_aug, _7pointdb_aug )\n",
      "File \u001b[0;32m~/MELANOMA/melanoma-detection-CNN/melanoma/util.py:2497\u001b[0m, in \u001b[0;36mUtil.combineSavedDatasets\u001b[0;34m(self, new_path, new_filename, *args)\u001b[0m\n\u001b[1;32m   2492\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mPickling \u001b[39m\u001b[39m{\u001b[39;00mnew_filename\u001b[39m}\u001b[39;00m\u001b[39m...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m   2493\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(totalpath, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m file:\n\u001b[1;32m   2494\u001b[0m \t\t\n\u001b[1;32m   2495\u001b[0m \t\t\u001b[39m# pickle.dump((trainimages_combined, None, validationimages_combined,\u001b[39;00m\n\u001b[1;32m   2496\u001b[0m \t\t\u001b[39m# trainlabels_combined, None, validationlabels_combined, 2), file)\u001b[39;00m\n\u001b[0;32m-> 2497\u001b[0m \t\tpickle\u001b[39m.\u001b[39;49mdump((trainimgs_list, \u001b[39mNone\u001b[39;49;00m, valimgs_list,\n\u001b[1;32m   2498\u001b[0m \t\ttrainlabels_list, \u001b[39mNone\u001b[39;49;00m, vallabels_list, \u001b[39m2\u001b[39;49m), file)\n\u001b[1;32m   2499\u001b[0m file\u001b[39m.\u001b[39mclose()\n\u001b[1;32m   2500\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mnew_filename\u001b[39m}\u001b[39;00m\u001b[39m generated\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device"
     ]
    }
   ],
   "source": [
    "import melanoma as mel\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload -p 2\n",
    "\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "logging.debug(\"test\")\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "networkType = mel.NetworkType.NASNetMobile\n",
    "rootpath = '/hpcstor6/scratch01/s/sanghyuk.kim001'\n",
    "dbpath = f'/hpcstor6/scratch01/s/sanghyuk.kim001/melanomaDB/customDB/{networkType.name}/'\n",
    "combineddbpath = f'/raid/mpsych/MELANOMA/combinedDBs/{networkType.name}/'\n",
    "\n",
    "if os.path.exists(combineddbpath) is False:\n",
    "    os.makedirs(combineddbpath)\n",
    "\n",
    "img_size = (150, 150)\n",
    "# img_size = (224, 224) # height, width\n",
    "utilInstance = mel.Util(rootpath, img_size)\n",
    "\n",
    "HAM10000 = dbpath + f'HAM10000_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "ISIC2016 = dbpath + f'ISIC2016_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "ISIC2017 = dbpath + f'ISIC2017_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "ISIC2018 = dbpath + f'ISIC2018_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "ISIC2019 = dbpath + f'ISIC2019_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "ISIC2020 = dbpath + f'ISIC2020_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "KaggleDB = dbpath + f'KaggleMB_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "MEDNODE = dbpath + f'MEDNODE_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "PAD_UFES_20 = dbpath + f'PAD_UFES_20_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "PH2 = dbpath + f'PH2_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "_7pointdb = dbpath + f'_7_point_criteria_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "\n",
    "HAM10000_aug = dbpath + f'HAM10000_augmentedWith_2434Melanoma_1399Non-Melanoma_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "ISIC2016_aug = dbpath + f'ISIC2016_augmentedWith_319Melanoma_146Non-Melanoma_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "ISIC2017_aug = dbpath + f'ISIC2017_augmentedWith_700Melanoma_326Non-Melanoma_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "ISIC2018_aug = dbpath + f'ISIC2018_augmentedWith_2894Melanoma_1781Non-Melanoma_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "ISIC2019_aug = dbpath + f'ISIC2019_augmentedWith_8684Melanoma_4162Non-Melanoma_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "ISIC2020_aug = dbpath + f'ISIC2020_augmentedWith_7093Melanoma_6509Non-Melanoma_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "KaggleDB_aug = dbpath + f'KaggleMB_augmentedWith_1197Melanoma_229Non-Melanoma_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "MEDNODE_aug = dbpath + f'MEDNODE_augmentedWith_72Melanoma_16Non-Melanoma_{img_size[0]}h_{img_size[1]}w_binary.pkl'\n",
    "PAD_UFES_20_aug = dbpath + f'PAD_UFES_20_augmentedWith_401Melanoma_358Non-Melanoma_150h_150w_binary.pkl'\n",
    "PH2_aug = dbpath + f'PH2_augmentedWith_72Melanoma_32Non-Melanoma_150h_150w_binary.pkl'\n",
    "_7pointdb_aug = dbpath + f'_7_point_criteria_augmentedWith_155Melanoma_65Non-Melanoma_150h_150w_binary.pkl'\n",
    "\n",
    "# Combine ISIC2018 + ISIC2016\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018_ISIC2016_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018, ISIC2016 )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018_ISIC2016_ISIC2017_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018, ISIC2016, ISIC2017 )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018_ISIC2016_ISIC2017_ISIC2019_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018, ISIC2016, ISIC2017, ISIC2019 )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018, ISIC2016, ISIC2017, ISIC2019, ISIC2020 )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020 + KaggleMB\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018, ISIC2016, ISIC2017, ISIC2019, ISIC2020, KaggleDB )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020 + KaggleMB + MEDNODE\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug, KaggleDB_aug, MEDNODE_aug )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020 + KaggleMB + MEDNODE + PAD_UFES_20\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_PADUFES20_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug, KaggleDB_aug, MEDNODE_aug, PAD_UFES_20_aug )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020 + KaggleMB + MEDNODE + PAD_UFES_20 + PH2\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_PADUFES20_PH2_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug, KaggleDB_aug, MEDNODE_aug, PAD_UFES_20_aug, PH2_aug )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020 + KaggleMB + MEDNODE + PAD_UFES_20 + PH2 + 7point\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018_ISIC2016_ISIC2017_ISIC2019_ISIC2020_KaggleMB_MEDNODE_PADUFES20_PH2_7POINT_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug, KaggleDB_aug, MEDNODE_aug, PAD_UFES_20_aug, PH2_aug, _7pointdb_aug )\n",
    "\n",
    "\n",
    "# Combine ISIC2018 + ISIC2016\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018aug_ISIC2016aug_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018aug_ISIC2016aug_ISIC2017aug_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020 + KaggleMB\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug, KaggleDB_aug )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020 + KaggleMB + MEDNODE\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug, KaggleDB_aug, MEDNODE_aug )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020 + KaggleMB + MEDNODE + PAD_UFES_20\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_PADUFES20aug_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug, KaggleDB_aug, MEDNODE_aug, PAD_UFES_20_aug )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020 + KaggleMB + MEDNODE + PAD_UFES_20 + PH2\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_PADUFES20aug_PH2aug_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug, KaggleDB_aug, MEDNODE_aug, PAD_UFES_20_aug, PH2_aug )\n",
    "# Combine ISIC2018 + ISIC2016 + ISIC2017 + ISIC2019 + ISIC2020 + KaggleMB + MEDNODE + PAD_UFES_20 + PH2 + 7point\n",
    "utilInstance.combineSavedDatasets(combineddbpath, f'ISIC2018aug_ISIC2016aug_ISIC2017aug_ISIC2019aug_ISIC2020aug_KaggleMBaug_MEDNODEaug_PADUFES20aug_PH2aug_7POINTaug_{img_size[0]}h_{img_size[1]}w.pkl', ISIC2018_aug, ISIC2016_aug, ISIC2017_aug, ISIC2019_aug, ISIC2020_aug, KaggleDB_aug, MEDNODE_aug, PAD_UFES_20_aug, PH2_aug, _7pointdb_aug )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 1440/1440 [00:03<00:00, 468.58it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████| 1197/1197 [00:02<00:00, 494.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 360/360 [00:00<00:00, 448.41it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 300/300 [00:00<00:00, 514.36it/s]\n"
     ]
    }
   ],
   "source": [
    "import melanoma as mel\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload -p 2\n",
    "\n",
    "networkType = mel.NetworkType.ResNet50\n",
    "rootpath = '/hpcstor6/scratch01/s/sanghyuk.kim001'\n",
    "dbpath = f'/hpcstor6/scratch01/s/sanghyuk.kim001/melanomaDB/customDB/{networkType.name}/'\n",
    "img_size = (224, 224) # height, width\n",
    "# img_size = (150, 150) # height, width\n",
    "utilInstance = mel.Util(rootpath, img_size)\n",
    "img_height, img_width = utilInstance.getImgSize()\n",
    "\n",
    "dbname = f'KaggleDB_{img_height}h_{img_width}w.pkl'\n",
    "\n",
    "directoryPath = rootpath + '/melanomaDB/Kaggle_malignant_benign_DB'\n",
    "\n",
    "benign_train_img = f'{directoryPath}/train/benign'\n",
    "malignant_train_img = f'{directoryPath}/train/malignant'\n",
    "benign_test_img = f'{directoryPath}/test/benign'\n",
    "malignant_test_img = f'{directoryPath}/test/malignant'\n",
    "\n",
    "# Generate Kaggle DB\n",
    "utilInstance.saveDatasetFromDirectory(dbpath, dbname, networkType, benign_train_img, malignant_train_img, benign_test_img, malignant_test_img )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m db\u001b[39m=\u001b[39mpickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/hpcstor6/scratch01/s/sanghyuk.kim001/melanomaDB/customDB/DenseNet121/ISIC2020_150h_150w_binary.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# mb=pickle.load(open('/hpcstor6/scratch01/s/sanghyuk.kim001/melanomaDB/customDB/ResNet50/KaggleMB_224h_224w.pkl', 'rb'))\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m a \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;32m/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb Cell 4\u001b[0m line \u001b[0;36m7\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m db\u001b[39m=\u001b[39mpickle\u001b[39m.\u001b[39mload(\u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39m/hpcstor6/scratch01/s/sanghyuk.kim001/melanomaDB/customDB/DenseNet121/ISIC2020_150h_150w_binary.pkl\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mrb\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# mb=pickle.load(open('/hpcstor6/scratch01/s/sanghyuk.kim001/melanomaDB/customDB/ResNet50/KaggleMB_224h_224w.pkl', 'rb'))\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bchimera.umb.edu/home/sanghyuk.kim001/MELANOMA/melanoma-detection-CNN/generateDBs.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=6'>7</a>\u001b[0m a \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[1;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[1;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[0;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[1;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[1;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/clean_chimera_env/lib/python3.9/site-packages/debugpy/_vendored/pydevd/pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[0;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[1;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[1;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[0;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[1;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "db=pickle.load(open('/hpcstor6/scratch01/s/sanghyuk.kim001/melanomaDB/customDB/DenseNet121/ISIC2020_150h_150w_binary.pkl', 'rb'))\n",
    "\n",
    "# mb=pickle.load(open('/hpcstor6/scratch01/s/sanghyuk.kim001/melanomaDB/customDB/ResNet50/KaggleMB_224h_224w.pkl', 'rb'))\n",
    "\n",
    "\n",
    "a = 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
