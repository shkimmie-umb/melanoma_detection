Sat 04 May 2024 05:43:47 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'ISIC2020', 'PH2']
IMG_SIZE: [384, 384]
CLASSIFIER: DenseNet201
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 5 dbs
Combining 2th db out of 5 dbs
Combining 3th db out of 5 dbs
Combining 4th db out of 5 dbs
Combining 5th db out of 5 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
densenet201 (Functional)     (None, 1920)              18321984  
_________________________________________________________________
dense (Dense)                (None, 512)               983552    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 19,440,450
Trainable params: 1,116,930
Non-trainable params: 18,323,520
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+ISIC2020+PH2_aug_DenseNet201_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+ISIC2020+PH2_aug_DenseNet201_384h_384w_None
Epoch: 1 loss: 0.7689 accuracy: 0.8389 val_loss: 0.4962 val_accuracy: 0.9429
Epoch: 2 loss: 0.5461 accuracy: 0.9058 val_loss: 0.4279 val_accuracy: 0.9582
Epoch: 3 loss: 0.4827 accuracy: 0.9211 val_loss: 0.3962 val_accuracy: 0.9606
Epoch: 4 loss: 0.4419 accuracy: 0.9299 val_loss: 0.3847 val_accuracy: 0.9545
Epoch: 5 loss: 0.4078 accuracy: 0.9351 val_loss: 0.3688 val_accuracy: 0.9527
Epoch: 6 loss: 0.3808 accuracy: 0.9395 val_loss: 0.3690 val_accuracy: 0.9467
Epoch: 7 loss: 0.3551 accuracy: 0.9431 val_loss: 0.3293 val_accuracy: 0.9558
Epoch: 8 loss: 0.3363 accuracy: 0.9452 val_loss: 0.2975 val_accuracy: 0.9639
Epoch: 9 loss: 0.3171 accuracy: 0.9481 val_loss: 0.3077 val_accuracy: 0.9543
Epoch: 10 loss: 0.2940 accuracy: 0.9532 val_loss: 0.3040 val_accuracy: 0.9522
Epoch: 11 loss: 0.2815 accuracy: 0.9542 val_loss: 0.2785 val_accuracy: 0.9587
Epoch: 12 loss: 0.2691 accuracy: 0.9548 val_loss: 0.2600 val_accuracy: 0.9625
Epoch: 13 loss: 0.2537 accuracy: 0.9575 val_loss: 0.2461 val_accuracy: 0.9698
Epoch: 14 loss: 0.2399 accuracy: 0.9603 val_loss: 0.2427 val_accuracy: 0.9635
Epoch: 15 loss: 0.2251 accuracy: 0.9625 val_loss: 0.2403 val_accuracy: 0.9661
Epoch: 16 loss: 0.2189 accuracy: 0.9634 val_loss: 0.2392 val_accuracy: 0.9599
Epoch: 17 loss: 0.2126 accuracy: 0.9629 val_loss: 0.2481 val_accuracy: 0.9587
Epoch: 18 loss: 0.2056 accuracy: 0.9634 val_loss: 0.2363 val_accuracy: 0.9575
Epoch: 19 loss: 0.1962 accuracy: 0.9653 val_loss: 0.2244 val_accuracy: 0.9621
Epoch: 20 loss: 0.1907 accuracy: 0.9659 val_loss: 0.2338 val_accuracy: 0.9578
Epoch: 21 loss: 0.1822 accuracy: 0.9681 val_loss: 0.2322 val_accuracy: 0.9590
Epoch: 22 loss: 0.1801 accuracy: 0.9672 val_loss: 0.2325 val_accuracy: 0.9599
Epoch: 23 loss: 0.1726 accuracy: 0.9684 val_loss: 0.2175 val_accuracy: 0.9617
Epoch: 24 loss: 0.1684 accuracy: 0.9699 val_loss: 0.2176 val_accuracy: 0.9615
Epoch: 25 loss: 0.1664 accuracy: 0.9697 val_loss: 0.2180 val_accuracy: 0.9639
Epoch: 26 loss: 0.1606 accuracy: 0.9704 val_loss: 0.2411 val_accuracy: 0.9478
Epoch: 27 loss: 0.1539 accuracy: 0.9713 val_loss: 0.2098 val_accuracy: 0.9613
Epoch: 28 loss: 0.1492 accuracy: 0.9729 val_loss: 0.2177 val_accuracy: 0.9564
Epoch: 29 loss: 0.1471 accuracy: 0.9726 val_loss: 0.2050 val_accuracy: 0.9597
Epoch: 30 loss: 0.1473 accuracy: 0.9717 val_loss: 0.1945 val_accuracy: 0.9621
Epoch: 31 loss: 0.1431 accuracy: 0.9730 val_loss: 0.2528 val_accuracy: 0.9403
Epoch: 32 loss: 0.1394 accuracy: 0.9745 val_loss: 0.2135 val_accuracy: 0.9540
Epoch: 33 loss: 0.1366 accuracy: 0.9748 val_loss: 0.1864 val_accuracy: 0.9689
Epoch: 34 loss: 0.1356 accuracy: 0.9736 val_loss: 0.1947 val_accuracy: 0.9698
Epoch: 35 loss: 0.1335 accuracy: 0.9744 val_loss: 0.1881 val_accuracy: 0.9636
Epoch: 36 loss: 0.1297 accuracy: 0.9749 val_loss: 0.2121 val_accuracy: 0.9571
Epoch: 37 loss: 0.1224 accuracy: 0.9773 val_loss: 0.2028 val_accuracy: 0.9607
Epoch: 38 loss: 0.1260 accuracy: 0.9757 val_loss: 0.1953 val_accuracy: 0.9608

Epoch 00038: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 39 loss: 0.1160 accuracy: 0.9794 val_loss: 0.1833 val_accuracy: 0.9680
Epoch: 40 loss: 0.1117 accuracy: 0.9802 val_loss: 0.1998 val_accuracy: 0.9600
Epoch: 41 loss: 0.1071 accuracy: 0.9818 val_loss: 0.1812 val_accuracy: 0.9661
Epoch: 42 loss: 0.1070 accuracy: 0.9816 val_loss: 0.1874 val_accuracy: 0.9650
Epoch: 43 loss: 0.1046 accuracy: 0.9814 val_loss: 0.1926 val_accuracy: 0.9648
Epoch: 44 loss: 0.1050 accuracy: 0.9818 val_loss: 0.1893 val_accuracy: 0.9632
Epoch: 45 loss: 0.1013 accuracy: 0.9823 val_loss: 0.1930 val_accuracy: 0.9675
Epoch: 46 loss: 0.0998 accuracy: 0.9830 val_loss: 0.1868 val_accuracy: 0.9666

Epoch 00046: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 47 loss: 0.0970 accuracy: 0.9836 val_loss: 0.1942 val_accuracy: 0.9646
Epoch: 48 loss: 0.0885 accuracy: 0.9873 val_loss: 0.1996 val_accuracy: 0.9620
Epoch: 49 loss: 0.0888 accuracy: 0.9858 val_loss: 0.1859 val_accuracy: 0.9678
Epoch: 50 loss: 0.0891 accuracy: 0.9859 val_loss: 0.1937 val_accuracy: 0.9593
Epoch: 51 loss: 0.0875 accuracy: 0.9862 val_loss: 0.1858 val_accuracy: 0.9678

Epoch 00051: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
End of augmented training
Finish
Job ended!
