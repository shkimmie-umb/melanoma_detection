Tue 07 May 2024 04:56:20 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018']
IMG_SIZE: [384, 384]
CLASSIFIER: EfficientNetB5
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 3 dbs
Combining 2th db out of 3 dbs
Combining 3th db out of 3 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb5 (Functional)  (None, 2048)              28513527  
_________________________________________________________________
dense (Dense)                (None, 512)               1049088   
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 29,697,529
Trainable params: 1,182,466
Non-trainable params: 28,515,063
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018_aug_EfficientNetB5_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018_aug_EfficientNetB5_384h_384w_None
Epoch: 1 loss: 1.2921 accuracy: 0.5595 val_loss: 1.0306 val_accuracy: 0.8413
Epoch: 2 loss: 1.1249 accuracy: 0.6447 val_loss: 0.9842 val_accuracy: 0.8413
Epoch: 3 loss: 1.0751 accuracy: 0.6797 val_loss: 0.9300 val_accuracy: 0.8413
Epoch: 4 loss: 1.0400 accuracy: 0.6911 val_loss: 0.9222 val_accuracy: 0.8413
Epoch: 5 loss: 1.0168 accuracy: 0.6941 val_loss: 0.8767 val_accuracy: 0.8413
Epoch: 6 loss: 0.9935 accuracy: 0.6980 val_loss: 0.8542 val_accuracy: 0.8413
Epoch: 7 loss: 0.9738 accuracy: 0.6959 val_loss: 0.8138 val_accuracy: 0.8413
Epoch: 8 loss: 0.9527 accuracy: 0.6972 val_loss: 0.7982 val_accuracy: 0.8413
Epoch: 9 loss: 0.9292 accuracy: 0.6995 val_loss: 0.7974 val_accuracy: 0.8413
Epoch: 10 loss: 0.9076 accuracy: 0.7034 val_loss: 0.7622 val_accuracy: 0.8413
Epoch: 11 loss: 0.8870 accuracy: 0.7052 val_loss: 0.7699 val_accuracy: 0.8413
Epoch: 12 loss: 0.8691 accuracy: 0.7025 val_loss: 0.7309 val_accuracy: 0.8413
Epoch: 13 loss: 0.8478 accuracy: 0.7039 val_loss: 0.7616 val_accuracy: 0.8413
Epoch: 14 loss: 0.8403 accuracy: 0.6941 val_loss: 0.7008 val_accuracy: 0.8413
Epoch: 15 loss: 0.8138 accuracy: 0.7053 val_loss: 0.6678 val_accuracy: 0.8413
Epoch: 16 loss: 0.8024 accuracy: 0.6985 val_loss: 0.6653 val_accuracy: 0.8413
Epoch: 17 loss: 0.7799 accuracy: 0.7069 val_loss: 0.6374 val_accuracy: 0.8413
Epoch: 18 loss: 0.7617 accuracy: 0.7100 val_loss: 0.6076 val_accuracy: 0.8413
Epoch: 19 loss: 0.7517 accuracy: 0.7061 val_loss: 0.6186 val_accuracy: 0.8413
Epoch: 20 loss: 0.7415 accuracy: 0.7059 val_loss: 0.5860 val_accuracy: 0.8413
Epoch: 21 loss: 0.7278 accuracy: 0.7055 val_loss: 0.5850 val_accuracy: 0.8413
Epoch: 22 loss: 0.7227 accuracy: 0.7015 val_loss: 0.6254 val_accuracy: 0.8413
Epoch: 23 loss: 0.7066 accuracy: 0.7070 val_loss: 0.6032 val_accuracy: 0.8413
Epoch: 24 loss: 0.6993 accuracy: 0.7069 val_loss: 0.5500 val_accuracy: 0.8413
Epoch: 25 loss: 0.6922 accuracy: 0.7040 val_loss: 0.5649 val_accuracy: 0.8413
Epoch: 26 loss: 0.6835 accuracy: 0.7082 val_loss: 0.5393 val_accuracy: 0.8413
Epoch: 27 loss: 0.6818 accuracy: 0.7025 val_loss: 0.5623 val_accuracy: 0.8413
Epoch: 28 loss: 0.6766 accuracy: 0.7019 val_loss: 0.5876 val_accuracy: 0.8413
Epoch: 29 loss: 0.6680 accuracy: 0.7075 val_loss: 0.5400 val_accuracy: 0.8413
Epoch: 30 loss: 0.6680 accuracy: 0.7031 val_loss: 0.5430 val_accuracy: 0.8413
Epoch: 31 loss: 0.6573 accuracy: 0.7090 val_loss: 0.5732 val_accuracy: 0.8413

Epoch 00031: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 32 loss: 0.6521 accuracy: 0.7121 val_loss: 0.5464 val_accuracy: 0.8413
Epoch: 33 loss: 0.6506 accuracy: 0.7096 val_loss: 0.5209 val_accuracy: 0.8413
Epoch: 34 loss: 0.6495 accuracy: 0.7092 val_loss: 0.5265 val_accuracy: 0.8413
Epoch: 35 loss: 0.6517 accuracy: 0.7035 val_loss: 0.5193 val_accuracy: 0.8413
Epoch: 36 loss: 0.6471 accuracy: 0.7057 val_loss: 0.5068 val_accuracy: 0.8413
Epoch: 37 loss: 0.6440 accuracy: 0.7072 val_loss: 0.5305 val_accuracy: 0.8413
Epoch: 38 loss: 0.6438 accuracy: 0.7051 val_loss: 0.5182 val_accuracy: 0.8413
Epoch: 39 loss: 0.6436 accuracy: 0.7023 val_loss: 0.5082 val_accuracy: 0.8413
Epoch: 40 loss: 0.6359 accuracy: 0.7092 val_loss: 0.5190 val_accuracy: 0.8413
Epoch: 41 loss: 0.6410 accuracy: 0.7025 val_loss: 0.5247 val_accuracy: 0.8413

Epoch 00041: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 42 loss: 0.6353 accuracy: 0.7061 val_loss: 0.5121 val_accuracy: 0.8413
Epoch: 43 loss: 0.6332 accuracy: 0.7082 val_loss: 0.5357 val_accuracy: 0.8413
Epoch: 44 loss: 0.6355 accuracy: 0.7048 val_loss: 0.5258 val_accuracy: 0.8413
Epoch: 45 loss: 0.6359 accuracy: 0.7031 val_loss: 0.5211 val_accuracy: 0.8413
Epoch: 46 loss: 0.6297 accuracy: 0.7086 val_loss: 0.4898 val_accuracy: 0.8413
Epoch: 47 loss: 0.6257 accuracy: 0.7110 val_loss: 0.5048 val_accuracy: 0.8413
Epoch: 48 loss: 0.6295 accuracy: 0.7070 val_loss: 0.5016 val_accuracy: 0.8413
Epoch: 49 loss: 0.6252 accuracy: 0.7107 val_loss: 0.5113 val_accuracy: 0.8413
Epoch: 50 loss: 0.6265 accuracy: 0.7084 val_loss: 0.4964 val_accuracy: 0.8413
Epoch: 51 loss: 0.6253 accuracy: 0.7097 val_loss: 0.5311 val_accuracy: 0.8413

Epoch 00051: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 52 loss: 0.6281 accuracy: 0.7047 val_loss: 0.4972 val_accuracy: 0.8413
Epoch: 53 loss: 0.6254 accuracy: 0.7074 val_loss: 0.5274 val_accuracy: 0.8413
Epoch: 54 loss: 0.6240 accuracy: 0.7074 val_loss: 0.4944 val_accuracy: 0.8413
Epoch: 55 loss: 0.6262 accuracy: 0.7039 val_loss: 0.4989 val_accuracy: 0.8413
Epoch: 56 loss: 0.6162 accuracy: 0.7149 val_loss: 0.5176 val_accuracy: 0.8413

Epoch 00056: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
End of augmented training
Finish
Job ended!
