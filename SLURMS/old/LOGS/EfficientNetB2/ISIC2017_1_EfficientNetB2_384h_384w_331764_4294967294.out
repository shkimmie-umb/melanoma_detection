Fri 03 May 2024 11:21:07 AM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2017']
IMG_SIZE: [384, 384]
CLASSIFIER: EfficientNetB2
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 1 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
efficientnetb2 (Functional)  (None, 1408)              7768569   
_________________________________________________________________
dense (Dense)                (None, 512)               721408    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 8,624,891
Trainable params: 854,786
Non-trainable params: 7,770,105
_________________________________________________________________
Fitting ISIC2017_aug_EfficientNetB2_384h_384w_None model...
model_name: ISIC2017_aug_EfficientNetB2_384h_384w_None
Epoch: 1 loss: 1.4946 accuracy: 0.5033 val_loss: 1.1601 val_accuracy: 0.8000
Epoch: 2 loss: 1.3735 accuracy: 0.5000 val_loss: 1.0902 val_accuracy: 0.8000
Epoch: 3 loss: 1.2963 accuracy: 0.5136 val_loss: 1.0473 val_accuracy: 0.8000
Epoch: 4 loss: 1.2399 accuracy: 0.5472 val_loss: 1.0711 val_accuracy: 0.8000
Epoch: 5 loss: 1.2240 accuracy: 0.5339 val_loss: 1.0839 val_accuracy: 0.8000
Epoch: 6 loss: 1.1797 accuracy: 0.5495 val_loss: 1.1188 val_accuracy: 0.8000
Epoch: 7 loss: 1.1548 accuracy: 0.5711 val_loss: 1.0069 val_accuracy: 0.8000
Epoch: 8 loss: 1.1446 accuracy: 0.5771 val_loss: 0.9185 val_accuracy: 0.8000
Epoch: 9 loss: 1.1499 accuracy: 0.5662 val_loss: 0.9224 val_accuracy: 0.8000
Epoch: 10 loss: 1.1294 accuracy: 0.5791 val_loss: 0.9168 val_accuracy: 0.8000
Epoch: 11 loss: 1.1153 accuracy: 0.5898 val_loss: 0.9064 val_accuracy: 0.8000
Epoch: 12 loss: 1.1375 accuracy: 0.5632 val_loss: 0.9548 val_accuracy: 0.8000
Epoch: 13 loss: 1.1115 accuracy: 0.5861 val_loss: 1.2326 val_accuracy: 0.2000
Epoch: 14 loss: 1.1009 accuracy: 0.5881 val_loss: 1.0834 val_accuracy: 0.2000
Epoch: 15 loss: 1.0826 accuracy: 0.6017 val_loss: 0.8869 val_accuracy: 0.8000
Epoch: 16 loss: 1.0806 accuracy: 0.5997 val_loss: 0.8962 val_accuracy: 0.8000
Epoch: 17 loss: 1.0836 accuracy: 0.5957 val_loss: 0.8796 val_accuracy: 0.8000
Epoch: 18 loss: 1.0732 accuracy: 0.6057 val_loss: 0.9322 val_accuracy: 0.8000
Epoch: 19 loss: 1.0829 accuracy: 0.5828 val_loss: 0.9919 val_accuracy: 0.8000
Epoch: 20 loss: 1.0724 accuracy: 0.5901 val_loss: 0.9021 val_accuracy: 0.8000
Epoch: 21 loss: 1.0691 accuracy: 0.5938 val_loss: 1.0968 val_accuracy: 0.2000
Epoch: 22 loss: 1.0605 accuracy: 0.5974 val_loss: 0.9451 val_accuracy: 0.8000

Epoch 00022: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 23 loss: 1.0502 accuracy: 0.6047 val_loss: 1.0648 val_accuracy: 0.2000
Epoch: 24 loss: 1.0759 accuracy: 0.5771 val_loss: 0.8938 val_accuracy: 0.8000
Epoch: 25 loss: 1.0535 accuracy: 0.5854 val_loss: 0.8544 val_accuracy: 0.8000
Epoch: 26 loss: 1.0415 accuracy: 0.5984 val_loss: 0.8849 val_accuracy: 0.8000
Epoch: 27 loss: 1.0456 accuracy: 0.5884 val_loss: 0.9980 val_accuracy: 0.8000
Epoch: 28 loss: 1.0275 accuracy: 0.6210 val_loss: 0.8832 val_accuracy: 0.8000
Epoch: 29 loss: 1.0625 accuracy: 0.5851 val_loss: 0.8512 val_accuracy: 0.8000
Epoch: 30 loss: 1.0238 accuracy: 0.6203 val_loss: 0.8839 val_accuracy: 0.8000
Epoch: 31 loss: 1.0308 accuracy: 0.6067 val_loss: 0.8905 val_accuracy: 0.8000
Epoch: 32 loss: 1.0315 accuracy: 0.5994 val_loss: 0.8624 val_accuracy: 0.8000
Epoch: 33 loss: 1.0370 accuracy: 0.5941 val_loss: 0.8490 val_accuracy: 0.8000
Epoch: 34 loss: 1.0302 accuracy: 0.5984 val_loss: 0.8686 val_accuracy: 0.8000
Epoch: 35 loss: 1.0204 accuracy: 0.6037 val_loss: 0.8823 val_accuracy: 0.8000
Epoch: 36 loss: 1.0303 accuracy: 0.5914 val_loss: 0.8602 val_accuracy: 0.8000
Epoch: 37 loss: 1.0052 accuracy: 0.6213 val_loss: 0.8881 val_accuracy: 0.8000
Epoch: 38 loss: 1.0239 accuracy: 0.5914 val_loss: 0.9675 val_accuracy: 0.8000

Epoch 00038: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 39 loss: 1.0054 accuracy: 0.6087 val_loss: 0.8974 val_accuracy: 0.8000
Epoch: 40 loss: 1.0113 accuracy: 0.6061 val_loss: 0.8736 val_accuracy: 0.8000
Epoch: 41 loss: 1.0052 accuracy: 0.6087 val_loss: 0.8738 val_accuracy: 0.8000
Epoch: 42 loss: 1.0032 accuracy: 0.6117 val_loss: 0.8455 val_accuracy: 0.8000
Epoch: 43 loss: 1.0109 accuracy: 0.6014 val_loss: 0.8638 val_accuracy: 0.8000
Epoch: 44 loss: 1.0153 accuracy: 0.6084 val_loss: 0.9037 val_accuracy: 0.8000
Epoch: 45 loss: 0.9865 accuracy: 0.6217 val_loss: 0.9282 val_accuracy: 0.8000
Epoch: 46 loss: 0.9855 accuracy: 0.6300 val_loss: 0.8959 val_accuracy: 0.8000
Epoch: 47 loss: 1.0099 accuracy: 0.5878 val_loss: 0.8358 val_accuracy: 0.8000
Epoch: 48 loss: 0.9854 accuracy: 0.6213 val_loss: 0.8586 val_accuracy: 0.8000
Epoch: 49 loss: 0.9907 accuracy: 0.6157 val_loss: 0.9277 val_accuracy: 0.8000
Epoch: 50 loss: 0.9909 accuracy: 0.6120 val_loss: 0.9668 val_accuracy: 0.8000
Epoch: 51 loss: 0.9788 accuracy: 0.6213 val_loss: 0.8570 val_accuracy: 0.8000
Epoch: 52 loss: 0.9708 accuracy: 0.6260 val_loss: 0.8620 val_accuracy: 0.8000

Epoch 00052: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 53 loss: 0.9749 accuracy: 0.6210 val_loss: 0.8326 val_accuracy: 0.8000
Epoch: 54 loss: 0.9701 accuracy: 0.6240 val_loss: 0.8373 val_accuracy: 0.8000
Epoch: 55 loss: 0.9876 accuracy: 0.6077 val_loss: 0.8862 val_accuracy: 0.8000
Epoch: 56 loss: 0.9818 accuracy: 0.6167 val_loss: 0.8562 val_accuracy: 0.8000
Epoch: 57 loss: 0.9684 accuracy: 0.6260 val_loss: 0.8683 val_accuracy: 0.8000
Epoch: 58 loss: 0.9675 accuracy: 0.6213 val_loss: 0.8644 val_accuracy: 0.8000

Epoch 00058: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
Epoch: 59 loss: 0.9621 accuracy: 0.6273 val_loss: 0.8499 val_accuracy: 0.8000
Epoch: 60 loss: 0.9600 accuracy: 0.6320 val_loss: 0.8328 val_accuracy: 0.8000
Epoch: 61 loss: 0.9610 accuracy: 0.6300 val_loss: 0.9095 val_accuracy: 0.8000
Epoch: 62 loss: 0.9630 accuracy: 0.6253 val_loss: 0.9407 val_accuracy: 0.8000
Epoch: 63 loss: 0.9595 accuracy: 0.6247 val_loss: 0.9681 val_accuracy: 0.8000

Epoch 00063: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.
End of augmented training
Finish
Job ended!
