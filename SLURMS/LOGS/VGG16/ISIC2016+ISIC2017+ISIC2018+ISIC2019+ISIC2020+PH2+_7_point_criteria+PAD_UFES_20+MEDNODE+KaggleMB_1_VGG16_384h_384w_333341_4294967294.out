Wed 08 May 2024 09:45:12 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'ISIC2019', 'ISIC2020', 'PH2', '_7_point_criteria', 'PAD_UFES_20', 'MEDNODE', 'KaggleMB']
IMG_SIZE: [384, 384]
CLASSIFIER: VGG16
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 10 dbs
Combining 2th db out of 10 dbs
Combining 3th db out of 10 dbs
Combining 4th db out of 10 dbs
Combining 5th db out of 10 dbs
Combining 6th db out of 10 dbs
Combining 7th db out of 10 dbs
Combining 8th db out of 10 dbs
Combining 9th db out of 10 dbs
Combining 10th db out of 10 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
vgg16 (Functional)           (None, 512)               14714688  
_________________________________________________________________
dense (Dense)                (None, 512)               262656    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 15,112,258
Trainable params: 396,034
Non-trainable params: 14,716,224
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020+PH2+_7_point_criteria+PAD_UFES_20+MEDNODE+KaggleMB_aug_VGG16_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020+PH2+_7_point_criteria+PAD_UFES_20+MEDNODE+KaggleMB_aug_VGG16_384h_384w_None
Epoch: 1 loss: 0.7360 accuracy: 0.7689 val_loss: 0.5053 val_accuracy: 0.8637
Epoch: 2 loss: 0.5565 accuracy: 0.8229 val_loss: 0.4572 val_accuracy: 0.8705
Epoch: 3 loss: 0.5094 accuracy: 0.8336 val_loss: 0.5849 val_accuracy: 0.7799
Epoch: 4 loss: 0.4758 accuracy: 0.8411 val_loss: 0.4485 val_accuracy: 0.8551
Epoch: 5 loss: 0.4561 accuracy: 0.8438 val_loss: 0.4295 val_accuracy: 0.8572
Epoch: 6 loss: 0.4305 accuracy: 0.8482 val_loss: 0.4028 val_accuracy: 0.8609
Epoch: 7 loss: 0.4135 accuracy: 0.8527 val_loss: 0.3575 val_accuracy: 0.8876
Epoch: 8 loss: 0.4000 accuracy: 0.8550 val_loss: 0.3572 val_accuracy: 0.8792
Epoch: 9 loss: 0.3885 accuracy: 0.8575 val_loss: 0.3779 val_accuracy: 0.8628
Epoch: 10 loss: 0.3796 accuracy: 0.8582 val_loss: 0.4059 val_accuracy: 0.8406
Epoch: 11 loss: 0.3707 accuracy: 0.8598 val_loss: 0.3447 val_accuracy: 0.8781
Epoch: 12 loss: 0.3648 accuracy: 0.8608 val_loss: 0.3974 val_accuracy: 0.8418
Epoch: 13 loss: 0.3572 accuracy: 0.8621 val_loss: 0.3192 val_accuracy: 0.8858
Epoch: 14 loss: 0.3489 accuracy: 0.8642 val_loss: 0.4056 val_accuracy: 0.8312
Epoch: 15 loss: 0.3430 accuracy: 0.8682 val_loss: 0.3079 val_accuracy: 0.8927
Epoch: 16 loss: 0.3428 accuracy: 0.8670 val_loss: 0.3471 val_accuracy: 0.8665
Epoch: 17 loss: 0.3374 accuracy: 0.8685 val_loss: 0.3826 val_accuracy: 0.8470
Epoch: 18 loss: 0.3340 accuracy: 0.8695 val_loss: 0.3021 val_accuracy: 0.8940
Epoch: 19 loss: 0.3285 accuracy: 0.8718 val_loss: 0.3867 val_accuracy: 0.8384
Epoch: 20 loss: 0.3282 accuracy: 0.8705 val_loss: 0.3247 val_accuracy: 0.8763
Epoch: 21 loss: 0.3213 accuracy: 0.8744 val_loss: 0.3167 val_accuracy: 0.8838
Epoch: 22 loss: 0.3222 accuracy: 0.8724 val_loss: 0.3189 val_accuracy: 0.8786
Epoch: 23 loss: 0.3186 accuracy: 0.8756 val_loss: 0.3305 val_accuracy: 0.8685

Epoch 00023: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 24 loss: 0.3105 accuracy: 0.8776 val_loss: 0.3954 val_accuracy: 0.8376
Epoch: 25 loss: 0.3086 accuracy: 0.8788 val_loss: 0.2975 val_accuracy: 0.8919
Epoch: 26 loss: 0.3044 accuracy: 0.8808 val_loss: 0.2917 val_accuracy: 0.8956
Epoch: 27 loss: 0.3016 accuracy: 0.8818 val_loss: 0.3127 val_accuracy: 0.8806
Epoch: 28 loss: 0.3023 accuracy: 0.8825 val_loss: 0.3742 val_accuracy: 0.8468
Epoch: 29 loss: 0.2972 accuracy: 0.8857 val_loss: 0.3079 val_accuracy: 0.8847
Epoch: 30 loss: 0.2972 accuracy: 0.8838 val_loss: 0.3242 val_accuracy: 0.8696
Epoch: 31 loss: 0.2939 accuracy: 0.8845 val_loss: 0.3505 val_accuracy: 0.8587

Epoch 00031: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 32 loss: 0.2882 accuracy: 0.8875 val_loss: 0.2921 val_accuracy: 0.8945
Epoch: 33 loss: 0.2863 accuracy: 0.8897 val_loss: 0.3001 val_accuracy: 0.8900
Epoch: 34 loss: 0.2814 accuracy: 0.8904 val_loss: 0.2842 val_accuracy: 0.9004
Epoch: 35 loss: 0.2818 accuracy: 0.8917 val_loss: 0.3159 val_accuracy: 0.8758
Epoch: 36 loss: 0.2789 accuracy: 0.8929 val_loss: 0.2975 val_accuracy: 0.8877
Epoch: 37 loss: 0.2783 accuracy: 0.8921 val_loss: 0.3040 val_accuracy: 0.8889
Epoch: 38 loss: 0.2773 accuracy: 0.8934 val_loss: 0.3008 val_accuracy: 0.8837
Epoch: 39 loss: 0.2766 accuracy: 0.8926 val_loss: 0.3678 val_accuracy: 0.8511

Epoch 00039: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 40 loss: 0.2706 accuracy: 0.8968 val_loss: 0.2972 val_accuracy: 0.8895
Epoch: 41 loss: 0.2710 accuracy: 0.8963 val_loss: 0.3205 val_accuracy: 0.8755
Epoch: 42 loss: 0.2682 accuracy: 0.8980 val_loss: 0.3184 val_accuracy: 0.8814
Epoch: 43 loss: 0.2679 accuracy: 0.8981 val_loss: 0.3421 val_accuracy: 0.8658
Epoch: 44 loss: 0.2681 accuracy: 0.8972 val_loss: 0.3141 val_accuracy: 0.8816

Epoch 00044: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
End of augmented training
Finish
Job ended!
