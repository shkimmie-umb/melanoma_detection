Sat 04 May 2024 04:02:37 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'ISIC2017', 'ISIC2018', 'ISIC2019', 'ISIC2020', 'PH2', 'MEDNODE', 'KaggleMB']
IMG_SIZE: [384, 384]
CLASSIFIER: DenseNet169
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 8 dbs
Combining 2th db out of 8 dbs
Combining 3th db out of 8 dbs
Combining 4th db out of 8 dbs
Combining 5th db out of 8 dbs
Combining 6th db out of 8 dbs
Combining 7th db out of 8 dbs
Combining 8th db out of 8 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
densenet169 (Functional)     (None, 1664)              12642880  
_________________________________________________________________
dense (Dense)                (None, 512)               852480    
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization (BatchNo (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_1 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 13,630,274
Trainable params: 985,858
Non-trainable params: 12,644,416
_________________________________________________________________
Fitting ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020+PH2+MEDNODE+KaggleMB_aug_DenseNet169_384h_384w_None model...
model_name: ISIC2016+ISIC2017+ISIC2018+ISIC2019+ISIC2020+PH2+MEDNODE+KaggleMB_aug_DenseNet169_384h_384w_None
Epoch: 1 loss: 0.7295 accuracy: 0.8434 val_loss: 0.5882 val_accuracy: 0.8902
Epoch: 2 loss: 0.5616 accuracy: 0.8858 val_loss: 0.5172 val_accuracy: 0.9015
Epoch: 3 loss: 0.4943 accuracy: 0.8995 val_loss: 0.4839 val_accuracy: 0.8990
Epoch: 4 loss: 0.4479 accuracy: 0.9081 val_loss: 0.4667 val_accuracy: 0.8951
Epoch: 5 loss: 0.4081 accuracy: 0.9163 val_loss: 0.4324 val_accuracy: 0.9012
Epoch: 6 loss: 0.3799 accuracy: 0.9199 val_loss: 0.4155 val_accuracy: 0.9015
Epoch: 7 loss: 0.3466 accuracy: 0.9270 val_loss: 0.3810 val_accuracy: 0.9113
Epoch: 8 loss: 0.3272 accuracy: 0.9305 val_loss: 0.3699 val_accuracy: 0.9131
Epoch: 9 loss: 0.3090 accuracy: 0.9329 val_loss: 0.3421 val_accuracy: 0.9235
Epoch: 10 loss: 0.2943 accuracy: 0.9359 val_loss: 0.3682 val_accuracy: 0.9055
Epoch: 11 loss: 0.2788 accuracy: 0.9392 val_loss: 0.3197 val_accuracy: 0.9264
Epoch: 12 loss: 0.2627 accuracy: 0.9431 val_loss: 0.3289 val_accuracy: 0.9208
Epoch: 13 loss: 0.2500 accuracy: 0.9454 val_loss: 0.3242 val_accuracy: 0.9177
Epoch: 14 loss: 0.2448 accuracy: 0.9459 val_loss: 0.3142 val_accuracy: 0.9195
Epoch: 15 loss: 0.2332 accuracy: 0.9471 val_loss: 0.3181 val_accuracy: 0.9154
Epoch: 16 loss: 0.2251 accuracy: 0.9493 val_loss: 0.2959 val_accuracy: 0.9233
Epoch: 17 loss: 0.2176 accuracy: 0.9508 val_loss: 0.3093 val_accuracy: 0.9176
Epoch: 18 loss: 0.2109 accuracy: 0.9518 val_loss: 0.2948 val_accuracy: 0.9254
Epoch: 19 loss: 0.2029 accuracy: 0.9538 val_loss: 0.2992 val_accuracy: 0.9225
Epoch: 20 loss: 0.1965 accuracy: 0.9553 val_loss: 0.3101 val_accuracy: 0.9127
Epoch: 21 loss: 0.1940 accuracy: 0.9551 val_loss: 0.2782 val_accuracy: 0.9287
Epoch: 22 loss: 0.1879 accuracy: 0.9570 val_loss: 0.2739 val_accuracy: 0.9318
Epoch: 23 loss: 0.1837 accuracy: 0.9576 val_loss: 0.2966 val_accuracy: 0.9196
Epoch: 24 loss: 0.1805 accuracy: 0.9589 val_loss: 0.2706 val_accuracy: 0.9314
Epoch: 25 loss: 0.1743 accuracy: 0.9606 val_loss: 0.2622 val_accuracy: 0.9321
Epoch: 26 loss: 0.1712 accuracy: 0.9611 val_loss: 0.2626 val_accuracy: 0.9338
Epoch: 27 loss: 0.1720 accuracy: 0.9607 val_loss: 0.2900 val_accuracy: 0.9181
Epoch: 28 loss: 0.1685 accuracy: 0.9610 val_loss: 0.2814 val_accuracy: 0.9297
Epoch: 29 loss: 0.1661 accuracy: 0.9614 val_loss: 0.2724 val_accuracy: 0.9293
Epoch: 30 loss: 0.1646 accuracy: 0.9621 val_loss: 0.2779 val_accuracy: 0.9255

Epoch 00030: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 31 loss: 0.1540 accuracy: 0.9663 val_loss: 0.2439 val_accuracy: 0.9405
Epoch: 32 loss: 0.1413 accuracy: 0.9702 val_loss: 0.2614 val_accuracy: 0.9314
Epoch: 33 loss: 0.1397 accuracy: 0.9705 val_loss: 0.2439 val_accuracy: 0.9383
Epoch: 34 loss: 0.1383 accuracy: 0.9703 val_loss: 0.2637 val_accuracy: 0.9344
Epoch: 35 loss: 0.1378 accuracy: 0.9699 val_loss: 0.2481 val_accuracy: 0.9403
Epoch: 36 loss: 0.1336 accuracy: 0.9717 val_loss: 0.2607 val_accuracy: 0.9326

Epoch 00036: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 37 loss: 0.1233 accuracy: 0.9752 val_loss: 0.2428 val_accuracy: 0.9411
Epoch: 38 loss: 0.1193 accuracy: 0.9775 val_loss: 0.2640 val_accuracy: 0.9355
Epoch: 39 loss: 0.1192 accuracy: 0.9765 val_loss: 0.2508 val_accuracy: 0.9418
Epoch: 40 loss: 0.1149 accuracy: 0.9778 val_loss: 0.2497 val_accuracy: 0.9413
Epoch: 41 loss: 0.1149 accuracy: 0.9777 val_loss: 0.2487 val_accuracy: 0.9411
Epoch: 42 loss: 0.1123 accuracy: 0.9785 val_loss: 0.2473 val_accuracy: 0.9427

Epoch 00042: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
Epoch: 43 loss: 0.1043 accuracy: 0.9821 val_loss: 0.2425 val_accuracy: 0.9442
Epoch: 44 loss: 0.1019 accuracy: 0.9825 val_loss: 0.2414 val_accuracy: 0.9460
Epoch: 45 loss: 0.1022 accuracy: 0.9822 val_loss: 0.2414 val_accuracy: 0.9450
Epoch: 46 loss: 0.0983 accuracy: 0.9834 val_loss: 0.2494 val_accuracy: 0.9411
Epoch: 47 loss: 0.0967 accuracy: 0.9837 val_loss: 0.2412 val_accuracy: 0.9467
Epoch: 48 loss: 0.0976 accuracy: 0.9832 val_loss: 0.2471 val_accuracy: 0.9450
Epoch: 49 loss: 0.0951 accuracy: 0.9844 val_loss: 0.2528 val_accuracy: 0.9437
Epoch: 50 loss: 0.0939 accuracy: 0.9844 val_loss: 0.2475 val_accuracy: 0.9465
Epoch: 51 loss: 0.0924 accuracy: 0.9849 val_loss: 0.2570 val_accuracy: 0.9397
Epoch: 52 loss: 0.0912 accuracy: 0.9853 val_loss: 0.2422 val_accuracy: 0.9464

Epoch 00052: ReduceLROnPlateau reducing learning rate to 4.0960000478662555e-05.
Epoch: 53 loss: 0.0856 accuracy: 0.9872 val_loss: 0.2342 val_accuracy: 0.9495
Epoch: 54 loss: 0.0849 accuracy: 0.9872 val_loss: 0.2459 val_accuracy: 0.9455
Epoch: 55 loss: 0.0834 accuracy: 0.9877 val_loss: 0.2433 val_accuracy: 0.9472
Epoch: 56 loss: 0.0832 accuracy: 0.9879 val_loss: 0.2389 val_accuracy: 0.9499
Epoch: 57 loss: 0.0829 accuracy: 0.9876 val_loss: 0.2382 val_accuracy: 0.9516
Epoch: 58 loss: 0.0814 accuracy: 0.9884 val_loss: 0.2519 val_accuracy: 0.9443

Epoch 00058: ReduceLROnPlateau reducing learning rate to 3.2767999800853435e-05.
Epoch: 59 loss: 0.0777 accuracy: 0.9893 val_loss: 0.2337 val_accuracy: 0.9523
Epoch: 60 loss: 0.0756 accuracy: 0.9905 val_loss: 0.2368 val_accuracy: 0.9503
Epoch: 61 loss: 0.0745 accuracy: 0.9903 val_loss: 0.2385 val_accuracy: 0.9510
Epoch: 62 loss: 0.0750 accuracy: 0.9898 val_loss: 0.2449 val_accuracy: 0.9464
Epoch: 63 loss: 0.0725 accuracy: 0.9907 val_loss: 0.2420 val_accuracy: 0.9479
Epoch: 64 loss: 0.0739 accuracy: 0.9901 val_loss: 0.2382 val_accuracy: 0.9517

Epoch 00064: ReduceLROnPlateau reducing learning rate to 2.6214399258606137e-05.
Epoch: 65 loss: 0.0691 accuracy: 0.9917 val_loss: 0.2396 val_accuracy: 0.9504
Epoch: 66 loss: 0.0686 accuracy: 0.9916 val_loss: 0.2439 val_accuracy: 0.9487
Epoch: 67 loss: 0.0674 accuracy: 0.9923 val_loss: 0.2556 val_accuracy: 0.9476
Epoch: 68 loss: 0.0671 accuracy: 0.9922 val_loss: 0.2439 val_accuracy: 0.9512
Epoch: 69 loss: 0.0664 accuracy: 0.9925 val_loss: 0.2496 val_accuracy: 0.9491

Epoch 00069: ReduceLROnPlateau reducing learning rate to 2.09715188248083e-05.
End of augmented training
Finish
Job ended!
