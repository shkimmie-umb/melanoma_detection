Thu 09 May 2024 11:45:33 PM EDT
Python 3.9.7
nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2019 NVIDIA Corporation
Built on Sun_Jul_28_19:07:16_PDT_2019
Cuda compilation tools, release 10.1, V10.1.243
My SLURM_ARRAY_TASK_ID: 
DB: ['ISIC2016', 'KaggleMB']
IMG_SIZE: [384, 384]
CLASSIFIER: Xception
JOB_INDEX: None
Start training augmented images
Combining...
Combining 1th db out of 2 dbs
Combining 2th db out of 2 dbs
Stacking data
Combining complete
Model: "sequential"
_________________________________________________________________
Layer (type)                 Output Shape              Param #   
=================================================================
xception (Functional)        (None, 2048)              20861480  
_________________________________________________________________
dense (Dense)                (None, 512)               1049088   
_________________________________________________________________
dropout (Dropout)            (None, 512)               0         
_________________________________________________________________
batch_normalization_4 (Batch (None, 512)               2048      
_________________________________________________________________
dense_1 (Dense)              (None, 256)               131328    
_________________________________________________________________
batch_normalization_5 (Batch (None, 256)               1024      
_________________________________________________________________
dense_2 (Dense)              (None, 2)                 514       
=================================================================
Total params: 22,045,482
Trainable params: 1,182,466
Non-trainable params: 20,863,016
_________________________________________________________________
Fitting ISIC2016+KaggleMB_aug_Xception_384h_384w_None model...
model_name: ISIC2016+KaggleMB_aug_Xception_384h_384w_None
Epoch: 1 loss: 1.0824 accuracy: 0.7712 val_loss: 1.1688 val_accuracy: 0.6992
Epoch: 2 loss: 0.9050 accuracy: 0.8562 val_loss: 1.1049 val_accuracy: 0.7472
Epoch: 3 loss: 0.8383 accuracy: 0.8859 val_loss: 1.0436 val_accuracy: 0.7542
Epoch: 4 loss: 0.7884 accuracy: 0.9090 val_loss: 1.0273 val_accuracy: 0.7571
Epoch: 5 loss: 0.7636 accuracy: 0.9178 val_loss: 1.0073 val_accuracy: 0.7669
Epoch: 6 loss: 0.7312 accuracy: 0.9309 val_loss: 1.0253 val_accuracy: 0.7811
Epoch: 7 loss: 0.7098 accuracy: 0.9379 val_loss: 1.0229 val_accuracy: 0.7768
Epoch: 8 loss: 0.6942 accuracy: 0.9443 val_loss: 0.9911 val_accuracy: 0.8206
Epoch: 9 loss: 0.6550 accuracy: 0.9580 val_loss: 1.0790 val_accuracy: 0.7669
Epoch: 10 loss: 0.6330 accuracy: 0.9645 val_loss: 1.0622 val_accuracy: 0.7924
Epoch: 11 loss: 0.6160 accuracy: 0.9705 val_loss: 1.0005 val_accuracy: 0.8121
Epoch: 12 loss: 0.6118 accuracy: 0.9679 val_loss: 1.0275 val_accuracy: 0.8065
Epoch: 13 loss: 0.5922 accuracy: 0.9726 val_loss: 1.0160 val_accuracy: 0.8136

Epoch 00013: ReduceLROnPlateau reducing learning rate to 7.999999797903001e-05.
Epoch: 14 loss: 0.5648 accuracy: 0.9844 val_loss: 0.9915 val_accuracy: 0.8136
Epoch: 15 loss: 0.5606 accuracy: 0.9820 val_loss: 0.9898 val_accuracy: 0.8362
Epoch: 16 loss: 0.5497 accuracy: 0.9835 val_loss: 1.0359 val_accuracy: 0.8164
Epoch: 17 loss: 0.5426 accuracy: 0.9850 val_loss: 1.0364 val_accuracy: 0.8305
Epoch: 18 loss: 0.5335 accuracy: 0.9861 val_loss: 1.0414 val_accuracy: 0.8164
Epoch: 19 loss: 0.5285 accuracy: 0.9861 val_loss: 1.0115 val_accuracy: 0.8333
Epoch: 20 loss: 0.5171 accuracy: 0.9904 val_loss: 1.0094 val_accuracy: 0.8249

Epoch 00020: ReduceLROnPlateau reducing learning rate to 6.399999838322402e-05.
Epoch: 21 loss: 0.5091 accuracy: 0.9897 val_loss: 1.0475 val_accuracy: 0.8220
Epoch: 22 loss: 0.5049 accuracy: 0.9908 val_loss: 1.0462 val_accuracy: 0.8277
Epoch: 23 loss: 0.4956 accuracy: 0.9929 val_loss: 1.0821 val_accuracy: 0.8220
Epoch: 24 loss: 0.4848 accuracy: 0.9953 val_loss: 1.0665 val_accuracy: 0.8263
Epoch: 25 loss: 0.4816 accuracy: 0.9944 val_loss: 1.0654 val_accuracy: 0.8319

Epoch 00025: ReduceLROnPlateau reducing learning rate to 5.119999987073243e-05.
End of augmented training
Finish
Job ended!
